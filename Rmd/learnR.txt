aucnntkcaatgioemngsofraudpedanhlncuaicslatysifisniogiagsucntpkrlaeaogte functiomnpgsloofrautdpdeanhnlcaiuclsatysiifspnoiigasgcnutkraaege olitnime e foilebjecftos cofrdaeme file foltliomweing objects cofrdlaitenimmeee fottrrsvnlschglsaestoedpoercsbmsuurareledueaestlmpldesesivlscsthsocefsfhuartpenoicaelmtaollsoosltyqonrnogeicaenufrpcdraactsafieeslruietctetneernsvgltunawidrtoaslnusreigrxlasrieiroeeovmtviittsloyvshiswscsarateuaoftekyscolisiiaariotnllsclsntuaaielpnauhnartolcpctsflaaeuspogeoyolosmobeynausmerurrewndreclurptdrlaamcrtomsretmelahaisersnrarmenlorlsanasagsaidasdfalsatsgeulcdnminnoeunasptaraatetgdwaecetodbtmgielrdneaeorettdprcesceeiasmncmhthndiarvefsdsytsaeaeipssdprrntdyonmuaaacmcmitdnsqchoaaiorenmeoacaevpetsufqttleeraaabcoeashemieisfckwtcsgrroflqcsttejiavmeeecdhtreatarmmeisooreieerpltxtcceoiwirdnhilfarrxigllrpatdstaoioiantermyuessneachanctcrtatdsntlsasaneidmttoontttlifenigesziorwgmcblaecemupaeespemmtssaslrspeitueshemtrcnsofdiltneieaautslecaeqtkecalritmoeldlecletealesvfiyeoismroyprsanmretraenlolnuaereaamlmcuereaeriisenrrlmslulstcfeiaaaalgnaictsefatvrtdulacotiitrnrbsvseconasthsaaalteteoeddetnodolteglcseaebmetdurrireenlimesduemanceslmduldceesedxivlsassstshomcaefagurtpepnstamoacraelmleysreontdrltanoapqonaogrcdmpcecdoltufdrniccrehihoaaecivosalseiaestseeetpaereusuecfettrneaebpcoashninsglscrtclccwkisdgtrrogollvgllnureraajaaeirmteaadheasvtetiroeoovrmvlbyhnotrcssllteceiswssiwarearhaitcfaerlalirsrkyslisconptueiarnaslitercynvelspncuentaaiadtsnratearceatteclsosfotnitdeuoegnernoeilsxwrbgnussonmgrepcwtrcurtsiegdtmlarpoorsmehaiseosrarmnnaalsalpiiddassgmasrdnnoeuiepeetnegvwsmiertdnqtooeeiemsecdsueslrlmnuieiirevupfvnrytmlloaaattielceserslirneelmuscfyeanuatarndtmiorsmcsvnlcahglaostoedpoereclmeamsuurarielfewseasesftmtpeildsecsvsrahesoicefsfeieuapenxoticiadnlollsxooigsltmtioonnogsesicanracdrtnsoatsflmeeesiiftntzlrrnvguluaecawipasplnueeirmxmaasriioeovmtsisilttloyseishwsseearatnuofedkylsscoseiaaritllscsntuaeaiecalnahtartolcpctslteaeuspovgfieyolosmboyrauaserurrelrtrrow femcli irccnkesorstliaeldulgurataimellosssntvenssiuvsaarrsmeoitleocnarshosbptloiheacecka
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               J H Maindonald
                                                       effects
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Learning and Exploring R
                                                       web svavaleueplots

cli icnkstallati losteniuvarseotlenrss                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        apply
                                    ggplot
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          row femcalalel

row femcalalel                              i irccnkesorstliaeldulgurataimellosssntvenssiuvsaarrsmeoitleocnarshospbtloiheaceckageessatibpilmlioattittieenssg

             effects                                                                               lot

            web svavaleueplots
Copyright © 2018 J H Maindonald
This text is dual licensed under the Creative Commons Attribution-ShareAlike 3.0 Unported License
(CC-BY-SA) and the GNU Free Documentation License (GFDL).
November 2018

S has forever altered the way people analyze, visualize, and manipulate data... S is
an elegant, widely accepted, and enduring software system, with conceptual integrity,
thanks to the insight, taste, and effort of John Chambers.
From the citation for the 1998 Association for Computing Machinery Software award.

A big computer, a complex algorithm and a long time does not equal science.
Robert Gentleman
    Contents

1 Getting started with R 13
2 The R Working Environment 29
3 Examples — Data analysis with R 43
4 Data Objects and Functions 59
5 Data Input and Storage 85
6 Data Manipulation and Management 97
7 Graphics – base, lattice, ggplot2, rgl, googleVis. . . 111
8 Regression with Linear Terms and Factors 143
9 A Miscellany of Models & Methods 173
10 Map Overlays and Spatial Modeling 195
11 Brief Notes on Text Mining 205
12 ∗Leveraging R Language Abilities 211
         4                219

A ∗R System Conﬁguration

B The R Commander Graphical User Interface 225

C Color Versions of Selected Graphs 229

D Bibliography 235
Introduction
6

The scope of these notes

These notes were developed over the course of more than a decade,
for use in R courses that were presented to groups within universi-
ties, within CSIRO, and within Government departments. Each new
course oﬀered the chance to extend and reﬁne the content, and to add
content that was tuned to the requirements of the new audience. The
result is a somewhat eclectic mix of material. The notes are provided
here with the intention that others will be free to add to them, or to
develop them for their own purposes.

Commentary on R                                                           R is free to download from a CRAN
                                                                          site (see above). It runs on all common
General                                                                   types of system – Windows, Mac,
                                                                          Unix and Linux.
R has extensive graphical abilities that are tightly linked with its
analytic abilities. A new release of base R, on which everything else     1 These include Python, SQL and
is built appears every few months.                                        other databases, parallel computing
                                                                          using MPI, and Excel.
    The major part of R’s abilities for statistical analysis and for
specialist graphics comes from the extensive enhancements that the
packages build on top of the base system. Its abilities are further
extended by an extensive range of interfaces into other systems1

    The main part of the R system – base R plus the recommended
packages – is under continuing development.

The R user base                                                           The R Task Views web page (http:
                                                                          //cran.csiro.au/web/views/)
Statistical and allied professionals have found R especially attractive,  notes, for application areas where R is
both for the access that it gives to cutting edge tools, and as a plat-   widely used, relevant packages.
form for developing new tools. Additionally, the R system has found
wide use among working scientists whose data analysis requirements
justify the time needed to gain the necessary R skills. It is ﬁnding
use, also, as an environment in which to embed applications whose
primary focus is not data analysis or graphics.

Getting help

Note the web sites:

Wikipedia:
http://en.wikipedia.org/wiki/R_(programming_language)

R-downunder (low traﬃc, friendly):
http://www.stat.auckland.ac.nz/mailman/listinfo/r-downunder

Stackoverﬂow
http://stackoverflow.com/questions/tagged/r.

    The r-help mailing list serves, especially for users with a techni-   Details of this and other lists can be
cal bent, as an informal support network. The R community expects         found at: http://www.r-project.
                                                                          org. Be sure to check the available
                                                                          documentation before posting to r-
                                                                          help. List archives can be searched for
                                                                          previous questions and answers.
users to want more than a quick cook-book ﬁx, and to show a will-                                               7
ingness to work at improving statistical knowledge.
                                                                       CRAN is the primary R ‘repository’.
    Novices will ﬁnd the low traﬃc R-downunder list more friendly      Among package repositories that
and helpful than the main R mailing list. Its subscribers include      supplement CRAN, note in particular
some highly expert individuals.                                        the Bioconductor repository (http:
                                                                       //www.bioconductor.org), which
Important R web links                                                  caters for high throughput genomic
                                                                       data.
Note the following web sites:
CRAN (Comprehensive R Archive Network):
http://cran.r-project.org
Obtain R and R packages from a CRAN mirror in the local region.
An Australian mirror (one of two) is: https://cran.csiro.au/
For New Zealand, use http://cran.stat.auckland.ac.nz
R homepage: https://www.r-project.org/
For various useful links click, from an R session that uses the GUI,
on the menu item R help. Then, on the browser window that pops
up, look under Resources

The origins and future of R                                            Open source systems that might have
                                                                       been the basis for an R-like project
The R system implements a dialect of the S language that was de-       include Scilab, Octave, Gauss, Lisp-
veloped at AT&T Bell Laboratories as a general purpose scientiﬁc       Stat, Python, and now Julia. None of
language, with especial strengths in data manipulation, graphical      these match the range and depth of
presentation and statistical analysis. The commercial S-PLUS imple-    R’s packages. Julia, which strongly
mentation popularized the S language, giving a user base into which    outperforms R in execution time
R could tap.                                                           comparisons that appear on the Julia
                                                                       website http://julialang.org,
    Ross Ihaka and Robert Gentleman, both at that time from the        has not had time to establish a clear
University of Auckland, developed the initial version of R, for use    place for itself.
in teaching. Since mid-1997, development has been overseen by a
‘core team’ of about a dozen people, drawn from diﬀerent institu-      More than 12,000 packages are, as of
tions worldwide.                                                       January 2018, available through the
                                                                       CRAN sites.
    With the release of version 1.0 in early 2000, R became a serious
tool for professional use. Since 2004, the number of packages has      R code looks at ﬁrst glance like C
increased at a rate of slightly more than 25% per annum.               code. The R interpreter is modeled on
                                                                       the Scheme LISP dialect.
    The R system uses a language model that dates from the 1980s.
Any change to a more modern language model is likely to be evolu-
tionary. Details of the underlying computer implementation are in a
process of limited continual change.

Interactive development environments – editors and more                Note also Emacs, with the ESS
                                                                       (Emacs Speaks Statistics) addon.
RStudio (http://rstudio.org/) is a very attractive run-time            is This is a feature-rich environment
environment for R, available for Windows, Mac and Linux/Unix           that can be daunting for novices. It
systems. This has extensive abilities for managing projects, and for   runs on Windows as well as Lin-
working with code. It is a highly recommended alternative to the       ux/Unix and Mac. Note also, for
                                                                       Windows, the Tinn-R editor (http:
                                                                       //www.sciviews.org/Tinn-R/).
8

GUIs that come with the Windows and Mac OS X binaries that are
available from CRAN sites.

Pervasive unifying ideas                                                  Expressions can be:
                                                                             evaluated (of course)
Ideas that pervade R include:                                                printed on a graph (come to think of
                                                                             it, why not?)
  Generic functions for common tasks – print, summary, plot, etc.
  (the Object-oriented idea; do what that “class” of object requires)     There are many unifying compu-
  Formulae, for specifying graphs, models and tables.                     tational features. Thus any ‘linear’
  Language structures can be manipulated, just like any data object       model (lm, lme, etc) can use spline
  (Manipulate formulae, expressions, function argument lists, . . . )     basis functions to ﬁt spline terms.
  Lattice (trellis) and ggplot graphics oﬀer innovative features that
  are widely used in R packages. They aid the provision of graphs
  that reﬂect important aspects of data structure.

Note however that these are not uniformly implemented through R.
This reﬂects the incremental manner in which R has developed.

Data set size                                                             An important step was the move,
                                                                          with the release of version 1.2, to a
R’s evolving technical design has allowed it, taking advantage of         dynamic memory model.
advances in computing hardware, to steadily improve its handling of       2 The diﬀerence in cost may be small
large data sets. The ﬂexibility of R’s memory model does however          or non-existent for systems that have a
have a cost2 for some large computations, relative to systems that        64-bit address space.
process data from ﬁle to ﬁle.
                                                                          Take particular care with newer or
Good planning, informed analysis and reliable software                    little-used abilities in contributed
                                                                          packages. These may not have been
While the R system is unique in the extent of close scrutiny that it      much tested, unless by their develop-
receives from highly expert users, the same warnings apply as to any      ers.
statistical system. The base system and the recommended packages
get unusually careful scrutiny.                                           Always, one has to ask whether data
                                                                          are available, or can be collected, that
    The scientiﬁc context, has crucial implications for the experi-       allow the required inferences.
ments that it is useful to do, and for the analyses that are meaningful.
Available statistical methodology, and statistical and computing soft-
ware and hardware, bring their own constraints and opportunities.

    Statistics of data collection encompasses statistical experimental
design, sampling design, and data collection more generally. Subject
area insights can be crucial.

    Once the data have been collected, the challenges are then those
of data analysis and of interpretation and presentation of results.
Eﬀective data analysis must take account of the limitations inherent
in the data, an understanding of the statistical issues, and risks that
arise from inadequate understanding of the statistical issues. For
this, software that is of high quality must be complemented with the
critical resources of well-trained and well-informed minds.
Documentation and Learning Aids                                                                               9

R podcasts: See for example http://www.r-podcast.org/                Also http://wiki.r-project.
                                                                     org/rwiki/doku.php
Oﬃcial Documentation: Users who are working through these
notes on their own should have available for reference the document
“An Introduction to R”, written by the R Development Core Team.
To download an up-to-date copy, go to CRAN.

Web-based Documentation: Go to http://www.r-project.org
and look under Documentation. There are further useful links under
Other.

The R Journal (formerly R News): Successive issues are a mine of
useful information. These can be copied down from a CRAN site.

Books: See http://www.R-project.org/doc/bib/R.bib
for a list of R-related books that is updated regularly. Here, note
especially:
Maindonald, J. H. & Braun, J. H. 2010. Data Analysis & Graphics
Using R. An Example-Based Approach. 3rd edn, Cambridge Univer-
sity Press, Cambridge, UK, 2010.
http://www.maths.anu.edu.au/~johnm/r-book.html
Notes for Readers of this Text                                                                                 11

Asterisked Sections or Subsections                                      The DAAGviz package collects to-
                                                                        gether scripts and datasets that may be
Asterisks are used to identify material that is more technical or spe-  useful to readers of these notes.
cialized, and that might be omitted at a ﬁrst reading.                  Assuming that the DAAGviz package
                                                                        has been installed, it can be attached
The DAAGviz package                                                     thus:

This package, available from Github, is an optional companion to        library(DAAGviz)
these notes. The most recent version can be installed, from an R
session (the devtools package must be installed), by executing the      More succinctly, use the function
command:                                                                getScript():

devtools :: install_github (" jhmaindonald / DAAGviz ")                 ## Place Ch 5 script in
                                                                        ## working directory
    Once attached, this package gives access to:                        getScript(5)

- Scripts that include all the code. To access these scripts do, e.g.   More succinctly, use the function
                                                                        sourceFigFuns():
   ## Check available scripts
   dir(system.file('scripts', package='DAAGviz'))                       ## Load Ch 5 functions
   ## Show chapter 5 script                                             ## into workspace
   script5 <- system.file('scripts/5examples-code.R',                   sourceFigFuns(5)

                                               package='DAAGviz')
   file.show(script5)

- Source ﬁles (also scripts) for functions that can be used to repro-
   duce the graphs. These are available for Chapters 5 to 15 only.
   To load the Chapter 5 functions into the workspace, use the com-
   mand:

   path2figs5 <- system.file('doc/figs5.R',
                                                   package='DAAGviz')

   source(path2figs5)

- The datasets bronchit, eyeAmp, and Crimean, which feature
   later in these notes.
1
Getting started with R
14 learning and exploring r

1.1 Installation of R

Click as indicated in the successive panels to download R for Win-
dows from the web page http://cran.csiro.au:

                                                                         Figure 1.1: This shows a sequence
                                                                         of clicks that will download the R
                                                                         installation ﬁle from cran.csiro.
                                                                         edu. At the time of writing, the
                                                                         website will oﬀer R-3.4.3 rather than
                                                                         R-2.13.0. The site cran.csiro.edu
                                                                         is one of two Australian CRAN
                                                                         (Comprehensive R Archive Network)
                                                                         sites. The other is: http://cran.ms.
                                                                         unimelb.edu.au/

    Click on the downloaded ﬁle to start installation. Most users will   Figure 1.2: On 64-bit Windows
want to accept the defaults. The eﬀect is to install the R base system,  systems the default installation process
plus recommended packages, with a standard “oﬀ-the-shelf” setup.         creates two icons, one for 32-bit R and
Windows users will ﬁnd that one or more desktop R icons have been        one for 64-bit R. Additional icons can
created as part of the installation process.                             be created as desired.

    Depending on the intended tasks, it may be necessary to install      Clicking on the RStudio icon to start
further packages. Section 1.3 describes alternative ways to install      a session will at the same time start
packages.                                                                R. RStudio has its own command
                                                                         line interface, where users can type R
    An optional additional step is to install RStudio. RStudio has       commands.
abilities that help in managing workﬂow, in navigating between
projects, and in accessing R system information. See Section 2.4.        Readers who have RStudio running
                                                                         can type their commands in the RStu-
1.2 First steps                                                          dio command line panel.

Click on an R icon to start an R session. This opens an R command
window, prints information about the installed version of R, and
gives a command prompt.
The > prompt that appears on the ﬁnal line is an invitation to start
typing R commands:
                                                                                 getting started with r 15

                                                                            Figure 1.3: Windows command win-
                                                                            dow at startup. This shows the default
                                                                            MDI (multiple display) interface. For
                                                                            running R from the R Commander,
                                                                            the alternative SDI (single display)
                                                                            interface may be required, or may be
                                                                            preferable. The Mac GUI has a SDI
                                                                            type interface; there is no other option.

    Thus, type 2+5 and press the Enter key. The display shows:              The [1] says, a little strangely, “ﬁrst
                                                                            requested element will follow”. Here,
> 2+5                                                                       there is just one element.

[1] 7                                                                       Typing result on the command line
                                                                            has printed the value 7.
The result is 7. The output is immediately followed by the >                Technically, the workspace is one of
prompt, indicating that R is ready for another command.                     a number of databases where objects
                                                                            may be stored.
    Try also:                                                               The object result was added to a
                                                                            previously empty workspace.
> result <- 2+5
> result                                                                    Technically, the R system refers to the
                                                                            workspace as .Globalenv.
[1] 7

    The object result is stored in the workspace. The workspace
holds objects that the user has created or input, or that were there at
the start of the session and not later removed

    Type ls() to list the objects in the workspace, thus:

> ls()

[1] "result"

    Figure 1.4 shows, with annotations, the screen as it appears fol-
lowing the above sequence of commands.

    An R session is structured as a hierarchy of databases. Functions
that were used or referred to above — such as ls() – are from a
database or package that is part of the R system. Objects that the
user has created or input, or that were there at the start of the session
and not later removed, are stored in the workspace.

    The workspace is the user’s database for the duration of a ses-
sion. It is a volatile database, i.e., it will disappear if not explicitly
saved prior to or at the end of the session.
16 learning and exploring r

                                                                        Figure 1.4: This shows the sequence
                                                                        of commands that are demonstrated in
                                                                        the text, as they appear on the screen,
                                                                        with added annotation.

1.2.1 Points to note

Printing      Typing the name of an object (and pressing Enter)
              displays (prints) its contents.
Quitting
Case matters  To quit, type q(), (not q)
              volume is diﬀerent from Volume

    Typing the name of an object (and pressing the Enter key) causes    1 Typing q lists the code for the func-
the printing of its contents, as above when result was typed. This      tion.
applies to functions also. Thus type q() in order to quit, not q.1 One
types q() because this causes the function q to spring into action.     2 Such an image allows reconstruction
                                                                        of the workspace of which it forms an
    Upon typing q() and pressing the Enter key, a message will ask      image!
whether to save the workspace image.2 Clicking Yes (usually the
safest option) will save the objects that remain in the workspace –     Figure 1.5: Note the use of the special
any that were there at the start of the session (unless removed or      characters: ; to separate multiple com-
overwritten) and any that have been added since. The workspace that     mands on the one line, + (generated
has been thus saved is automatically reloaded when an R session is      by the system) to denote continuation
restarted in the working directory to which it was saved.               from previous line, and # to introduce
                                                                        comment that extends to end of line.

    Note that for names of R objects or commands, case is signiﬁ-       3 Under Windows case is ignored. For
                                                                        Unix case does distinguish. (Mac OS
cant. Thus Myr (millions of years, perhaps) diﬀers from myr. For ﬁle    X Unix is a partial exception.)
names,3 the operating system conventions apply.
    Commands may, as demonstrated in Figure 1.5, continue over               getting started with r 17
more than one line. By default, the continuation prompt is +. As
with the > prompt, this is generated by R, and appears on the left      Here is a command that extends over
margin. Including it when code is entered will give an error!           two lines:

                                                                          > result <-
                                                                          + 2+5

1.2.2 Some further comments on functions in R                           R is a functional language. Whenever
                                                                        a command is entered, this causes a
Common functions that users should quickly get to know include          function to run. Addition is imple-
print(), plot() and help(). Above, we noted the function q(),           mented as a function, as are other such
used to quit from an R session.                                         operations.

    Consider the function print(). One can explicitly invoke it to
print the number 2 thus:

print(2)
[1] 2

    Objects on which the function will act are placed inside the round
brackets. Such quantities are known as arguments to the function.

    An alternative to typing print(2) is to type 2 on the command
line. The function print() is then invoked implicitly:

2
[1] 2

1.2.3 Help information                                                  Examples of use of ??:
                                                                        ??Arithmetic
Included on the information that appeared on the screen when R
started up, and shown in Figures 1.4 and 1.5, were brief details on     ??base::Arith
how to access R’s built-in help information:
                                                                           # Search base R only
Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.

The shorthand ?plot is an alternative to typing help(plot).
    Replace ‘?’ by ‘??’ for a wider search. This invokes the function

help.search(), which looks for a partial match in the title or
concept ﬁelds as well as in the name.

    R has extensive built-in help information. Be sure to check it out
as necessary. Section 1.8 has further details on what is available,
beyond what you can get by using the help function.

1.2.4 The working directory                                             Under Windows, if R is started by
                                                                        clicking on an R icon, the working
Associated with each session is a working directory where R will by     directory is that speciﬁed in the
default look for ﬁles. In particular:                                   Start in directory speciﬁed in the
                                                                        icon Preferences. Subsection A.1 has
• If a command inputs data from a ﬁle into the workspace and the        details on how to specify the Start in
   path is not speciﬁed, this is where R will look for the ﬁle.         directory for an icon.

• If a command outputs results to a ﬁle, and the path is not speciﬁed,
   this is where R will place the ﬁle.
18 learning and exploring r                                               When R ﬁnds a .RData ﬁle in the
                                                                          working directory at startup, that ﬁle
• Upon quitting a session, the “oﬀ-the-shelf” setup will ask whether      will, in an oﬀ-the-shelf setup, be used
   to save an “image” of the session. Answering “Yes” has the result      to restore the workspace.
   that the contents of the workspace are saved into a ﬁle, in the
   working directory, that has the name .RData.

    For regular day to day use of R, it is advisable to have a sep-
arate working directory for each diﬀerent project. RStudio users
will be asked to specify a working directory when setting up a new
“project”.

1.3 Installation of R Packages

Installation of R Packages (Windows & MacOS X)                            A fresh install of R packages is
Start R (e.g., click on the R icon). Then use the relevant menu item      typically required when moving to a
to install packages via an internet connection. This is (usually) easier  new major release (e.g., from a 3.0
than downloading, then installing.                                        series release to a 3.1 series release).

For command line instructions to install packages, see below.

    The functions that R provides are organised into packages. The
packages that need to be installed, additional to those that come with
the initial ready-to-run system, will vary depending on individual
user requirements. The GUIs — MacOS X, Windows or Linux —
make package installation relatively straightforward.

Installation of packages from the command line                            By default, a CRAN mirror is
                                                                          searched for the required package.
To install the R Commander from the command line, enter:                  Refer back to the introduction for brief
                                                                          comments on CRAN. Subsection 2.3.1
install.packages("Rcmdr", dependencies=TRUE)                              gives details of alternatives to CRAN.
                                                                          Note in particular the Bioconductor
    The R Commander has a number of dependencies, i.e., packages          repository.
that need to be installed for the R Commander to run. Graphics
packages that are dependencies include rgl (3D dynamic graphics),
scatterplot3d, vcd (visualization of categorical data) and colorspace
(generation of color palettes, etc).

Installation of Bioconductor packages                                     For installation of Bioconductor pack-
                                                                          ages from the GUI, see Subsection
To set your system up for use of Bioconductor packages, type:             A.4.
source("http://bioconductor.org/biocLite.R")
biocLite()

    Additional packages can be installed thus:
biocLite(c("GenomicFeatures", "AnnotationDbi"))

    See further http://www.bioconductor.org/install/.
1.4 Practice with R commands                                               getting started with r 19

  Column Objects                                                      Read c as “concatenate”, or perhaps as
        width = c(11.3, 13.1, 20, 21.1, 25.8, 13.1)                   “column”.
        height = c(23.9, 18.7, 27.6, 28.5, 36, 23.4)                  Lists are widely used in R. A data
                                                                      frame is a special type of list, used to
  Data frame                                                          collect together column objects under
  A data frame is a list of column objects, all of the same length.   one name.

        widheight <- data.frame(                                      The R language has the standard
              width = c(11.3, 13.1, 20, 21.1, 25.8, 13.1),            abilities for evaluating arithmetic
              height = c(23.9, 18.7, 27.6, 28.5, 36, 23.4)            and logical expressions. There are
                                                                      numerous functions that extend these
          )                                                           basic arithmetic and logical abilities.

  Also: Arithmetic operations; simple plots; input of data.           A change by a factor of 2 is a one unit
                                                                      change on a log2 scale. A change by a
    Try the following                                                 factor of 10 is a one unit change on a
                                                                      log10 scale.
2+3 # Simple arithmetic
[1] 5                                                                 Other relational operators are
1:5 # The numbers 1, 2, 3, 4, 5
[1] 1 2 3 4 5                                                          < >= < <= == ! =
mean(1:5) # Average of 1, 2, 3, 4, 5
[1] 3
sum(1:5) # Sum of 1, 2, 3, 4, 5
[1] 15
(8:10)^2 # 8^2 (8 to the power of 2), 9^2, 10^2
[1] 64 81 100

    In addition to log(), note log2() and log10():

log2(c(0.5, 1, 2, 4, 8))
[1] -1 0 1 2 3
log10(c(0.1, 1, 10, 100, 1000))
[1] -1 0 1 2 3

It turns out, surprisingly often, that logarithmic scales are appro-
priate for one or other type of graph. Logarithmic scales focus on
relative change — by what factor has the value changed?

    The following uses the relational operator >:

(1:5) > 2 # Returns FALSE FALSE TRUE TRUE TRUE
[1] FALSE FALSE TRUE TRUE TRUE

Demonstrations                                                        Images and perspective plots:

Demonstrations can be highly helpful in learning to use R’s func-     demo(image)
tions. The following are some of demonstrations that are available    demo(persp)
for graphics functions:

demo(graphics) # Type <Enter> for each new graph
library(lattice)
20 learning and exploring r                                            For the following, the vcd package
                                                                       must be installed:
demo(lattice)
                                                                       library(vcd)
    Especially for demo(lattice), it pays to stretch the graphics      demo(mosaic)
window to cover a substantial part of the screen. Place the cursor on
the lower right corner of the graphics window, hold down the left
mouse button, and pull.

    The following lists available demonstrations:

## List demonstrations in attached packages
demo()
## List demonstrations in all installed packages
demo(package = .packages(all.available = TRUE))

1.5 A Short R Session

We will work with the data set shown in Table 1.1:

             Aird’s Guide to Sydney  thickness      width  height      weight  volume   type
       Moon’s Australia handbook          1.30      11.30  23.90          250      351  Guide
      Explore Australia Road Atlas        3.90      13.10  18.70          840      955  Guide
        Australian Motoring Guide         1.20      20.00  27.60          550      662  Roadmaps
                                          2.00      21.10  28.50         1360    1203   Roadmaps
              Penguin Touring Atlas       0.60      25.80  36.00          640      557  Roadmaps
               Canberra - The Guide       1.50      13.10  23.40          420      460  Guide

                                                                       Table 1.1: Weights and volumes, for
                                                                       six Australian travel books.

Entry of columns of data from the command line                         Read c as “concatenate”, or perhaps as
                                                                       “column”. It joins elements together
The following enters data as numeric vectors:                          into a vector, here numeric vectors.

volume <- c(351, 955, 662, 1203, 557, 460)                             The end result is that objects volume,
weight <- c(250, 840, 550, 1360, 640, 420)                             weight and description are
                                                                       stored in the workspace.
    Now store details of the books in the character vector
description:

description <- c("Aird's Guide to Sydney",
 "Moon's Australia handbook",
 "Explore Australia Road Atlas",
 "Australian Motoring Guide",
 "Penguin Touring Atlas", "Canberra - The Guide")

Listing the workspace contents

Use ls() to examine the current contents of the workspace.

ls()

[1] "description" "result"           "volume"               "weight"

Use the argument pattern to specify a search pattern:                  Note also:
                                                                       ls(pattern="^des")

                                                                          ## begins with 'des'
                                                                       ls(pattern="ion$")

                                                                          ## ends with 'ion'
                                                                      getting started with r 21

ls(pattern="ume") # Names that include "ume"
[1] "volume"

Operations with numeric vectors

Here are the values of volume
volume
[1] 351 955 662 1203 557 460

    To extract the ﬁnal element of volume, do:
volume[6]
[1] 460

    For the ratio of weight to volume, i.e., the density, we can do:
weight/volume
[1] 0.7123 0.8796 0.8308 1.1305 1.1490 0.9130

A note on functions                                                   More simply, type:
                                                                      round(weight/volume, 2)
For the weight/volume calculation, two decimal places in the out-
put is more than adequate accuracy. The following uses the function     Providing the arguments are in the
round() to round to two decimal places:                               deﬁned order, they can as here be
                                                                      omitted from the function call.
round(x=weight/volume, digits=2)
[1] 0.71 0.88 0.83 1.13 1.15 0.91                                     Many functions, among them plot()
                                                                      that is used for Figure 1.6, accept
    Functions take arguments — these supply data on which they        unnamed as well as named arguments.
operate. For round() the arguments are ‘x’ which is the quantity      The symbol ‘...’ is used to denote
that is to be rounded, and ‘digits’ which is the number of decimal    the possibility of unnamed arguments.
places that should remain after rounding.
                                                                      Isf a ‘...’ appears, indicating that
    Use the function args() to get details of the named arguments:
                                                                      there can be unnamed arguments,
args(round)                                                           check the help page for details.
function (x, digits = 0)
NULL

Tabulation

Use the function table() for simple numeric tabulations, thus:

type <- c("Guide","Guide","Roadmaps","Roadmaps",
               "Roadmaps","Guide")

table(type)
type

    Guide Roadmaps
           33
22 learning and exploring r                                             1400                                                                 q

A simple plot                                                           1200

Figure 1.6 plots weight against volume, for the six Australian travel   1000
books. Note the use of the graphics formula weight ~ volume
to specify the x− and y−variables. It takes a similar from to the       weight                                                      q
“formulae” that are used in specifying models, and in the functions            800
xtabs() and unstack().
                                                                        600                             q
    Code for Figure 1.6 is:                                                                  q
                                                                                                           q
## Code
plot(weight ~ volume, pch=16, cex=1.5)                                  400

   # pch=16: use solid blob as plot symbol                                          q                      600 800                     1000  1200
   # cex=1.5: point size is 1.5 times default                                           400                                 volume
## Alternative
plot(volume, weight, pch=16, cex=1.5)                                   Figure 1.6: Weight versus volume, for
                                                                        six Australian travel books.
    The axes can be labeled:
                                                                        Use text() for non-interactive
plot(weight ~ volume, pch=16, cex=1.5,                                  labeling of points.
       xlab="Volume (cubic mm)", ylab="Weight (g)")

    Interactive labeling of points (e.g., with species names) can be
done interactively, using identify():

identify(weight ~ volume, labels=description)

    Then click the left mouse button above or below a point, or on
the left or right, depending on where you wish the label to appear.
Repeat for as many points as required.

    On most systems, the labeling can be terminated by clicking the
right mouse button. On the Windows GUI, an alternative is to click
on the word “Stop” that appears at the top left of the screen, just
under “Rgui” on the left of the blue panel header of the R window.
Then click on “Stop locator”.

Formatting and layout of plots

There are extensive abilities that may be used to control the format-
ting and layout of plots, and to add features such as special symbols,
ﬁtted lines and curves, annotation (including mathematical annota-
tion), colors, . . .

1.6 Data frames – Grouping columns of data                              Data frames are pervasive in R. Most
                                                                        datasets that are included with R
  Data frames Store data that have a cases by columns layout.           packages are supplied as data frames.
  Creating Enter from the command line (small datasets)
  data frames Or: Use read.table() to input from a ﬁle.
  Columns of travelbooks$weight or travelbooks[, 4]
  data frames or travelbooks[, "weight"]

    The following code groups the several columns of Table 1.1
together, under the name travelbooks. It is tidier to have matched            getting started with r 23
columns of data grouped together into a data frame, rather than
separate objects in the workspace.                                       The vectors weight, volume and
                                                                         description were entered earlier,
## Group columns together into a data frame                              and (unless subsequently removed)
travelbooks <- data.frame(                                               can be copied directly into the data
                                                                         frame.
    thickness = c(1.3, 3.9, 1.2, 2, 0.6, 1.5),
    width = c(11.3, 13.1, 20, 21.1, 25.8, 13.1),                           It is a matter of convenience whether
    height = c(23.9, 18.7, 27.6, 28.5, 36, 23.4),                        the description information is used to
    weight = weight, # Use values entered earlier                        label the rows, or alternatively placed
    volume = volume, # Use values entered earlier                        in a column of the data frame.
    type = c("Guide", "Guide", "Roadmaps", "Roadmaps",

                   "Roadmaps", "Guide"),
    row.names = description
)
## Remove objects that are not now needed.
rm(volume, weight, description)

The storage of character data as factors                                 While in most contexts factors and
                                                                         character vectors are interchangeable,
Vectors of character, such as type, are by default stored in the         there are important exceptions.
data frame as factors. In the data as stored, "Guide" is 1 and
"Roadmaps" is 2. Stored with the factor is an attribute table that
interprets 1 as "Guide" and 2 as "Roadmaps".

Accessing the columns of data frames

The following are alternative ways to extract the column weight          For a matrix or array, users
from the data frame:                                                     are restricted to the ﬁrst and
                                                                         second of these alternatives.
travelbooks[, 4]         # Reference as a list.                          With a matrix travelmat
travelbooks[, "weight"]                                                  use, e.g., travelmat[,4] or
travelbooks$weight                                                       travelmat[,"weight"].
travelbooks[["weight"]]
                                                                         Most modeling functions and many
    There are several mechanisms that avoid repeated reference to        plotting functions accept a data
the name of the data frame. The following are alternative ways to        argument.
plot weight against volume:
                                                                         Attachment of a data frame:
1. Use the parameter data, where available, in the function call         attach(travelbooks)
plot( weight ~ volume, data=travelbooks)                                 plot( weight ~ volume)
                                                                         detach(travelbooks)
2. Use with(): Take columns from speciﬁed data frame
## Take columns from the specified data frame                             ## Detach when no longer
with(travelbooks, plot(weight ~ volume))                                  ## required.

Both these mechanisms look ﬁrst for a data frame column with a
needed name. The workspace is searched only if this fails.

    A third option, usually best avoided, is to use attach() to add
the data frame to the search list. In this case, names in the workspace
take precedence over column names in the attached data frame – not
usually what is wanted if there are names in common.

    Subsection 2.3.2 will discuss the attaching of packages and im-
age ﬁles.
24 learning and exploring r

1.7 Input of Data from a File

The function read.table() is designed for input from a rectangu-        This use of datafile(), avoiding
lar ﬁle into a data frame. There are several variants on this function  use of the mouse to copy the ﬁle and
— notably read.csv() and read.delim().                                  the associated need to navigate the ﬁle
                                                                        system, is a convenience for teaching
    First use the function datafile() (DAAG) to copy from the           purposes.
DAAG package and into the working directory a data ﬁle that will be
used for demonstration purposes.

## Place the file in the working directory
## NB: DAAG must be installed
DAAG::datafile("travelbooks")

Use dir() to check that the ﬁle is indeed in the working directory:

dir(pattern="travel")
   # File(s) whose name(s) include 'travel'

    The ﬁrst two lines hold the column headings and ﬁrst row, thus:

                        thickness width height weight volume type

Aird’s Guide to Sydney       1.30 11.30 23.90 250 351 Guide

...

Observe that column 1, which has the row names, has no name.            Row 1 has column names.
    The following reads the ﬁle into an R data frame:                   Column 1 has row names.

## Input the file to the data frame travelbooks
travelbooks <- read.table("travelbooks.txt",

                                         header=TRUE, row.names=1)

    The assignment places the data frame in the workspace, with
the name travelbooks. The ﬁrst seven columns are numeric. The
character data in the ﬁnal column is by default stored as a factor.

Data input – points to note:                                            Section 5.1 discusses common types
                                                                        of input errors.
- Alternatives to command line input include the R Commmander
   menu and the RStudio menu. These make it easy to check that          Character vectors and factors can
   data are being correctly entered.                                    often, but by no means always, be
                                                                        treated as equivalent.
- If the ﬁrst row of input gives column names, specify
   heading=TRUE. If the ﬁrst row of input is the ﬁrst row of data,
   specify heading=FALSE.

- See help(read.table) for details of parameter settings that may
   need changing to match the data format.

- Character vectors that are included as columns in data frames
   become, by default, factors.

1.8 Sources of Help

                                                                        Note also:
                                                                          help.search()
                                                                          apropos()
                                                                          help.start()
                                                                          RSiteSearch()
                                                                         getting started with r 25

help()         # Help for the help function
help(plot)     # Show the help page for plot
?plot          # Shorthand for help(plot)
example(plot)  # Run examples from help(plot)
demo()         # List available demonstrations
vignette()     # Get information on vignettes
               # NB also browseVignettes()

This section enlarges on the very brief details in Subsection 1.2.3      Oﬃcial R manuals include
                                                                         An Introduction to R, a manual on
Access to help resources from a browser screen                           Writing R Extensions, and so on.

Type help.start() to display a screen that gives a                       By default, all installed packages are
browser interface to R’s help resources. Note especially                 searched. Limiting the search, here
Frequently Asked Questions and Packages. Under Packages, click           to package="base", will often give
on base to get information on base R functions. Standard elemen-         more manageable and useful output.
tary statistics functions are likely to be found under stats, and base
graphics functions under graphics.                                       To work through the code for an
                                                                         example, look on the screen for the
    Also available, after clicking on a package name, is a link          code that was used, and copy or type it
User guides, package vignettes and other documentation. Click to         following the command line prompt.
get details of any documentation that is additional to the help pages.   Or get the code from the help page.

Searching for key words or strings                                       Vignettes are created from a Mark-
                                                                         down or HTML or LaTeX document
Use help.search() to look for functions that include a speciﬁc           in which R code is embedded, sur-
word or part of word in their alias or title. Thus, functions for oper-  rounded by markup that controls what
ating on character strings are likely to have “str” or “char” in their   is to be done with the code and with
name. Try                                                                any output generated. See Section 2.4.
help.search("str", package="base")
help.search("char", package="base")

    The function RSiteSearch() searches web-based resources,
including R mailing lists, for the text that is given as argument.

Examples that are included on help pages

All functions have help pages. Most help pages include examples,
which can be run using the function example(). Be warned that,
even for relatively simple functions, some of the examples may
illustrate non-trivial technical detail.

Vignettes

Many packages have vignettes; these are typically pdf or (with ver-
sion ≥ 3.0.0 of R) HTML ﬁles that give information on the package
or on speciﬁc aspects of the package. To get details of vignettes
that are available in a package, call browseVignettes() with the
26 learning and exploring r

package name (as a character string) as argument. Thus, for the knitr
package, enter browseVignettes(package="knitr").

    The browser window that appears will list the vignettes, with the
option to click on links that, in most cases, oﬀer a choice of one of
PDF and HTML, source, and R code.

Searching for Packages

A good ﬁrst place to look, for information on packages that relate to
one or other area of knowledge, is the R Task Views web page, at:
http://cran.r-project.org/web/views/. See also the website
http://crantastic.org/, which has details on what packages
are popular, and what users think of them.

1.9 Summary and Exercises                                                 NB also: Use apropos() to search
                                                                          for functions that include a stated text
1.9.1 Summary                                                             string as part of their name.

   One use of R is as a calculator, to evaluate arithmetic expressions.   Aliases of read.table() include
   Calculations can be carried out in parallel, across all elements of a  read.csv() and read.delim()
   vector at once.
                                                                          Use with() in preference to the
   The R Commander GUI can be helpful in getting quickly into use         attach() / detach() combination.
   of R for many standard purposes. It may, depending on require-
   ments, be limiting for serious use of R.

   Use q() to quit from an R session. To retain objects in the
   workspace, accept the oﬀer to save the workspace.

- Useful help functions are help() (for getting information on a
   known function) and help.search() (for searching for a word
   that is used in the header for the help ﬁle).

- The function help.start() starts a browser window from which
   R help information can be accessed.

- Use the GUI interface in RStudio or R Commander to input rect-
   angular ﬁles. Or, use read.table() or one of its aliases.

- Data frames collect together under one name columns that all
   have the same length. Columns of a data frame can be any mix of,
   among other possibilities: logical, numeric, character, or factor.

- The function with() attaches a data frame temporarily, for the
   duration of the call to with().

- For simple forms of scatterplot, use plot() and associated func-
   tions, or perhaps the lattice function xyplot().

 1.9.2 Exercises

1. Use the following code to to place the ﬁle bestTimes.txt in the
    working directory:
 (a) Examine the ﬁle, perhaps using the function file.show().              getting started with r 27
       Read the ﬁle into the workspace, with the name bestTimes.
       ## file.show("bestTimes.txt")                                  Subsection 2.2.2 discusses the use of
       bestTimes <- read.table("bestTimes.txt")                       the function save().
                                                                      4 If necessary, refer back to Section 1.6
 (b) The bestTimes ﬁle has separate columns that show hours,          for details.
       minutes and seconds. Use the following to add the new column
       Time, then omitting the individual columns as redundant        The notation base::minimum tells
       ## Exercise 1b                                                 the help function to look in R’s base
       bestTimes$Time <- with(bestTimes,                              package.
                                           h*60 + min + sec/60)
          # Time in minutes
       names(bestTimes)[2:4] # Check column names
       bestTimes <- bestTimes[, -(2:4)]
                                             # omit columns 2:4

 (c) Here are alternative ways to plot the data
       plot(Time ~ Distance, data=bestTimes)
       ## Now use a log scale
       plot(log(Time) ~ log(Distance), data=bestTimes)
       plot(Time ~ Distance, data=bestTimes, log="xy")

 (d) Now save the data into an image ﬁle in the working directory
       save(bestTimes, file="bestTimes.RData")

2. Re-enter the data frame travelbooks.4 Add a column that has
    the density (weight/volume) of each book.

3. The functions summary() and str() both give summary informa-
    tion on the columns of a data frames Comment on the diﬀerences
    in the information provided, when applied to the following data
    frames from the DAAG package:

 (a) nihills;
 (b) tomato.

4. Examine the results from entering:

 (a) ?minimum
 (b) ??minimum
 (c) ??base::minimum
 (d) ??base::min

    For ﬁnding a function to calculate the minimum of a numeric
    vector, which of the above gives the most useful information?

5. For each of the following tasks, applied to a numeric vector (nu-
    meric column object), ﬁnd a suitable function. Test each of the
    functions that you ﬁnd on the vector volume in Section 1.5:
28 learning and exploring r

(a) Reverse the order of the elements in a column object;
(b) Calculate length, mean, median, minimum maximum, range;
(c) Find the diﬀerences between successive values.
2
The R Working Environment
30 learning and exploring r

Object  Objects can be data objects, function objects,                 Important R technical terms include
        formula objects, expression objects, . . .                     object, workspace, working directory,
        Use ls() to list contents of current workspace.                image ﬁle, package, library, database
                                                                       and search list.
Workspace User’s “database”, where the user can make
                additions or changes or deletions.                     Use the relevant menu. or enter
                                                                       save.image() on the command
Working Default directory for reading or writing ﬁles.                 line, to store or back up workspace
directory Use a new working directories for a new project.             contents. During a long R session, do
                                                                       frequent saves!
Image ﬁles Use to store R objects, e.g., workspace contents.
                (The expected ﬁle extension is .RData or .rda)

Search list search() lists ‘databases’ that R will search.
                library() adds packages to the search list

2.1 The Working Directory and the Workspace                            The workspace is a volatile database
                                                                       that, unless saved, will disappear at the
Each R session has a working directory and a workspace. If not         end of the session.
otherwise instructed, R looks in the working directory for ﬁles, and
saves ﬁles that are output to it.                                      The ﬁle .RData has the name image
                                                                       ﬁle. From it the workspace can, as and
    The workspace is at the base of a list of search locations, known  when required, be reconstructed.
as databases, where R will as needed search for objects. It holds
objects that the user has created or input, or that were there at the
start of the session and not later removed.

    The workspace changes as objects are added or deleted or
modiﬁed. Upon quitting from R (type q(), or use the relevant
menu item), users are asked whether they wish to save the current
workspace. If saved, it is stored in the ﬁle .RData, in the current
working directory. When an R session is next started in that working
directory, the oﬀ-the-shelf action is to look for a ﬁle named .RData,
and if found to reload it.

Setting the Working Directory                                          1 When a Unix or Linux command
                                                                       starts a session, the default is to use
When a session is started by clicking on a Windows icon, the icon’s    the current directory.
Properties specify the Start In directory.1 Type getwd() to identify
the current working directory.                                         2 To make a complete change to
                                                                       a new workspace, ﬁrst save the
    It is good practice to use a separate working directory, and as-   existing workspace, and type
sociated workspace or workspaces, for each diﬀerent project. On        rm(list=ls(all=TRUE) to
Windows systems, copy an existing R icon, rename it as desired,        empty its contents. Then change the
and change the Start In directory to the new working directory. The    working directory and load the new
working directory can be changed2 once a session has started, either   workspace.
from the menu (if available) or from the command line. Changing
the working directory from within a session requires a clear head; it
is usually best to save one’s work, quit, and start a new session.
                                                                      the r working environment 31

2.2 Code, data, and project Maintenance

2.2.1 Maintenance of R scripts

It is good practice to maintain a transcript from which work done     Note again RStudio’s abilities for
during the session, including data input and manipulation, can as     managing and keeping R scripts.
necessary be reproduced. Where calculations are quickly completed,
this can be re-executed when a new session is started, to get to the
point where the previous session left oﬀ.

2.2.2 Saving and retrieving R objects

Use save() to save one or more named objects into an image            The command save.image()) saves
ﬁle. Use load() to reload the image ﬁle contents back into the        everything in the workspace, by
workspace. The following demonstrate the explicit use of save()       default into a ﬁle named .RData in
and load() commands:                                                  the working directory. Or, from a GUI
                                                                      interface, click on the relevant menu
volume <- c(351, 955, 662, 1203, 557, 460)                            item.

weight <- c(250, 840, 550, 1360, 640, 420)                            See Subsection 2.3.2 for use of
                                                                      attach("books.RData") in
save(volume, weight, file="books.RData")                              place of load("books.RData").

# Can save many objects in the same file                              Before saving the workspace, consider
                                                                      use of rm() to remove objects that are
rm(volume, weight)        # Remove volume and weight                  no longer required.

load("books.RData")       # Recover the saved objects

    Where it will be time-consuming to recreate objects in the
workspace, users will be advised to save (back up) the current
workspace image from time to time, e.g., into a ﬁle, preferably with
a suitably mnemonic name. For example:

fnam <- "2014Feb1.RData"
save.image(file=fnam)

Two further possibilities are:

- Use dump() to save one or more objects in a text format. For
   example:

volume <- c(351, 955, 662, 1203, 557, 460)

weight <- c(250, 840, 550, 1360, 640, 420)

dump(c("volume", "weight"), file="volwt.R")

rm(volume, weight)

source("volwt.R")               # Retrieve volume & weight

- Use write.table() to write a data frame to a text ﬁle.
32 learning and exploring r

2.3 Packages and System Setup

Packages  Packages are structured collections of R                      For download or installation of R or
          functions and/or data and/or other objects.                   CRAN packages, use for preference
                                                                        a local mirror. In Australia http://
Installation R Binaries include ’recommended’ packages.                 cran.csiro.au is a good choice. The
of packages Install other packages, as required,                        mirror can be set from the Windows
                                                                        or Mac GUI. Alternatively (on any
library() Use to attach a package, e.g., library(DAAG)                  system), type chooseCRANmirror()
                 Once attached, a package is added to the list of       and choose from the list that pops up.
                 “databases” that R searches for objects.
                                                                        To discover which packages are
An R installation is structured as a library of packages.               attached, enter one of:
                                                                        search()
• All installations should have the base packages (one of them is       sessionInfo()
   called base). These provide the infrastructure for other packages.
                                                                          Use sessionInfo() to get more
• Binaries that are available from CRAN sites include, also, all the    detailed information.
   recommended packages.
                                                                        Arguments are a vector of package
• Other packages can be installed as required, from a CRAN mirror       names and a destination directory
   site, or from another repository.                                    destdir where the latest ﬁle ver-
                                                                        sions will be saved as .zip or (MacOS
    A number of packages are by default attached at the start of a      X) .tar.gz ﬁles.
session. To attach other packages, use library() as required.
                                                                        On Unix and Linux systems, gzipped
2.3.1 Installation of R packages                                        tar ﬁles can be installed using the shell
                                                                        command:
Section 1.3 described the installation of packages from the internet.
Note also the use of update.packages() or its equivalent from the         R CMD INSTALL xx.tar.gz
GUI menu. This identiﬁes packages for which updates are available,      (replace xx.tar.gz by the ﬁle name.)
oﬀering the user the option to proceed with the update.

    The function download.packages() allows the downloading of
packages for later installation. The menu, or install.packages(),
can then be used to install the packages from the local directory. For
command line installation of packages that are in a local directory,
call install.packages() with pkgs giving the ﬁles (with path, if
necessary), and with the argument repos=NULL.

    If for example the binary DAAG_1.22.zip has been downloaded
to D:\tmp\, it can be installed thus

install.packages(pkgs="D:/DAAG_1.22.zip",
                           repos=NULL)

    On the R command line, be sure to replace the usual Windows
backslashes by forward slashes.

    Use .path.package() to get the path of a currently attached
package (by default for all attached packages).

2.3.2 The search path: library() and attach()

The R system maintains a search path (a list of databases) that de-
termines, unless otherwise speciﬁed, where and in what order to
look for objects. The search list includes the workspace, attached      the r working environment 33
packages, and a so-called Autoloads database. It may include other
items also.                                                             Database 1, where R looks ﬁrst,
                                                                        is the user workspace, called
    To get a snapshot of the search path, here taken after starting up  ".GlobalEnv".
and entering library(MASS), type:                                       Packages other than MASS were
                                                                        attached at startup.
search()
                                                                        If the process runs from RStudio,
 [1] ".GlobalEnv"        "package:MASS"                                 "tools:rstudio" will appear in
 [3] "tools:RGUI"        "package:stats"                                place of "tools:RGUI".
 [5] "package:graphics"  "package:grDevices"
 [7] "package:utils"     "package:datasets"
 [9] "package:methods"   "Autoloads"
[11] "package:base"

    For more detailed information that has version numbers of any
packages that are additional to base packages, type:

sessionInfo()

The ’::’ notation                                                       It is necessary that the latticeExtra
                                                                        package has been installed!
Use notation such as base::print() to specify the package where
a function or other object is to be found. This avoids any risk of
ambiguity when two or more objects with the same name can be
found in the search path.

    In Subsection 7.2.9 the notation latticeExtra::layer()
will be used to indicate that the function layer() from the lat-
ticeExtra package is required, distinguishing it from the func-
tion layer() in the ggplot2 package. Use of the notation
latticeExtra::layer() makes unnecessary prior use of
library(latticeExtra) or its equivalent.

Attachment of image ﬁles                                                Objects that are attached, whether
                                                                        workspaces or packages (using
The following adds the image ﬁle books.RData to the search list:        library()) or other entities, are
attach("books.RData")                                                   added to the search list.
The session then has access to objects in the ﬁle books.RData. Note     The ﬁle becomes a further “database”
that if an object from the image ﬁle is modiﬁed, the modiﬁed copy       on the search list, separate from the
becomes part of the workspace.                                          workspace.

    In order to detach books.RData, proceed thus:                       Alternatively, supply the numeric
detach("file:books.RData")                                              position of books.RData on the
                                                                        search list (if in position 2, then 2) as
2.3.3 ∗Where does the R system keep its ﬁles?                           an argument to detach().

Type R.home() to see where the R system has stored its ﬁles.            Note that R expects (and displays)
R.home()                                                                either a single forward slash or double
[1] "/Library/Frameworks/R.framework/Resources"                         backslashes, where Windows would
                                                                        show a single backslash.
34 learning and exploring r

    Notice that the path appears in abbreviated form. Type
normalizePath(R.home()) to get the more intelligible result

    [1] "C:\\Program Files\\R\\R-2.15.2"
    By default, the command system.file() gives the path to the
base package. For other packages, type, e.g.

                      system.file(package="DAAG")

                      [1] "/Library/Frameworks/R.framework/Versions/3.5/Resources/library/DAAG"

    To get the path to a ﬁle viewtemps.RData that is stored with the
DAAG package in the misc subdirectory, type:

                      system.file("misc/viewtemps.RData", package="DAAG")

2.3.4 Option Settings

Type help(options) to get full details of option settings. There are  To display the setting for the line
a large number. To change to 60 the number of characters that will    width (in characters), type:
be printed on the command line, before wrapping, do:
                                                                      options()$width
options(width=60)                                                     [1] 54

    The printed result of calculations will, unless the default is    Use signif() to aﬀect one statement
changed (as has been done for most of the output in this document)    only. For example
often show more signiﬁcant digits of output than are useful. The
following demonstrates a global (until further notice) change:          signif(sqrt(10),2)
                                                                      NB also the function round().
sqrt(10)

[1] 3.162

opt <- options(digits=2) # Change until further notice,
                                       # or until end of session.

sqrt(10)

[1] 3.2

options(opt)           # Return to earlier setting

    Note that options(digits=2) expresses a wish, which R will
not always obey!

Rounding will sometimes introduce small inconsistencies!

For example:           3.48*9), 2)

round(sqrt(85/7), 2)
[1] 3.48
round(c(sqrt(85/7)*9,
[1] 31.36 31.32
                                                                      the r working environment 35

2.4 Enhancing the R experience — RStudio

The url for RStudio is http://www.rstudio.com/. Click on the          The screenshots here are for version
icon for the downloaded installation ﬁle to install it. An RStudio    0.98.501 of RStudio.
icon will appear. Click on the icon to start RStudio. RStudio should
ﬁnd any installed version of R, and if necessary start R. Figure 2.1
shows an RStudio display, immediately after starting up and enter-
ing, very unimaginatively, 1+1.

                                                                      Figure 2.1: Here is shown the RStudio
                                                                      interface, after starting up and entering
                                                                      1+1.
36 learning and exploring r                                               Extensive and careful RStudio docu-
                                                                          mentation can be accessed, assuming
    Techncally, RStudio oﬀers an Interactive Development Environ-         an internet connection, from the Help
ment. It provides, from a graphical user interface, a range of abilities  drop-down menu. The notes included
that are helpful for organizing and managing work with R. Helpful         here are designed to draw attention to
features of RStudio include:                                              some of the more important RStudio
                                                                          abilities and features.
• The organisation of work into projects.
                                                                          Alternative available types of markup
• The recording of ﬁles that have been accessed from RStudio, of          are R Markdown or R HTML or
   help pages accessed, and of plots. The record of ﬁles is maintained    Sweave with LaTeX.
   from one session of a project to the next.

• By default, a miniature is displayed of any graph that is plotted. A
   single click expands the miniature to a full graphics window.

• The editing, maintenance and display of code ﬁles.

• Abilities that assist reproducible reporting. Markup text sur-
   rounds R code that is incorporated into a document, with option
   settings used to control the inclusion of code and/or computer out-
   put in the ﬁnal document. Output may include tables and graphs.

• Abilities that help in the creation of packages.

2.4.1 The RStudio ﬁle menu

                                                                          Figure 2.2: The RStudio File drop-
                                                                          down menu. The New File submenu
                                                                          has been further expanded.

    For now, the RStudio drop-down menus that are of most immedi-
ate importance are File and Help. Here (Figure 2.2) is the File menu,
with the New File submenu also shown.
    Here, note the possibility of opening a new R script ﬁle, and       the r working environment 37
entering code into that ﬁle. Or, to open an existing R code ﬁle, click
on the Open File... submenu.                                            Here, <CTRL> is the control key and
                                                                        <ENTER> is the Enter key.
    The key combination <CTRL><ENTER> can be used to send
code to the command line. Code that has been selected will be sent
to the command line. Or if no code has been selected, the line on
which the cursor is placed will be sent to the command line.

2.4.2 Compile a code notebook

Figure 2.3 shows a script ﬁle in the upper left panel. The code has
been sent to the command line, so that it also appears in the code
history panel on the upper right.

    In Figure 2.3, take particular note of the icon on which you can    Figure 2.3: Code from the script
click to create an R notebook. Upon clicking this icon, the system      window has been sent to the command
will ask for a name for the ﬁle. It will then create an HTML ﬁle that   line.
has, along with the code and comment, the compluter output. An
alternative to clicking on the icon is to click on the File drop-down   For the code that is shown, the HTML
menu, and then on Compile Notebook... .                                 ﬁle that results will include the output
                                                                        from summary(cars) and the graph
                                                                        from plot(cars).
38 learning and exploring r

2.5 Abilities for reproducible reporting

Markdown editors use simple markup conventions to control how
text and other document features will appear. For example:

  **Help** or __Help__ will be rendered as Help

  *Help* or _Help_ will be rendered as Help.

2.5.1 R Markdown                                                     R Markdown, as available under
                                                                     RStudio, is an enhanced version of
Click on File | New File | R Markdown.... Clicking on HTML (alter-   Markdown. It adds the ability to
natives are PDF, Word), on Document (alternatives are Presentation,  include R code, surrounded by markup
Shiny, From Template) and then on OK displays a simple skeleton R    that controls what code and/or output
Markdown document thus:                                              will appear in the ﬁnal document.

---                                                                    R users are strongly encouraged
title: "Untitled"                                                    to use R Markdown, or another such
output: html_document                                                markup system that allows embedded
---                                                                  R code, for documenting any work
                                                                     that is more than trivial. Those who
This is an R Markdown document. Markdown is a simple                 are familiar with more sophisticated
formatting syntax for authoring HTML, PDF, and MS                    markdown languages may still, for
Word documents. For more details on using R Markdown                 some types of work, ﬁnd beneﬁt in the
see <http://rmarkdown.rstudio.com>.                                  simplicity and speed of working with
                                                                     R markdown.
When you click the **Knit** button a document will
be generated that includes both content as well as
the output of any embedded R code chunks within the
document. You can embed an R code chunk like this:

    {r}
summary(cars)

You can also embed plots, for example:

    {r, echo=FALSE}
plot(cars)

Note that the echo = FALSE parameter was added                       For tutorial purposes, the ﬁle can
to the code chunk to prevent printing of the R                       be processed as it stands. Click the
code that generated the plot.                                        Knit HTML button to start the process
                                                                     of generating the HTML ﬁle. When
    In actual use, one would edit out the text and R code and re-    prompted, enter a name for the ﬁle.
place it with one’s own text and R code chunks, then clicking on     An HTML ﬁle will be generated and
Knit HTML. When prompted, enter a name for the ﬁle.                  displayed in a browser.
                                                                      the r working environment 39

R Markdown code chunk options

The markup that surrounds R code can include instructions on what
to do with R code and/or any output, including tables and graphs.
Should code be executed, should it be echoed, and what output text
and/or tables and/or graphs should appear in the ﬁnal document?

    Here is an example of code with surrounding markup, with
the code chunk options fig.width and fig.height giving
the width and height of the initial ﬁgure, and out.width giv-
ing the width to which it should be scaled in the ﬁnal document:

    {r plotgph, fig.width=7, fig.height=6, out.width="80%"}

plot(cars)

    Giving the code chunk a name, here plotgph, is optional. The      Other possible settings include:
fig.width and fig.height settings control the size of the output      echo=FALSE (do not show code), &
plot, before it is scaled to ﬁt within the available line width. The  eval=FALSE (do not evaluate).
out.width setting controls the width (here given as a percentage
of the line width) in the ﬁnal HTML document. The width may
alternatively be given in pixels, e.g., ‘out.width="600px"‘.

    An image from a ﬁle pic.png that has been generated separately
from the markup R code can be input thus:

        {r, out.width="80%"}

    knitr::include\_graphics("pic.png")

∗Inclusion of HTML in R Markdown documents

Note also that HTML markup can be included in R Markdown doc-
uments. The following is a less preferred alternative to the R code
knitr::include_graphics("pic.png") whose use was demon-
strated above:

<IMG SRC="pic.png" alt="Show this, if no image" STYLE="width: 1200px"/>

    The image position can if necessary be adjusted thus:

<IMG SRC="pic.png" alt="Show this, if no image" STYLE="position:absolute;
TOP:-25px; LEFT:40px; WIDTH:800px; HEIGHT:500px"/>

R Presentation

Note the R Presentation variant of R Markdown. To display a simple
skeleton document, click on:

   File | New File | R Presentation

An R Presentation document is a speciﬁc type of R Markdown docu-
ment that is formatted to provide slides that can be displayed using a
browser.

    Click on Knit HTML to process the document, either as it stands
or after replacing the sample text and code with one’s own text and
code.
40 learning and exploring r

2.5.2 ∗Other markup types – HTML, LaTeX, . . .

R HTML                                                                Also available is reStructuredText
                                                                      (reST), which is an extended variant of
Click on File | New File | R HTML to display a skeleton HTML doc-     R Markdown.
ument that has embedded R code. The following shows the markup
format:

<!--begin.rcode fig.width=7, fig.height=6, out.width="600px"
plot(cars)
end.rcode-->

    Again, the document that appears can be processed as it stands –
click on Knit HTML.

R Sweave:

Click on File | New File | R Sweave to display a template for a La-
TeX ﬁle. The web page http://maths-people.anu.edu.au/
~johnm/r-book/knitr/ has ﬁles that demonstrate the use of knitr
Sweave type markup.

2.5.3 RStudio documentation – markup and other

Extensive RStudio documentation is available online. Click on Help
| RStudio Docs to go to the relevant web page. For R Markdown and
R Presentation, note the documentation ﬁles for Using R Mark-
down. LATEX users should note the Sweave and knitr documenta-
tion ﬁles.

2.5.4 A strategy for RStudio project management

RStudio is designed to encourage good project management prac-
tices, using a strategy akin to the following:

  Set up each new project in its own working directory.

  For each project, maintain one or more script ﬁles that holds the
  code. Script ﬁles can be compiled into "notebooks" for purposes
  of keeping a paper record.

  Script ﬁles are readily expanded into R Markdown documents –
  a simple form of "reproducible reporting" document. They can as
  required be expanded into a draft for a paper.

2.6 Summary and Exercises

2.6.1 Summary

  Each R session has a working directory, where R will by default
  look for ﬁles or store ﬁles that are external to R.
User-created R objects are added to the workspace, which is at the       the r working environment 41
base of a search list, i.e., a list of “databases” that R will search
when it looks for objects.                                               From within functions, R will look
                                                                         ﬁrst in the functions environment,
It is good practice to keep a separate workspace and associated          and then if necessary look within the
working directory for each major project. Use script ﬁles to keep a      search list.
record of work.
                                                                         Before making big changes to the
At the end of a session an image of the workspace will typically         workspace, it may be wise to save the
(respond “y” when asked) be saved into the working directory.            existing workspace under a name (e.g.,
                                                                         Aug27.RData) diﬀerent from the
Note also the use of attach() to give access to objects in an            default .RData.
image (.RData or .rda) ﬁle.3                                             3 Include the name of the ﬁle (option-
                                                                         ally preceded by a path) in quotes.
R has an extensive help system. Use it!

 2.6.2 Exercises                                                         The function DAAG::datafile()
                                                                         is able to place in the working di-
 Data ﬁles used in these exercises are available from the web page       rectory any of the ﬁles: fuel.txt
 http://www.maths.anu.edu.au/~johnm/datasets/text/.                      molclock1.txt, molclock2.txt, travel-
                                                                         books.txt. Specify, e.g.
1. Place the ﬁle fuel.txt to your working directory.
                                                                           datafile(file="fuel")
2. Use file.show() to examine the ﬁle, or click on the RStudio
    Files menu and then on the ﬁle name to display it. Check carefully   A shortcut for placing these ﬁles in the
    whether there is a header line. Use the RStudio menu to input        working directory is:
    the data into R, with the name fuel. Then, as an alternative, use
    read.table() directly. (If necessary use the code generated by         datafile(file=c("molclock1",
    RStudio as a crib.) In each case, display the data frame and check                        "molclock2"))
    that data have been input correctly.

3. Place the ﬁles molclock1.txt and molclock2.txt in a directory
    from which you can read them into R. As in Exercise 1, use the
    RStudio menu to input each of these, then using read.table()
    directly to achieve the same result. Check, in each case, that data
    have been input correctly.

    Use the function save() to save molclock1, into an R image ﬁle.
    Delete the data frame molclock1, and check that you can recover
    the data by loading the image ﬁle.

4. The following counts, for each species, the number of missing val-
    ues for the column root of the data frame DAAG::rainforest:

    library(DAAG)
    with(rainforest, table(complete.cases(root), species))

    For each species, how many rows are “complete”, i.e., have no
    values that are missing?

5. For each column of the data frame MASS::Pima.tr2, determine
    the number of missing values.
42 learning and exploring r

6. The function dim() returns the dimensions (a vector that has the
    number of rows, then number of columns) of data frames and
    matrices. Use this function to ﬁnd the number of rows in the data
    frames tinting, possum and possumsites (all in the DAAG
    package).

7. Use mean() and range() to ﬁnd the mean and range of:

(a) the numbers 1, 2, . . . , 21                                           The datasets package that has the data
                                                                           frame women is by default attached
(b) the sample of 50 random normal values, that can be generated           when R is started.
     from a normaL distribution with mean 0 and variance 1 using
     the assignment y <- rnorm(50).

(c) the columns height and weight in the data frame women.

  Repeat (b) several times, on each occasion generating a nwe set of
  50 random numbers.

8. Repeat exercise 6, now applying the functions median() and
    sum().

9. Extract the following subsets from the data frame DAAG::ais

(a) Extract the data for the rowers.

(b) Extract the data for the rowers, the netballers and the tennis
     players.

(c) Extract the data for the female basketballers and rowers.

10. Use head() to check the names of the columns, and the ﬁrst
     few rows of data, in the data frame DAAG::rainforest. Use
     table(rainforest$species) to check the names and numbers
     of each species that are present in the data. The following extracts
     the rows for the species Acmena smithii

     Acmena <- subset(rainforest, species=="Acmena smithii")

The following extracts the rows for the species Acacia
mabellae and Acmena smithii:

                     AcSpecies <- subset(rainforest, species %in% c("Acacia mabellae",
                                                                                               "Acmena smithii"))

Now extract the rows for all species except C. fraseri.
3
Examples — Data analysis with R
44 learning and exploring r

Scatterplot   Scatterplot matrices can give useful insights on
matrices      data that will be used for regression or related
              calculations.

Transformation Data often require transformation prior to entry
                      into a regression model.

Model         Fitting a regression or other such model gives,
objects       in the ﬁrst place, a model object.

Generic       plot(), print() and summary() are examples
functions     of generic functions. With a dataframe as
              argument plot() gives a scatterplot matrix.
              With an lm object, it gives diagnostic plots.

Extractor     Use an extractor function to extract output from
function      a model object. Extractor fucntions are generic
              functions

List objects  An lm model object is a list object. Lists are
              used extensively in R.

    This chapter will use examples to illustrate common issues in         Issues that will be noted include
the exploration of data and the ﬁtting of regression models. It will      the use of generic functions such
round out the discussion of Chapters 1 and 2 by adding some further       as plot() and print(), the way
important technical details.                                              that regression model objects are
                                                                          structured, and the use of extractor
Notation, when referring to datasets                                      functions to extract information from
                                                                          model objects.
Data will be used that is taken from several diﬀerent R packages.
The notation MASS::mammals, which can be used in code as well
as in the textual description, makes it clear that the dataset mammals
that is required is from the MASS package. Should another attached
package happen to have a dataset mammals, there is no risk of confu-
sion.

3.1 Science, statistics, and R

How does statistical analysis ﬁt into the wider scientiﬁc enterprise?
While not a central focus of the present notes, the issues that will
now be noted are too important to be ignored.

    The R system is an enabler that allows users to do eﬀective data
analysis, and much else besides. These notes hint at its scope, pri-
marily for data manipulation, for data analysis, and for graphics.
Note, however, the chapters on map overlays and on text mining
— these extend into areas that would not ordinarily be described as
"data analysis".

    For the purposes of this next, the terms "data science" and "statis-
tics" are diﬀerent names for an endeavour whose concern is to ex-
tract meaning from data, leading for example to results that might
examples — data analysis with r 45

 be reported in a scientiﬁc paper, or that might form the basis for a       1 Green et al. (1996)
 business or government policy. Statistical issues and ideas are funda-
 mental to any use of data to make generalizations that extend beyond
 the particular data that have been collected, or that are otherwise
 available. They are fundamental, in that sense, to any scientiﬁc use
 of data. It is, at the same time, important to acknowledge that there
 are strict limits on what statistical analysis can achieve. Statistical
 analysis is a partner to, and not a substitute for, robust scientiﬁc pro-
 cesses. The use of experimental data provides the simplest context in
 which to explore this point further.

     For experimental work, over and above what may emerge from
 a statistical analsysis, the demand is that results be replicable. Lab-
 oratory studies have repeatedly shown shown that drinking regular
 caﬀeinated coﬀee increases blood pressure, though with minimal
 long term eﬀects.1 It is accepted that there is this eﬀect, not from
 the statistical analysis of results from any individual trial, but be-
 cause the eﬀect has been demonstrated in repeated trials. The role of
 statistical analysis has been:

1. to demonstrate that, collating the evidence from repeated trials, the
    eﬀect does appear real;

2. to assess the magnitude of the eﬀect.

     Worldwide, hundreds of thousands of randomised trials are con-
 ducted annually. What do they tell us? In clinical medicine, follow-
 up trials are common, and clear conclusions will often emerge from
 the careful collation of evidence that, in important cases, is likely to
 follow. In many other areas follow-up trials have until recently been
 uncommon. This is now changing, and for good reason. Independent
 replication of the experimental process provides checks on the total
 experimental process, including the statistical analysis. It is unlikely
 that the same mistakes in experimental procedure and/or statistical
 analysis will be repeated.

     Papers that had a key role in getting attention to reproducibility
 concerns have been Prinz et al. (2011) and (Begley and Ellis, 2012),
 the ﬁrst (6 out of 53 "landmark" studies reproduced) relating to drug
 trials, and the second (19 out of 65 "seminal" studies) to cancer drug
 trials. Since those studies appeared, results have appeared from sys-
 tematic attempts to reproduce published work in psychology (around
 40%), in laboratory economics (11 of 18), and in social science (12
 of 18). These replication rates are so low, in these areas, that they
 make nonsense of citations to published individual trial results as
 evidence that a claimed eﬀect has been scientiﬁcally demonstrated.

     Many of the problems that these studies identify extend, also,
 into research and associated analyses that works with observational
 data. In any attempt to draw hard conclusions from observational
 data, in a case where the aim is to compare two groups, there are
 certain to be many more diﬀerences than the diﬀerence that is of
 interest. One application of regression methods is to do "covariate
46 learning and exploring r

adjustments". The limitations of such an approach are not as widely
understood as they should be. There has to be conﬁdence that all
relevant covariates are accounted for, that they are measured with
adequate accuracy, and that the form of the adjustment (e.g., x, or
log(x), or x2) is close to correct.

    In a hard-hitting paper titled "Cargo-cult statistics and scien-
tiﬁc crisis", Stark and Saltelli (2018) comment, quoting also from
Edwards and Roy (2017):

    While some argue that there is no crisis (or at least not a systemic problem),
    bad incentives, bad scientiﬁc practices, outdated methods of vetting and dis-
    seminating results, and techno-science appear to be producing misleading and
    incorrect results. This might produce crisis of biblical proportions: as Ed-
    wards and Roy write: “If a critical mass of scientists become untrustworthy, a
    tipping point is possible in which the scientiﬁc enterprise itself becomes inher-
    ently corrupt and public trust is lost, risking a new dark age with devastating
    consequences to humanity.”

Statistical issues are then front and central in what many are iden-
tifying as a crisis, but are not the whole story. The crisis is one that
scientists and statisticians need to tackle in partnership.

    In a paper that deserves much more attention than it has received,
(Tukey, 1997), John W Tukey argued that, as part of the process of
ﬁtting a model and forming a conclusion, there should be incisive
and informed critique of the data used, of the model, and of the
inferences made. It is important that analysts search out available
information about the processes that generated the data, and consider
critically how this may aﬀect the reliance placed on it. Other speciﬁc
types of challenge (this list is longer than Tukey’s) may include:

• For experiments, is the design open to criticism?
• Look for biases in processes that generated the data.
• Look for inadequacies in laboratory procedure.
• Use all relevant graphical or other summary checks to critique the

   model that underpins the analysis.
• Where possible, check the performance of the model on test data

   that reﬂects the manner of use of results. (If for example predic-
   tions are made that will be applied a year into the future, check
   how predictions made a year ahead panned out for historical data.)
• For experimental data, have the work replicated independently
   by another research group, from generation of data through to
   analysis.

Exposure to diverse challenges will build (or destroy!) conﬁdence
in model-based inferences. We should trust those results that have
withstood thorough and informed challenge.

Where does R ﬁt in?

R clearly has a huge range of abilities for manipulating data, ﬁtting
and checking statistical models, and for using graphs and tables
                                                                                           examples — data analysis with r 47

to present results. More than this, it has extensive reproducible re-
porting abilities that can be used to allow others to repeat the data
manipulation, analysis, and steps in the processing of output that
have led to an eventual paper or report. A ﬁle is provided that mixes
code with the text for the eventual document, and that is then pro-
cessed ("woven" or "knitted") to provide the ﬁnal document, com-
plete with analysis output, tables, graphs, and code (if any) that is
to be included in the ﬁnal document. This makes it straightforward
for referees, or for anyone with an interest in the work, to check the
analysis and/or try modiﬁcations. The publication of data and code
is an important step on the way to making results more open and
transparent, and encouraging informed critique.

3.2 The Uses of Scatterplots

 ## Below, the dataset MASS::mammals will be required                    Among other issues, is there a wide
 library(MASS, quietly=TRUE)                                             enough spread of distinct values that
                                                                         data can be treated as continuous.
3.2.1 Transformation to an appropriate scale
                                                                                        A: Unlogged data
A ﬁrst step is to elicit basic information on the columns in the data,
including information on relationships between explanatory vari-                                                                                 q
ables. Is it desirable to transform one or more variables?
                                                                                5000
    Transformations are helpful that ensure, if possible, that:
                                                                                4000                   q
• All columns have a distribution that is reasonably well spread out                                   3000
   over the whole range of values, i.e., it is unsatisfactory to have    brain  3000
   most values squashed together at one end of the range, with a
   small number of very small or very large values occupying the                2000    q
   remaining part of the range.                                                 1000    qqqqqqqqqqqqq

• Relationships between columns are roughly linear.                                  0
• the scatter about any relationship is similar across the whole range
                                                                                        0 1000               5000
   of values.
                                                                                                       body
It may happen that the one transformation, often a logarithmic trans-
formation, will achieve all these at the same time.                                     B: Log scales (both axes)

    The scatterplot in Figure 3.1A, showing data from the dataset                                                                                qq
MASS::mammals, is is an extreme version of the common situation
where positive (or non-zero) values are squashed together in the         brain  1e+03                                         q
lower part of the range, with a tail out to the right. Such a distribu-         1e+02                                         qq qqqqq
tion is said to be “skewed to the right”.                                       1e+01               qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq
                                                                                1e+00             qqq
    Code for Figure 3.1A                                                        1e−01
                                                                                          q qq q
 plot(brain ~ body, data=mammals)                                                       q
 mtext(side=3, line=0.5, adj=0,

            "A: Unlogged data", cex=1.1)

    Figure 3.1B shows the scatterplot for the logged data. Code for
Figure 3.1B is:

 plot(brain ~ body, data=mammals , log="xy")

                                                                                        1e−02 1e+00 1e+02 1e+04

                                                                                                  body

                                                                         Figure 3.1: Brain weight (g) versus
                                                                         Body weight (kg), for 62 species of
                                                                         mammal. Panel A plots the unlogged
                                                                         data, while Panel B has log scales for
                                                                         both axes, but with axis labels in the
48 learning and exploring r

mtext(side=3, line=0.5, adj=0,
           "B: Log scales (both axes)", cex=1.1)

    Where, as in Figure 3.1A, values are concentrated at one end of
the range, the small number (perhaps one or two) of values that lie at
the other end of the range will, in a straight line regression with that
column as the only explanatory variable, be a leverage point. When
it is one explanatory variable among several, those values will have
an overly large say in determining the coeﬃcient for that variable.

    As happened here, a logarithmic transformation will often re-
move much or all of the skew. Also, as happened here, such transfor-
mations often bring the added bonus that relationships between the
resulting variables are approximately linear.

3.2.2 The Uses of Scatterplot Matrices                                              The datasets package is, in an oﬀ-
                                                                                    the-shelf installation, attached when R
Subsequent chapters will make extensive use of scatterplot matrices.                starts.
A scatterplot matrix plots every column against every other column,
with the result in the layout used for correlation matrices. Figure 3.2
shows a scatterplot matrix for the datasets::trees dataset.

Interpreting Scatterplot Matrices:                                                            65 70 75 80 85                                               q 20
For identifying the axes for each panel                                                                                       q                                 18
                                                                                                                                                                16
- look across the row to the diagonal to identify the                                                            qqq                                  qqq       14
   variable on the vertical axis.                                                                     qq                                       qq               12
                                                                                                                                       qqqqqqqq                 10
- look up or down the column to the diagonal for the                         Girth            q           q     qq     qq          qqqqqqqqqqq                  8
   variable on the horizontal axis.                                                                   q                          qq
                                                                                                          q                                                q
Each below diagonal panel is the mirror image of the                                             q q q qqq qqq q
corresponding above diagonal panel.
                                                                                              qq q
## Code used for the plot
plot(trees, cex.labels=1.5)                                                     qq         q                                         qq

   # Calls pairs(trees)                                85                 q           qqq                                           q           qqqq
                                                       80    qqq                    q                                               qqq
                                                       75                       q                                                   qqqqq  q
                                                       70 q                     q                                                           qq
                                                                          qqqqq q                  Height                                    q

                                                             q qq                                                                q  qq     q
                                                                                                                                      q
                                                                             q

                                                       65 q q                   q                                                qq  q
                                                              q                                                                  q

                                                                                           qq

                                                                                qqq                             qqq                                        70
                                                                                  q                             q                                          60
                                                                                                                                                           50
                                                                             q                               q                       Volume                40
                                                                   q qqq q                            qq qq q                                              30
                                                             qqqqqqqqqqqqq                                             q                                   20
                                                       qqq                                    q       q   qqqq  qqq q                                      10
                                                                                                q  q   q

                                                                                              qq q

                                                       8 10 14 18                                                                10 30 50 70

     Notice that plot(), called with the dataframe trees, has in                    Figure 3.2: Scatterplot matrix for the
 turn called the plot method for a data frame, i.e., it has called                  trees data, obtained using the default
 plot.data.frame() which has in turn called the function                            plot() method for data frames.
 pairs().                                                                           The scatterplot matrix is a graphical
                                                                                    counterpart of the correlation matrix.
     The scatterplot matrix may be examined, if there are enough
 points, for evidence of:                                                           The scatterplot matrix is best used
                                                                                    as an initial coarse screening device.
1. Strong clustering in the data, and/or obvious outliers;                          Skewness in the individual distribu-
                                                                                    tions is better checked using plots of
2. Clear non-linear relationships, so that a correlation will underesti-            density estimates.
    mate the strength of any relationship;

3. Severely skewed distributions, so that the correlation is a biased
    measure of the strength of relationship.
                                                                         examples — data analysis with r 49

3.3 World record times for track and ﬁeld events

The ﬁrst example is for world track and road record times,               Note also the use of these data in
as at 9th August 2006. Data, copied down from the web page               the exercise at the end of Chapter 2
http://www.gbrathletics.com/wrec.htm, are in the dataset                 (Section 1.9.2)
DAAG::worldRecords.

Data exploration

First, use str() to get information on the data frame columns:

library(DAAG, quietly=TRUE)

str(worldRecords , vec.len=3)

'data.frame ': 40 obs. of 5 variables:

$ Distance : num 0.1 0.15 0.2 0.3 0.4 0.5 0.6 0.8 ...

$ roadORtrack: Factor w/ 2 levels "road","track": 2 2 2 2 2 2 2 2 ...

$ Place  : chr "Athens" "Cassino" "Atlanta" ...

$ Time   : num 0.163 0.247 0.322 0.514 ...

$ Date   : Date, format: "2005-06-14" "1983-05-22" ...

    Distinguishing points for track events from those for road events                   road q            track q
is easiest if we use lattice graphics, as in Figure 3.3.
                                                                               1500                                         q
## Code
library(lattice)                                                               1000
xyplot(Time ~ Distance , scales=list(tck=0.5),
                                                                         Time                         qq
            groups=roadORtrack , data=worldRecords ,
            auto.key=list(columns=2), aspect=1)                                500                 q
## On a a colour device the default is to use                                     0
## different colours, not different symbols,                                                    q
## to distinguish groups.                                                                     q
                                                                                     qqqqqqqqqqq
    Clearly increases in Time are not proportional to increases in
Distance. Indeed, such a model does not make sense; velocity                         0 50 100 150 200 250 300
decreases as the length of the race increases. Proportionality when
logarithmic scales are used for the two variables does make sense.                                 Distance

    Figure 3.4 uses logarithmic scales on both axes. The two panels      Figure 3.3: World record times versus
diﬀer only in the labeling of the scales. The left panel uses labels on  distance, for ﬁeld and road events.
scales of loge, while the right panel has labels in the orginal units.
Notice the use of auto.key to obtain a key.

## Code for Left panel
xyplot(log(Time) ~ log(Distance),

            groups=roadORtrack , data=worldRecords ,
            scales=list(tck=0.5),
            auto.key=list(columns=2), aspect=1)
## Right panel
xyplot(Time ~ Distance, groups=roadORtrack ,
            data=worldRecords ,
            scales=list(log=10, tck=0.5),
            auto.key=list(columns=2), aspect=1)
50 learning and exploring r

   road q                track q                                 road q  track q                                       Figure 3.4: World record times versus
                                                                                                                       distance, for ﬁeld and road events,
                                   q                       10^3                                                     q  using logarithmic scales. The left
                                                           10^2                                                        panel uses labels on scales of loge,
6q                              q                          10^1                                                 q      while in the right panel, labeling is in
                                                           10^0                                              q         the orginal units, expressed as powers
                         qq                                                                             qq             of 10.
                                                                                          qqqqqqqqqqq
log(Time)                                                                             qq
                                                     Time                         qqq
4 qqqqqqqqqqq                                                           qqqqqq
                     qq                                            qq
2                qqq                                             q

0 qqqqqq
             qq

−2 q

   −2 0 2 4 6                                                    10^−1 10^0 10^1 10^2

                 log(Distance)                                              Distance

Fitting a regression line

The plots suggest that a line is a good ﬁt. Note however that the                                                      The name lm is a mnemonic for linear
data span a huge range of distances. The ratio of longest to shortest                                                  model.
distance is almost 3000:1. Departures from the line are of the order
of 15% at the upper end of the range, but are so small relative to this                                                The equation gives predicted times:
huge range that they are not obvious.                                                                                   Time = e0.7316 × Distance1.1248
                                                                                                                                 = 2.08 × Distance1.1248
    The following uses the function lm() to ﬁt a straight line ﬁt to
the logged data, then extracting the regression coeﬃcients:                                                            This implies, as would be expected,
                                                                                                                       that kilometers per minute increase
worldrec.lm <- lm(log(Time) ~ log(Distance),                                                                           with increasing distance. Fitting a line
                                data=worldRecords)                                                                     to points that are on a log scale thus
                                                                                                                       allows an immediate interpretation.
coef(worldrec.lm)
                                                                                                                       The name worldrec.lm is used to
(Intercept) log(Distance)                                                                                              indicate that this is an lm object, with
                                                                                                                       data from worldRecords. Use any
   0.7316                       1.1248                                                                                 name that seems helpful!
                                                                                                                       Plot points; add line:
There is no diﬀerence that can be detected visually between the
track races and the road races. Careful analysis will in fact ﬁnd no                                                   plot(log(Time) ~ log(Distance),
diﬀerence.                                                                                                                      data = worldRecords)

3.3.1 Summary information from model objects                                                                           abline(worldrec.lm)

In order to avoid recalculation of the model information each time                                                     By default, there are four “diagnostic”
that some diﬀerent information is required, we store the result from                                                   plots.
the lm() calculation in the model object worldrec.lm.

    Note that the function abline() can be used with the model
object as argument to add a line to the plot of log(Time) against
log(Distance).

Diagnostic plots

Insight into the adequacy of the line can be obtained by examining
the “diagnostic” plots, obtained by “plotting” the model object.
Figure 3.5 following shows the ﬁrst and last of the default plots:

## Code
plot(worldrec.lm , which=c(1,5),

         sub.caption = rep ("" ,2))
                                                                                                                             examples — data analysis with r 51

             Residuals vs Fitted                                                    Residuals vs Leverage                               Figure 3.5: First and last of the default
                                                                                                                                        diagnostic plots, from the linear
Residuals0.15                                     40q                                                                              1    model for log(record time) versus
                                                      Standardized residuals  3 40q                                                     log(distance), for ﬁeld and road
0.10                                              q39                                                                                   events.
                                                  q24                                                                              0.5
                                                                              2 q39                                                     2 A diﬀerence of 0.05 on a scale
                                                                                                                                        of loge translates to a diﬀerence of
                                                                                                              q24                       just over 5%. A diﬀerence of 0.15
                                                                                                                                        translates to a diﬀerence of just over
 0.05  q     qqqq qqq qq qqqq                                                  1           qqq  q      q                  q             16%, i.e., slightly more than 15%.
 0.00     q                     qq                                                     qqqqq      q  q
−0.05                                       q qq                               0
−0.10                                     q                                                       q    qq
                                                                              −1
                            qq q                                                       qq q                            q
                            q qqqqq                                           −2       qq q                      q
                  q                                                              0.00                      q
                q
             q                                                                         qqqqqq                 q

                                    qqqq                                               qCqqqook's distance

       −2 0 2 4 6                                                                      0.04 0.08 0.12

               Fitted values                                                             Leverage

    Panel A is designed to give an indication whether the relationship
really is linear, or whether there is some further systematic com-
ponent that should perhaps be modeled. It does show systematic
diﬀerences from a line.

    The largest diﬀerence is more than a 15% diﬀerence.2 There are
mechanisms for using a smooth curve to account for the diﬀerences
from a line, if these are thought important enough to model.

    The plot in panel B allows an assessment of the extent to which
individual points are inﬂuencing the ﬁtted line. Observation 40 does
have both a very large leverage and a large Cook’s distance. The plot
on the left makes it clear that this is the point with the largest ﬁtted
time. Observation 40 is for a 24h race, or 1440 min. Examine

worldRecords["40", ]

       Distance roadORtrack Place Time                                                          Date

40 290.2                                  road Basle 1440 1998-05-03

3.3.2 The model object

Functions that are commonly used to get information about model
objects are: print(), summary() and plot(). These are all
generic functions. The eﬀect of the function depends on the class
of object that is printed (ie, by default, displayed on the screen) or or
plotted, or summarized.

    The function print() may display relatively terse output, while
summary() may display more extensive output. This varies from
one type of model object to another.

    Compare the outputs from the following:

print(worldrec.lm) # Alternatively , type worldrec.lm

Call:
lm(formula = log(Time) ∼ log(Distance), data = worldRecords)

Coefficients:

(Intercept) log(Distance)

                     0.732                             1.125
52 learning and exploring r
summary(worldrec.lm)

Call:
lm(formula = log(Time) ∼ log(Distance), data = worldRecords)

Residuals:
       Min 1Q Median 3Q Max

-0.0807 -0.0497 0.0028 0.0377 0.1627

Coefficients:

               Estimate Std. Error t value Pr(>|t|)

(Intercept) 0.73160 0.01241           59 <2e-16

log(Distance) 1.12475 0.00437        257 <2e-16

Residual standard error: 0.0565 on 38 degrees of freedom

Multiple R2 : 0.999 ,  Adjusted R2 : 0.999

F-statistic: 6.63e+04 on 1 and 38 DF, p-value: <2e-16

    Used with lm objects, print() calls print.lm(), while                 Internally, summary(wtvol.lm)
summary() calls summary.lm(). Note that typing worldrec.lm                calls UseMethod("summary"). As
has the same eﬀect as print(worldrec.lm).                                 wtvol.lm is an lm object, this calls
                                                                          summary.lm().

3.3.3 The lm model object is a list

The model object is actually a list. Here are the names of the list
elements:

names(worldrec.lm)

[1] "coefficients" "residuals"       "effects"
                                     "qr"
"rank"                               "terms"

[5] "fitted.values" "assign"

"df.residual"

[9] "xlevels"          "call"

"model"

These diﬀerent list elements hold very diﬀerent classes and dimen-
sions (or lengths) of object. Hence the use of a list; any collection of
diﬀerent R objects can be brought together into a list.

    The following is a check on the model call:

worldrec.lm$call

lm(formula = log(Time) ∼ log(Distance), data = worldRecords)

    Commonly required information is best accessed using generic          Use extractor function coef():
extractor functions. Above, attention was drawn to print(),
summary() and plot(). Other commonly used extractor func-                 coef(worldrec.lm)
tions are residuals(), coefficients(), and fitted.values().
These can be abbreviated to resid(), coef(), and fitted().

3.4 Regression with two explanatory variables

The dataset nihills in the DAAG package will be used for a regres-
sion ﬁt in Section 8.6. This has record times for Northern Ireland
                                                                                                                                         examples — data analysis with r 53

mountain races. Overview details of the data are:

str(nihills)

'data.frame ':                               23 obs. of 4 variables:
 $ dist : num                               7.5 4.2 5.9 6.8 5 4.8 4.3 3 2.5 12 ...
 $ climb: int                               1740 1110 1210 3300 1200 950 1600 1500 1500 5080 ...
 $ time : num                               0.858 0.467 0.703 1.039 0.541 ...
 $ timef: num                               1.064 0.623 0.887 1.214 0.637 ...

    Figure 3.6 uses the lattice function splom() (from the lattice                                                                                                  The function splom() is a lattice
package) to give scatterplot matrices, one for the unlogged data,                                                                                                   alternative to pairs(), giving a
and the other for the logged data. The left panel shows the unlogged                                                                                                diﬀerent panel layout.
data, while the right panel shows the logged data:

A: Untransformed data                                                                                        B: Log transformed data

                         q                             q                     q6                                                          qqq
                                                                                  5
                                                                          q                            456                                                                                       1.5 0.5 1.5
                                                                      q
                                                           qqqqqqqqqqq           4                                                    q                                 q                              q       1.0
                                                                                                                                     q                           q                                 q
                                                       q4                            timef 3                                                                                                                  0.5 ltimef
                      q                          q          3                                                q qqqqqqqqqqqqqqqqq                qqqqqqqqqqqqqqq  qq                qqqqqqqqqqqqqqqq
                    q                       q                                                          2       q                             q                   q             q                                             0.0
                                                                                                                                         q                                 q
qqqqqqqqqqqqqqqqq           qqqqqqqqqqqqqq  qq                                   123 1                                                                                                                    −1.0 0.0 −0.5
                                            q                                                                                                                                                                               −1.0

                         q                                                                                q                                                                                                                                    q

                                                                             34                                                                                               1.0 0.00.51.0

                                                             time                                                                  q                                    q     0.5                                                    q
                                                                                                                                  q                              q                                                                 q
                                                          12                                                                                                                  0.0 ltime 0.0
                      q                          q                           2q                                 q             q                     q            qq                                                       qqq       0.994
                    q                                                                                                          q            qqqqqqqqqqqqqq       q                         −0.5                    qqqqqqqqqqqqq
                                            q    6000                                          q             q qqqqqqqqqqqqqqq           q                                 −1.0 0.0 −1.0                       q

qqqqqqqqqqqqqqqqqq          qqqqqqqqqqqqqq  qq                               1 qqqqqqqqqqq
                                            q
                                                                                 q
                                                                                                             q
                                                                                                  q
                         q                                                              qqq q             q                           q 9.0                                                                 q                                q
                                                                                     qqqqqqqqqqq          q                                          8.0 8.5 9.0                                   q                               q
                              8000                                               q
                                                                                                                                  q 8.5
                             6000                                                              qq
                    q                                                    q           qqqqqqqqqqqqqqqq                        q    q      8.0 lclimb 8.0                          q          q   q                         q        q
                                 climb4000                                                                          qq                                                                     q                         qq
                                                             qqq q                                                                                     7.5                                                                           0.92
   q qq             q       2000 2000                     qqqqqqqqqqqqq                                      q qqqqqqqqqqqqq q           7.07.58.0 7.0                        qqqqqqqqqqqqqqqq  0.924 qqqqqqqqqqqqqqqq
qqqqqqqqqqqqq q                                                                                                q                                                           q                                    q                               q

                                                       q                                                       3.0                                                         qq

      10 15                                                                                                  2.5 2.0 2.5 3.0                                     qq                             qq                                 qq
15
                                            qq                      qq                                         2.0 ldist 2.0             qq                                                qq                        qq
10 dist 10                                                qqqqqqqqqqqqqqqq
                                                                                                                              1.5        qqqqqqqqqqq             q                  q      q                      qqqqqqqqqqqqq q
                                q                                                                            1.0 1.5 2.0 1.0                                     q            qqqqqqqqqqq
5 10 5                      qqqqqqqqqqqqqq    q                                                                                                      qq                                                           q
                                            q                                                                                            qq                                   q                                   q
                                            q                                                                                                     q                  0.78  q  q                 0.945          q  q                0.933

    The following panel function was used to show the correlations:                                                                                                 Figure 3.6: Scatterplot matrices for
                                                                                                                                                                    the Northern Ireland mountain racing
showcorr <- function(x,y,...){                                                                                                                                      data. The left panel is for the unlogged
       panel.xyplot(x,y,...)                                                                                                                                        data, while the right panel is for the
       xy <- current.panel.limits()                                                                                                                                 logged data. Code has been added that
       rho <- paste(round(cor(x,y),3))                                                                                                                              shows the correlations, in the lower
       eps <- 0.035*diff(range(y))                                                                                                                                  panel.
       panel.text(max(x), min(y)+eps, rho,
                           pos=2, offset=-0.2)

}

    Code for the scatterplot matrix in the left panel is:

## Scatterplot matrix; unlogged data
library(lattice)
splom(~nihills, xlab="",

            main=list("A: Untransformed data", x=0,
            just="left", fontface="plain"))

    For the right panel, create a data frame from the logged data:
54 learning and exploring r                                               Unlike paste(), the function
                                                                          paste0() does not leave spaces
lognihills <- log(nihills)                                                between text strings that it pastes
names(lognihills) <- paste0("l", names(nihills))                          together.
## Scatterplot matrix; log scales
splom(~ lognihills , lower.panel=showcorr, xlab="",

            main=list("B: Log transformed data", x=0,
            just="left", fontface="plain"))

    Note that the data are positively skewed, i.e., there is a long tail
to the right, for all variables. For such data, a logarithmic transfor-
mation often gives more nearly linear relationships. The relation-
ships between explanatory variables, and between the dependent
variable and explanatory variables, are closer to linear when loga-
rithmic scales are used. Just as importantly, issues with large lever-
age, so that the point for the largest data values has a much greater
leverage and hence much greater inﬂuence than other points on the
the ﬁtted regression, are greatly reduced.

    Notice also that the correlation of 0.913 between climb and
dist in the left panel of Figure 3.6 is very diﬀerent from the corre-
lation of 0.78 between lclimb and ldist in the right panel. Corre-
lations where distributions are highly skew are not comparable with
correlations where distributions are more nearly symmetric. The
statistical properties are diﬀerent.

    The following regresses log(time) on log(climb) and
log(dist):

nihills.lm <- lm(ltime ~ lclimb + ldist,
                               data=lognihills)

3.5 One-way Comparisons                                                   A common strategy for getting a
                                                                          valid comparison is to grow the
The dataset tomato has weights of plants that were grown under one        plants in separate pots, with a random
of four diﬀerent sets of experimental comditions. Five plants were        arrangement of pots.
grown under each of the treatments:
                                                                          Notice that “water only” is made the
- water only                                                              reference level. This choice makes
                                                                          best sense for the analysis of variance
- conc nutrient                                                           calculations that appear below.

- 2-4-D + conc nutrient                                                   Observe that, to get estimates and SEs
                                                                          of treatment eﬀects, tomato.aov
- x conc nutrient                                                         can be treated as an lm (regression)
                                                                          object.
Figure 3.7, created using the function quickplot() from the gg-
plot2 package, shows the plant weights. Are the apparent diﬀerences
between treatments large enough that they can be distinguished sta-
tistically?

## Code
library(ggplot2)
tomato <- within(DAAG::tomato,

                               trt <- relevel(trt, ref="water only"))
quickplot(weight , trt, data=tomato ,

                  xlab="Weight (g)", ylab="")
conc nutrient                 q qq                     q             examples — data analysis with r 55
                                                                q Figure 3.7: Weights (g) of tomato
3x conc nutrient q q q q q q
                                                                              plants grown under four diﬀerent
2−4−D + conc nutrient  qq  q      qq                                          treatments.

water only                    qq      q                   q      3.0

                           1.0 1.5 2.0                     2.5

                                           Weight (g)

    The command aov(), followed by a call to summary.lm(), can
be used to analyse these data, thus:

tomato.aov <- aov(weight ~ trt, data=tomato)
round(coef(summary.lm(tomato.aov)), 3)

                           Estimate Std. Error t value Pr(>|t|)

(Intercept)                   1.683      0.187 9.019 0.000

trt2 -4-D + conc nutrient -0.358         0.264 -1.358 0.190

trt3x conc nutrient           -0.700     0.264 -2.652 0.015

trtconc nutrient              0.067      0.264 0.253 0.803

Because we made “water only” the reference level,
“(Intercept)” is the mean for water only, and the other coef-
ﬁcients are for diﬀerences from water only.

A randomized block comparison                                            3 In language used originally in con-
                                                                         nection with agricultural ﬁeld trials,
Growing conditions in a glasshouse or growth chamber — tempera-          where the comparison was repeated on
ture, humidity and air movement — will not be totally uniform. This      diﬀerent blocks of land, each diﬀerent
makes it desirable to do several repeats of the comparison between       location is a "block".
treatments3, with conditions within each repeat ("block") kept as
uniform as possible. Each diﬀerent "block" may for example be a          The eﬀect of an appropriate choice of
diﬀerent part of the glasshouse or growth chamber.                       clocks, then carrying out an analysis
                                                                         that accounts for block eﬀects, is to
    The dataset DAAG::rice is from an experiment where there were        allow a more precise comparison
six treatment combinations — three types of fertilizer were applied      between treatments.
to each of two varieties of rice plant. There were two repeats, i.e.,
two blocks.

    For these data, Figure 3.8 gives a clear picture of the result. For
fertilizers NH4Cl and NH4NO3, any diﬀerence between the varieties
is inconsequential. There is strong “interaction” between fert and
variety. A formal analysis, accounting for block diﬀerences, will
conﬁrm what seems already rather clear.

3.6 Time series – Australian annual climate data                         Data are from the website
                                                                           http://www.bom.gov.au/
The data frame bomregions2012 from the DAAG package has
annual rainfall data, both an Australian average and broken down by      climate/change/
location within Australia, for 1900 – 2012. Figure 3.9 shows annual
rainfall in the Murray-Darling basin, plotted against year.
56 learning and exploring r

              mean of ShootDryMass                                                       variety                         Figure 3.8: Interaction plot for the
                                                                                                                         terms fert and variety, with
                                    100                                                                                  ShootDryMass as the dependent
                                                                                                                         variable. Notice that for fertilizer F10,
                                                                                                    wt                   there is a huge variety diﬀerence in
                                     80 ANU843                                                                           the response. For the other fertilizers,
                                                                                                                         there is no diﬀerence of consequence.
                                     60

                                     40

                                     20

                                    F10           NH4Cl                    NH4NO3

                                                        fert

## Code
library(DAAG)
with(rice, interaction.plot(x.factor=fert,

                                                   trace.factor=variety ,
                                                  ShootDryMass ,
                                                  cex.lab=1.4))

         800                                                     qq                                               q      Figure 3.9: Annual rainfall in the
                                                                                                                         Australian Murray-Darling Basin.
         700 q                                                                                                           by year. The lowess() function is
                                                                                         q                               used to The dashed curve with f=2/3
                                                                                            qq                           captures the overall trend, while the
mdbRain             q               q  q                                q                                                solid curve with f=0.1 captures trends
         600                        q                            q                                                    q  on a scale of around eleven years.
         500                                                                                      qqqqqqqqqq             (10% of the 113 year range from 1900
         400    q qq                   qq  q                       qq      q             qq    q                         to 2012 is a little more than 11 years.)
         300          q                           q              q                           q
                                                                              q    qqqq                               q
              q qqqq q                      qqq q                          qqqq q
              q qq
                                        qqqq         q                        q                   q         q  qqqqq
                                               q         q                                       q
                                                     qqq          q
                                       q                         q                                    q
                                                                                            qq
                                                                                             qq                qq

                                    q             q
                                    q q qq q q                                      q
                                       qq                                                                q
                                                              q        qq
                                                                                q            q qq

              q

              1900                  1920          1940                 1960                 1980            2000

                                                                 Year
                                                                         examples — data analysis with r 57

## Code
library(DAAG)
plot(mdbRain ~ Year, data=bomregions2012)
## Calculate and plot curve showing long-term trend
with(bomregions2012 , lines(lowess(mdbRain ~ Year, f=2/3), lty=2))
## Calculate and plot curve of short-term trends
with(bomregions2012 , lines(lowess(mdbRain ~ Year, f=0.1),

                                                 lty=1, col="gray45"))

    The lowess() function has been used to ﬁt smooth curves,             For each smoothing window, a line
formed by moving a smoothing window across the data. The dashed          or other simple response function is
curve with f=2/3 (include 2/3 of the data in the smoothing window)       ﬁtted. Greatest weight to points near
captures the overall trend in the data. The choice of f=0.1 for the      the centre of the smoothing window,
solid curve has the eﬀect that somewhat more than ten years of data      with weights tailing oﬀ to zero at the
are used in determining each ﬁtted value on the smooth.                  window edge.

    This graph is exploratory. A next step might to model a correla-     The functions acf() and pacf()
tion structure in residuals from the overall trend. There are extensive  might be used to examine the correla-
abilities for this. For graphical exploration, note lag.plot() (plot     tion structure in the residuals.
series against lagged series).

    The cube root of average rainfall has a more symmetric distri-
bution than rainfall. Thus, use this in preference to average rainfall
when ﬁtting models.

 3.7 Exercises

1. Plot Time against Distance, for the worldRecords data. Ignor-
    ing the obvious curvature, ﬁt a straight line model. Use plot.lm
    to obtain diagnostic plots. What do you notice?

2. The data set LakeHuron (datasets package) has mean July aver-
    age water surface elevations (ft) for Lake Huron, for 1875-1972.
    The following reates a data frame that has the same information:

     Year=as(time(LakeHuron), "vector")
     huron <- data.frame(year=Year, mean.height=LakeHuron)

(a) Plot mean.height against year.                                       This plots the level in each year
(b) To see how each year’s mean level is related to the previous         against the level in the previous year.

     year’s mean level, use                                              For an explanation of the autocorrela-
                                                                         tion function, look up “Autocorrela-
       lag.plot(huron$mean.height)                                       tion” on Wikepedia.

(c) *Use the function acf() to plot the autocorrelation function.
     Compare with the result from the pacf() (partial autocorrela-
     tion). What do the graphs suggest?
58 learning and exploring r
4
Data Objects and Functions
60 learning and exploring r

Diﬀerent types of data objects:                                      Data objects and functions are two
                                                                     of several types of objects (others
Vectors These collect together elements of the same mode.            include model objects, formulae, and
            (Possible modes are "logical", "integer", "numeric",     expressions) that are available in R.
            "complex", "character" and "raw")                        Users can create and work with such
                                                                     objects in a user workspace. All can,
Factors Factors identify category levels in categorical data.        if the occasion demands, be treated as
            Modeling functions know how to represent factors.        data!
            (Factors do not quite manage to be vectors! Why?)
                                                                     1 Strictly, the vectors that we discuss
Data A list of columns – same length; modes may diﬀer.               here are atomic vectors. Their ele-
frame Data frames are a device for organizing data.                  ments are not, as happens with lists,
                                                                     wrappers for other language objects.
Lists      Lists group together an arbitrary set of objects          Common vector modes are logical,
           (Lists are recursive; elements of lists are lists.)       numeric and character. The 4 lines of
                                                                     code create vectors that are, in order:
NAs Use is.na() to check for NAs.                                    numeric, numeric, logical, character.

    We start this chapter by noting data objects that may appear as
columns of a data frame.

4.1 Column Data Objects – Vectors and Factors

Column objects is a convenient name for one-dimensional data
structures that can be included as columns in a data frame. This
includes vectors1, factors, and dates.

4.1.1 Vectors

Examples of vectors are

c(2,3,5,2,7,1)
3:10 # The numbers 3, 4,.., 10
c(TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, FALSE)
c("fig","mango","apple","prune")

    Use mode() to show the storage mode of an object, thus:

x <- c(TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, FALSE)
mode(x)

[1] "logical"

    The missing value symbol is NA. Subsection 4.1.3 will discuss
issues that arise when one or more vector elements is an NA.

Subsets of Vectors

There are four common ways to extract subsets of vectors.
    1. Specify the subscripts of elements that are to be extracted:

x <- c(3,11,8,15,12) # Assign to x the values

x[c(2,4)]           # Extract elements 2 and 4
                                                                         data objects and functions 61

[1] 11 15                                                                2 Mixing of positive and negative
                                                                         subscripts is not allowed.
Negative numbers may be used to omit elements:2
                                                                         Arithmetic relations that may be used
x <- c(3,11,8,15,12)                                                     for extraction of subsets are >=, ==,
x[-c(2,3)]                                                               != and %in%. The ﬁrst four compare
                                                                         magnitudes, == tests for equality, !=
[1] 3 15 12                                                              tests for inequality, and %in% tests
                                                                         whether any element matches.
    2. Specify a vector of logical values. The elements that are
extracted are those for which the logical value is TRUE. Thus suppose
we want to extract values of x that are greater than 10.

x>10 # Values are logical (TRUE or FALSE)

[1] FALSE TRUE FALSE TRUE TRUE

x[x > 10]
[1] 11 15 12

"John" %in% c("Jeff", "Alan", "John")

[1] TRUE

    3. Where elements have names, these can be used to extract
elements:

altitude <- c(Cambarville=800, Bellbird=300,
                         "Allyn River"=300,
                         "Whian Whian"=400,
                         Byrangery=200, Conondale=400,
                         Bulburin=600)

##
## Names can be used to extract elements
altitude[c("Cambarville", "Bellbird")]

Cambarville        Bellbird
              800           300

    4. Use subset(), with the vector as the ﬁrst argument, and a
logical statement that identiﬁes the elements to be extracted as the
second argument. For example:

subset(altitude, altitude >400)

Cambarville        Bulburin
              800           600

4.1.2 Factors                                                            Factors are an economical way to store
                                                                         vectors of repetitive text strings. By
Factors are column objects whose elements are integer values 1, 2,       default, when a vector of text strings
. . . , k, where k is the number of levels. They are distinguished from  becomes a column in a data frame, it
integer vectors by having the class factor and a levels attribute.       is incorporated as a factor.

    For example, create a character vector fruit, thus:
62 learning and exploring r

fruit <- c("fig","mango","apple","plum", "fig")

This might equally well be stored as a factor, thus:

fruitfac <- factor(fruit)

    Internally, the factor is stored as the integer vector 2, 3, 1, 4, 2.  Thus 1 is interpreted as "apple";
These numbers are interpreted according to the attributes table:           2:"fig"; 3:"mango"; 4:"plum".

123                              4                                         3 Where counts are tabulated by factor
                                                                           level, or lattice or other graphs have
"apple" "fig" "mango" "plum"                                               one panel per factor level, these are in
                                                                           order of the levels.
By default, the levels are taken in alphanumeric order.
    The function factor(), with the levels argument speciﬁed,

can be used both to specify the order of levels when the factor is
created, or to make a later change to the order.3 For example, the
following orders levels according to stated glycemic index:

glycInd <- c(apple=40, fig=35, mango=55, plum=25)
## Take levels in order of stated glycInd index
fruitfac <- factor(fruit,

                                  levels=names(sort(glycInd)))
levels(fruitfac)

[1] "plum" "fig" "apple" "mango"

unclass(fruitfac) # Examine stored values

[1] 2 4 3 1 2     "apple" "mango"                                          Mis-spelt name, example:
attr(,"levels")
[1] "plum" "fig"                                                           trt <- c("A","A","Control")
                                                                           trtfac <- factor(trt,
    Incorrect spelling of the level names generates missing values,
for the level that was mis-spelled. Use the labels argument if you            levels=c("control","A"))
wish to change the level names, but be careful to ensure that the          table(trtfac)
label names are in the correct order.
                                                                           trtfac       A
    In most places where the context seems to demand it, the integer       control      2
levels are translated into text strings, thus:
                                                                                     0
fruit <- c("fig","mango","apple", "plum","fig")
fruitfac <- factor(fruit)
fruitfac == "fig"

[1] TRUE FALSE FALSE FALSE TRUE

    Section 8.5 has detailed examples of the use of factors in model
formulae.

Ordered factors

In addition to factors, note the existence of ordered factors, created
using the function ordered(). For ordered factors, the order of
levels implies a relational ordering. For example:

windowTint <- ordered(rep(c("lo","med","hi"), 2),
                                        levels=c("lo","med","hi"))

windowTint
                                                                      data objects and functions 63

[1] lo med hi lo med hi
Levels: lo < med < hi

sum(windowTint > "lo")
[1] 4

Subsetting of factors

Consider the factor fruitfac that was created earlier:

fruitfac <- factor(c("fig","mango","apple","plum", "fig"))

We can remove elements with levels fig and plum thus:

ff2 <- fruitfac[!fruitfac %in% c("fig","plum")]
ff2

[1] mango apple
Levels: apple fig mango plum

table(ff2)

ff2       fig mango plum
apple        010

       1

The levels fig and plum remain, but with the table showing 0 values   Note also:
for these levels. Use the function droplevels() to remove levels
that are not present in the data:                                     table(droplevels(ff2))

droplevels(ff2)                                                       apple mango
                                                                             11

[1] mango apple
Levels: apple mango

Why is a factor not a vector?                                         Vectors can be concatenated (joined).
                                                                      Two or mare factors can be sensi-
Two factors that have diﬀerent levels vectors are diﬀerent types of   bly concatenated only if they have
object. Thus, formal concatenation of factors with diﬀerent levels    identical levels vectors.
vectors is handled by ﬁrst coercing both factors to integer vectors.
The integer vector that results is not, in most circumstances, mean-  Failure to understand the rules for
ingful or useful.                                                     calculations with NAs can lead to
                                                                      unwelcome surprises.
4.1.3 Missing Values, Inﬁnite Values and NaNs

Any arithmetic or logical operation with NA generates an NA. The
consequences are more far-reaching than might be immediately
obvious. Use is.na() to test for a missing value:

is.na(c(1, NA, 3, 0, NA))

[1] FALSE TRUE FALSE FALSE TRUE
64 learning and exploring r                                              The modeling function lm()
                                                                         accepts any of the arguments
    An expression such as c(1, NA, 3, 0, NA) == NA returns a             na.action=na.omit (omit),
vector of NAs, and cannot be used to test for missing values.            na.action=na.exclude (omit
                                                                         NAs when ﬁtting; replace by NAs when
c(1, NA, 3, 0, NA) == NA                                                 ﬁtted values and residuals are calcu-
                                                                         lated), and na.action=na.fail.
[1] NA NA NA NA NA

As the value is unknown, it might or might not be equal to 1, or to
another NA, or to 3, or to 0.

    Note that diﬀerent functions handle NAs in diﬀerent ways.
Functions such as mean() and median() accept the argument
na.rm=TRUE, which causes observations that have NAs to be ig-
nored. The plot() function omits NAs, inﬁnities and NaNs. For use
of lowess() to put a smooth curve through the plot, NAs must ﬁrst
be removed. By default, table() ignores NAs.

    Problems with missing values are a common reason why calcu-
lations fail. Inﬁnite values and NaNs are a further potential source of
diﬃculty.

Inf and NaN                                                              Note that sqrt(-1+0i) returns 0+1i.
                                                                         R distinguishes between the real
The expression 1/0 returns Inf. The expression log(0) returns            number -1 and the complex number
-Inf, i.e., smaller than any real number. The expressions 0/0 and        -1+0i.
log(-1) both return NaN.

NAs in subscripts?

It is best to ensure that NAs do not appear, when there is an assign-
ment, in subscript expressions on either side of the expression.

4.2 Data Frames, Matrices, Arrays and Lists                              Data frames with all columns numeric
                                                                         can sometimes be handled in the same
Data frames: Data frames are lists of column objects. The require-       way as matrices. In other cases, a
ment that all of the column objects have the same length gives data      diﬀerent syntax may be needed, or
frames a row by column rectangular structure. Diﬀerent columns can       conversion from one to the other.
have diﬀerent column classes — commonly numeric or character or          Proceed with care!
factor or logical or date.
                                                                         Internally, matrices are stored as one
Matrices – vectors with a Dimension: When printed, matrices              long vector in which the columns are
appear in a row by column layout in which all elements have the          stacked one above the other. The ﬁrst
same mode – commonly numeric or character or logical.                    element in the dimension attribute
                                                                         gives the number of rows in each
Arrays and tables: Matrices are two-dimensional arrays. Arrays           column.
more generally can have an arbitrary number of dimensions. Tables
have a structure that is identical to that of arrays.

    The data frame travelbooks will feature in the subsequent
discussion. Look back to Section 1.7 to see how it can be entered.
4.2.1 Data frames versus matrices and tables                           data objects and functions 65

Modeling functions commonly return larger numeric objects as           Computations that can be performed
matrices rather than data frames. The principal components function    with matrices are typically much
prcomp() returns scores as a matrix, as does the linear discriminant   faster than their equivalents with data
analysis function lda() from the MASS package.                         frames. See Section 6.4.

    Functions are available to convert data frames into matrices, and  Alternatively, do:
vice versa. For example:
                                                                       attr(travelmat , "dim")
 travelmat <- as.matrix(travelbooks[, 1:4])                            [1] 6 4
    # From data frame to matrix
                                                                       A data frame is a list of columns. The
 newtravelbooks <- as.data.frame(travelmat)                            function length() returns the list
    # From matrix to data frame                                        length.

    In comparing data frames with matrices, note that:                 Use unlist(travelbooks[6,
                                                                       ]) to turn row from the data frame
• Both for data frames and for matrices or two-way tables, the func-   into a vector. All elements are coerced
   tion dim() returns number of rows by number of columns, thus:       to a common mode, in this case
                                                                       numeric. Thus the ﬁnal element
    travelmat <- as.matrix(travelbooks[, 1:4])                         becomes 1.0 (the code that is stored),
    dim(travelmat)                                                     rather than Guide which was the ﬁrst
                                                                       level of the factor type.
    [1] 6 4

• For a matrix, length() returns the number of elements. For a
   data frame it returns the number of columns.

    c(dframelgth=length(travelbooks),
        matlgth=length(travelmat))

dframelgth         matlgth
                6           24

• The notation that uses single square left and right brackets to
   extract subsets of data frames, introduced in Section 1.6 works in
   just the same way with matrices. For example

    travelmat[, 4]
    travelmat[, "weight"]
    travelmat[, 1:3]
    travelmat[2,]

   Negative indices can be used to omit rows and/or columns.

• Use of the subscript notation to extract a row from a data frame
   returns a data frame, whereas extraction of a column yields a
   column vector. Thus:

  – Extraction of a row from a data frame, for example
      travelbooks["Canberra - The Guide", ] or
      travelbooks[6, ], yields a data frame, i.e., a special form
      of list.

  – travelbooks$volume (equivalent to travelbooks[,1] or
      travelbooks[,"volume"])) is a vector.

• For either a data frame or a matrix, the function rownames()
   can be used to extract row names, and the function colnames()
   to extract column names. For data frames, row.names() is an
   alternative to rownames(), while names() is an alternative to
   colnames().
66 learning and exploring r

    Note also a diﬀerence in the mechanisms for adding columns.
The following adds new columns area (area of page), and density
(weight to volume ratio) to the data frame travelbooks:

travelbooks$area <- with(travelbooks , width*height)
travelbooks$density <- with(travelbooks ,

                                                   weight/volume)
names(travelbooks) # Check column names

[1] "thickness" "width"          "height"  "weight"

"volume" "type"

[7] "area"            "density"

Columns are added to the data frame as necessary.
    For matrices, use cbind(), which can also be used for data

frames, to bind in new columns.

4.2.2 Inclusion of character vectors in data frames                    4 This assumes that the global
                                                                       option stringsAsFactors is
When data frames are created, whether by use of read.table()           FALSE. To check, interrogate
or another such function to input data from a ﬁle, or by use of the    options()$stringsAsFactors.
function data.frame() to join columns of data together into a data
frame, character vectors are converted into factors. Thus, the ﬁnal
column (type) of travelbooks became, by default, a factor.4 To
prevent such type conversions, specify stringsAsFactors=FALSE
in the call to read.table() or data.frame().

4.2.3 Factor columns in data frame subsets

The data frame ais (DAAG) has physical charateristics of athletes,
divided up thus between ten diﬀerent sports:

with(ais, table(sport))

sport        Field    Gym Netball          Row Swim T_400m T_Sprnt Tennis
 B_Ball           19     4 23               37 22 29 15 11
         25
 W_Polo
         17

    Figure 7.2.1 in Subsection 7.9 limits the data to swimmers and
rowers. For this, at the same time removing all levels except Row and
Swim from the factor sport, do:

rowswim <- with(ais, sport %in% c("Row", "Swim"))                      If redundant levels were left in place,
aisRS <- droplevels(subset(ais, rowswim))                              the graph would show empty panels
xtabs(~sport, data=aisRS)                                              for each such level.

sport
 Row Swim
   37 22

Contrast the above with:

xtabs(~sport, data=subset(ais, rowswim))
                                                                  data objects and functions 67

sport        Field     Gym Netball  Row Swim T_400m T_Sprnt Tennis
 B_Ball             0     00         37 22 0 0 0
          0
 W_Polo
          0

4.2.4 Handlng rows that include missing values

The function na.omit() omits rows that contain one or more miss-
ing values. The argument may be a data frame or a matrix. The
function complete.cases() identiﬁes such rows. Thus:

test.df <- data.frame(x=c(1:2,NA), y=1:3)
test.df

     xy
1 11
2 22
3 NA 3

## complete.cases()
complete.cases(test.df)

[1] TRUE TRUE FALSE

## na.omit()
na.omit(test.df)

   xy
111
222

4.2.5 Arrays — some further details                               Tables, which will be the subject
                                                                  of the next subsection, have a very
A matrix is a two-dimensional array. More generally, arrays can   similar structure to arrays.
have an arbitrary number of dimensions.

Removal of the dimension attribute

The dimension attribute of a matrix or array can be changed or re-
moved, thus:

travelvec <- as.matrix(travelbooks[, 1:4])
dim(travelvec) <- NULL # Columns of travelmat are stacked into one

                                           # long vector
travelvec

 [1] 1.3 3.9 1.2 2.0                 0.6   1.5    11.3            13.1 20.0 21.1
[11] 25.8 13.1 23.9 18.7            27.6  28.5    36.0            23.4 250.0 840.0
[21] 550.0 1360.0 640.0 420.0

# as(travelmat , "vector") is however preferable
68 learning and exploring r

    Note again that the $ notation, used with data frames and other
list objects to reference the contents of list elements, is not relevant
to matrices.

4.2.6 Lists

A list is a collection of arbitrary objects. As noted above, a data       Elements of lists are themselves lists.
frame is a specialized form of list. Consider for example the list        Distinguish rcanberra[4], which
                                                                          is a sub-list and therefore a list, from
rCBR <- list(society="ssai", branch="Canberra",                           rcanberra[[4]] which extracts
                       presenter="John",                                  the contents of the fourth list element.
                       tutors=c("Emma", "Chris", "Frank"))
                                                                          List elements can be accessed by
First, extract list length and list names:                                name. Thus, to extract the contents
                                                                          of the 4th list element, alterna-
length(rCBR)  # rCBR has 4 elements                                       tives to rcanberra[[4]] are
names(rCBR)                                                               rcanberra[["tutors"]] or
                                                                          rcanberra$tutors.
[1] 4

[1] "society" "branch" "presenter" "tutors"

The following extracts the 4th list element:

rCBR[4]       # Also a list, name is ' tutors '

$tutors
[1] "Emma" "Chris" "Frank"

Alternative ways to extract the contents of the 4th element are:

rCBR[[4]]     # Contents of 4th list element

[1] "Emma" "Chris" "Frank"

rCBR$tutors   # Equivalent to rCBR[["tutors"]]

[1] "Emma" "Chris" "Frank"

Model objects are lists                                                   Recall again, also, that data frames
                                                                          are a specialized form of list, with the
As noted in Subsection 3.3.2, the various R modeling functions all        restriction that all columns must all
return their own particular type of model object, either a list or as an  have the same length.
S4 object.
4.3 Functions                                                          data objects and functions 69

Diﬀerent Kinds of Functions:                                           Functions for working with dates are
                                                                       discussed in Section 4.3.9 immediately
Generic    The ’class’ of the function argument determines the         following.

           action taken. E.g., print(), plot(), summary()

Modeling   For example, lm() ﬁts linear models.
           Output may be stored in a model object.

Extractor  These extract information from model objects.
           Examples include summary()), coef()),
           resid()), and fitted()

User Use, e.g., to automate and document computations

Anonymous These are user functions that are deﬁned at the
                  point of use, and do not need a name.

    The above list is intended to include the some of the most impor-
tant types of function. These categories may overlap.

    The language that R implements has many of the features of a
functional language. Functions have accordingly featured throughout
the earlier discussion. Here will be noted functions that are com-
monly important.

4.3.1 Built-In Functions
Common useful functions

## Use with any R object as argument

print()        # Prints a single R object

length()       # Number of elements in a vector or of a list

## Concatenate and print R objects [does less coercion than print()]

cat()          # Prints multiple objects, one after the other

## Use with a numeric vector argument

mean()         # If argument has NA elements , may want na.rm=TRUE

median()       # As for mean(), may want na.rm=TRUE

range()        # As for mean(), may want na.rm=TRUE

unique()       # Gives the vector of distinct values

diff()         # Vector of first differences

               # N. B. diff(x) has one less element than x

cumsum()       # Cumulative sums, c.f., also, cumprod()

## Use with an atomic vector object

sort()         # Sort elements into order, but omitting NAs

order()        # x[order(x)] orders elements of x, with NAs last

rev()          # reverse the order of vector elements

any()          # Returns TRUE if there are any missing values

as()           # Coerce argument 1 to class given by argument 2

               # e.g. as(1:6, "factor")

is()           # Is argument 1 of class given by argument 2?

               # is(1:6, "factor") returns FALSE
70 learning and exploring r

is.na()             # is(TRUE, "logical") returns TRUE
                    # Returns TRUE if the argument is an NA

## Information on an R object

str()               # Information on an R object

args()              # Information on arguments to a function

mode()              # Gives the storage mode of an R object

                    # (logical, numeric, character , . . ., list)

## Create a vector

numeric()           # numeric(5) creates a numeric vector, length 5,

                    # all elements 0.

                    # numeric(0) (length 0) is sometimes useful.

character()         # Create character vector; c.f. also logical()

    The function mean(), and a number of other functions, takes
the argument na.rm=TRUE; i.e., remove NAs, then proceed with the
calculation. For example

mean(c(1, NA, 3, 0, NA), na.rm=T)

[1] 1.333

    Note that the function as() has, at present, no method for coerc-
ing a matrix to a data frame. For this, use as.data.frame().

Functions in diﬀerent packages with the same name

For example, as well as lattice function dotplot() the graphics
package has a defunct function dotplot(). To be sure of getting the
lattice function dotplot(), refer to it as lattice::dotplot.

4.3.2 Functions for data summary and/or manipulation                   For data manipulation, note:

4.3.3 Functions for creating and working with tables                   - the apply family of functions
                                                                          (Subsection 4.3.7).
4.3.4 Tables of Counts
                                                                       - data manipulation functions in
Use either table() or xtabs() to make a table of counts. Use              the reshape2 and plyr packages
xtabs() for cross-tabulation, i.e., to determine totals of numeric        (Chapter 6).
values for each table category.

The table() function

For use of table(), specify one vector of values (often a factor) for
each table margin that is required. For example:

library(DAAG)       # possum is from DAAG

with(possum , table(Pop, sex))

            sex
Pop f m

   Vic 24 22
   other 19 39
                                                                       data objects and functions 71

NAs in tables

By default, table() ignores NAs. To show information on NAs,
specify exclude=NULL, thus:

library(DAAG)
table(nswdemo$re74==0, exclude=NULL)

FALSE TRUE <NA>
   119 326 277

The xtabs() function

This more ﬂexible alternative to table() uses a table formula to
specify the margins of the table:

xtabs(~ Pop+sex, data=possum)

            sex
Pop f m

   Vic 24 22
   other 19 39

    A column of frequencies can be speciﬁed on the left hand side of   Manipulations with data frames are
the table formula. In order to demonstrate this, the three-way table   in general conceptually simpler than
UCBAdmissions (datasets package) will be converted into its data       manipulations with tables. For tables
frame equivalent. Margins in the table become columns in the data      that are not unreasonably large, it
frame:                                                                 is in general a good strategy to ﬁrst
                                                                       convert the table to a data frame and
UCBdf <- as.data.frame.table(UCBAdmissions)                            make that the starting point for further
head(UCBdf, n=3)                                                       calculations.

         Admit Gender Dept Freq
1 Admitted Male A 512
2 Rejected Male A 313
3 Admitted Female A 89

    The following then forms a table of total admissions and rejec-
tions in each department:

xtabs(Freq ~ Admit+Dept, data=UCBdf)

       Dept

Admit            ABCDEF

Admitted 601 370 322 269 147 46

Rejected 332 215 596 523 437 668

Information on data objects

The function str() gives basic information on the data object that is
given as argument.

library(DAAG)
str(possumsites)
72 learning and exploring r

'data.frame ': 7 obs. of 3 variables:
 $ Longitude: num 146 149 151 153 153 ...
 $ Latitude : num -37.5 -37.6 -32.1 -28.6 -28.6 ...
 $ altitude : num 800 300 300 400 200 400 600

4.3.5 Utility functions

dir()              # List files in the working or other specified directory
sessionInfo()      # Print version numbers for R and for attached packages
system.file()      # By default , show path to ' package="base " '
R.home()           # Path to R home directory
.Library           # Path to the default library
.libPaths()        # Get/set paths to library directories

Section A has further details.

4.3.6 User-deﬁned functions                                                 Note also that functions can be deﬁned
                                                                            at the point of use. Such functions
The function mean() calculates means, The function sd() calcu-              do not need a name, and are called
lates standard deviations. Here is a function that calculates mean and      anonymous functions. Section 4.3.4
standard deviation at the same time:                                        has an example.

mean.and.sd <- function(x){                                                 5 Data are from Lewontin, R. 1974.
       av <- mean(x)                                                        The Genetic Basis of Evolutionary
       sdev <- sd(x)                                                        Change.
       c(mean=av, sd = sdev) # return value
                                                                            Note that a diﬀerent set of random
}                                                                           numbers will be returned, giving a
                                                                            diﬀerent mean and SD, each time that
The parameter x is the argument that the user must supply. The body         the function is run with its default
of the function is enclosed between curly braces. The value that the        argument.
function returns is given on its ﬁnal line. Here the return value is a
vector that has two named elements.

    The following calculates the mean and standard deviation of
heterozygosity estimates for seven diﬀerent Drosophila species.5

hetero <- c(.43,.25,.53,.47,.81,.42,.61)
mean.and.sd(hetero)

mean  sd

0.5029 0.1750

    It is useful to give the function argument a default value, so that it
can be run without user-supplied parameters, in order to see what it
does. A possible choice is a set of random normal numbers, perhaps
generated using the rnorm() function. Here is a revised function
deﬁnition. Because the function body has been reduced to a single
line, the curly braces are not needed.

mean.and.sd <- function(x = rnorm(20))
                               c(mean=mean(x), sd=sd(x))

mean.and.sd()

mean           sd

-0.1610 0.9986
                                                                         data objects and functions 73

mean.and.sd()

mean           sd

0.08901 0.85100

4.3.7 The apply family of functions                                      For the apply family of functions,
                                                                         specify as the FUN argument any
apply(), sapply() and friends                                            function that will not generate an
  apply() Use apply() to apply a function across rows                    error. Obviously, log("Hobart") is
                  or columns of a matrix (or data frame)                 not allowed!
                                                                         Note also the function tapply(),
  sapply() sapply() and lapply() apply functions in                      which will not be discussed here.
  & friends parallel across columns of a data frame, or across
                                                                         If used with a data frames, the data
                  elements of a list, or across elements of a vector.    frame is ﬁrst coerced to matrix.

apply(): The function apply() is intended for use with matrices          Code that will input molclock1:
or, more generally, with arrays. It has three mandatory arguments, a
matrix or data frame, the dimension (1 for rows; 2 for columns) or       library(DAAG)
dimensions, and a function that will be applied across that dimension    datafile("molclock1")
of the matrix or data frame.                                             molclock <-

    Here is an example:                                                     read.table("molclock1.txt")

apply(molclock, 2, range)

    The following tabulates admissions, in the three-way table
UCBAdmissions, according to sex:

apply(UCBAdmissions , c(1,2), sum)

       Gender

Admit  Male Female

Admitted 1198 557

Rejected 1493 1278

sapply() and lapply(): Use sapply() and lapply() to apply                Warning: Use apply() with
a function (e.g., mean(), range(), median()) in parallel to all          COLUMN=2, to apply a function to
columns of a data frame. They take as arguments the name of the          all columns of a matrix. If sapply()
data frame, and the function that is to be applied.                      or lapply() is given a matrix as
                                                                         argument, the function is applied to
    The function sapply() returns the same information as                each element (the matrix is treated as a
lapply(). But whereas lapply() returns a list, sapply() tries            vector).
if possible to simplify the result to give a vector or matrix or array.
                                                                         Use of na.rm=TRUE:
    Here is an example of the use of sapply():
                                                                         sapply(molclock , range,
sapply(molclock, range)                                                              na.rm=TRUE)

         Gpdh Sod Xdh AvRate Myr                                                  Gpdh Sod Xdh AvRate Myr
[1,] 1.5 12.6 11.5 11.9 55                                               [1,] 1.5 12.6 11.5 11.9 55
[2,] 40.0 46.0 31.7 24.9 1100                                            [2,] 40.0 46.0 31.7 24.9 1100

    A third argument na.rm=TRUE can be supplied to the function
sapply. This argument is then automatically passed to the function
that is given in the second argument position.
74 learning and exploring r

    More generally, the ﬁrst argument to sapply() or lapply() can
be any vector.

sapply() – Application of a user function

We will demonstrate the use of sapply() to apply a function that      6 This is called an anonymous func-
counts the number of NAs to each column of a data frame. A suitable   tion.
function can be deﬁned thus:

countNA <- function(x)sum(is.na(x))

    An alternative is to deﬁne a function6 in place, without a name,
that counts number of NAs. The alternatives are:

Use function deﬁned earlier:      Deﬁne function at place of call:

library(MASS)                     sapply(Pima.tr2[, 1:5],
sapply(Pima.tr2[, 1:5], countNA)              function(x)sum(is.na(x)))

npreg glu    bp skin bmi                   npreg glu                  bp skin bmi
       00                                         00
             13 98  3                                                 13 98  3

4.3.8 Functions for working with text strings                         For paste(), the default is to use a
                                                                      space as a separator; paste0() omits
The functions paste() and paste0() join text strings. The func-       the space.
tion sprintf(), primarily designed for formatting output for print-
ing, usefully extends the abilities of paste() and paste0().          Other functions that accept an ar-
                                                                      gument fixed include the search
    Other simple string operations include substring() and            functions grep() and regexpr(),
nchar() (number of characters). Both of these, and strsplit()         and the search and replace functions
noted in the next paragraph, can be applied to character vectors.     sub() and gsub().

    The function strsplit(), used to split strings, has an argument   Regular expression substitution:
fixed that by default equals FALSE. The eﬀect is that the argument
split, which speciﬁes the character(s) on which the string will       specnam <- sub("\\.",
split, is assumed to be a regular expression. See help(regexp) for                               " ", spec)
details. For use of a split character argument, call strsplit()
with fixed=FALSE.                                                     In regular expressions enter a period
                                                                      (".") as "\\."
    Bird species in the dataset cuckoos (DAAG) are:
                                                                      See help(regex) for information on
(spec <- levels(cuckoos$species))                                     the use of regular expressions.

[1] "hedge.sparrow" "meadow.pipit" "pied.wagtail"

[4] "robin"  "tree.pipit" "wren"

Now replace the periods in the names by spaces:

(specnam <- sub(".", " ", spec, fixed=TRUE))

[1] "hedge sparrow" "meadow pipit" "pied wagtail"

[4] "robin"  "tree pipit" "wren"

    For string matching, use match(), pmatch() and charmatch().
For matching with regular expressions, note grep() and
regexpr(). For string substitution, use sub() and gsub().

    Web pages with information on string manipulation in R include:
http://www.stat.berkeley.edu/classes/s133/R-6.html                   data objects and functions 75
http://en.wikibooks.org/wiki/R_Programming/Text_Processing
                                                                     For strings representing biological se-
The ﬁrst is an overview, with the second more detailed.              quences, install the well-documented
    The package stringr, due to Hadley Wickham, provides what        Bioconductor package Biostrings.

may be a more consistent set of functions for string handling than   Good starting points for learning
are available in base R.                                             about dates in R are the help pages
                                                                     help(Dates), help(as.Date)
4.3.9 Functions for Working with Dates (and Times)                   and help(format.Date).

Use as.Date() to convert character strings into dates. The default   Subtraction yields a time diﬀerence
format has year, then month, then day of month, thus:                object. If necessary, use unclass()
                                                                     to convert this to a numeric vector.
# Electricity Billing Dates                                          Use unclass() to turn a time
dat <- c("2003-08-24","2003-11-23","2004-02-22",                     diﬀerence object into an integer
                                                                     vector:
                "2004-05-03")
dd <- as.Date(dat)                                                   unclass(diff(dd))

    Use format() to set or change the way that a date is formatted.  See help(format.Date).
The following is a selection of the available symbols:

     %d: day, as number
     %a: abbreviated weekday name (%A: unabbreviated)
     %m: month (00-12)
     %b: month abbreviated name (%B: unabbreviated)
     %y: ﬁnal two digits of year (%Y: all four digits)
    The default format is "%Y-%m-%d". The character / can be used
in place of -. Other separators (e.g., a space) must be explicitly
speciﬁed, using the format argument, as in the examples below.
    Date objects can be subtracted:

as.Date("1960-12-1") - as.Date("1960-1-1")

Time difference of 335 days

There is a diff() method for date objects:

dd <- as.Date(c("2003-08-24","2003-11-23",
                             "2004-02-22", "2004-05-03"))

diff(dd)

Time differences in days
[1] 91 91 71

Formatting dates for printing: Use format() to ﬁne tune the
formatting of dates for printing.

dec1 <- as.Date("2004-12-1")
format(dec1, format="%b %d %Y")

[1] "Dec 01 2004"

format(dec1, format="%a %b %d %Y")

[1] "Wed Dec 01 2004"
76 learning and exploring r                                                            1840                                    q
                                                                                       1820
    Such formatting may be used to give meaningful labels on                           1800                                    q
graphs. Figure 4.1 provides an example:                                                1780
                                                                                       1760                                 q
## Labeling of graph: data frame jobs (DAAG)                                           1740                          q
library(DAAG); library(lattice)
fromdate <- as.Date("1Jan1995", format="%d%b%Y")                                   BC                                qqq  q
startofmonth <- seq(from=fromdate , by="1 month",                                                                           q
                                                                                                                  q
                                    length=24)                                                                  qq
atdates <- seq(from=fromdate , by="6 month",
                                                                                                      qqq
                           length=4)
xyplot(BC ~ startofmonth , data=jobs,                                                        qq    q         q
                                                                                                 q         q
            scale=list(x=list(at=atdates ,                                                   qq
                                             labels=format(atdates ,
                                                                       "%b%y"))))            q

Conversion of dates to and from integer number of days: By de-                               Jan95 Jul95 Jan96 Jul96
fault, dates are stored in integer numbers of days. Use julian()
to convert a date into its integer value, by default using January 1                                   startofmonth
1970 as origin. Use the argument option to specify some diﬀerent
origin:                                                                            Figure 4.1: Canadian worker force
                                                                                   numbers, with dates used to label the
dates <- as.Date(c("1908-09-17", "1912-07-12"))                                    x-axis. See Figure 7.12 in Subsection
julian(dates)                                                                      7.2.6 for data from all Canadian
                                                                                   provinces.
[1] -22386 -20992
attr(,"origin")
[1] "1970-01-01"

julian(dates, origin=as.Date("1908-01-01"))

[1] 260 1654
attr(,"origin")
[1] "1908-01-01"

    Note also weekdays(), months(), and quarters():

dates <- as.Date(c("1908-09-17", "1912-07-12"))
weekdays(dates)

[1] "Thursday" "Friday"

months(dates)

[1] "September" "July"

quarters(dates)

[1] "Q3" "Q3"

Regular sequences of dates: Use the function help(seq.Date).
    Given a vector of ‘event’ times, the following function can be

used to count the number of events in each of a regular sequence of
time intervals:
                                                                                                   data objects and functions 77

intervalCounts <- function(date, from=NULL, to=NULL, interval="1 month"){
   if(is.null(from))from <- min(date)
   if(is.null(to))to <- max(date)
   dateBreaks <- seq(from=from , to=to, by=interval)
   dateBreaks <- c(dateBreaks , max(dateBreaks)+diff(dateBreaks[1:2]))
   cutDates <- cut(date, dateBreaks , right=FALSE)
   countDF <- data.frame(Date=dateBreaks[-length(dateBreaks)],
                                           num=as.vector(table(cutDates)))
   countDF

}

    The following counts the number of events by year:

dates <- c("1908-09-17", "1912-07-12", "1913-08-06", "1913-09-09", "1913-10-17")
dates <- as.Date(dates)
(byYear <- intervalCounts(dates, from=as.Date("1908-01-01"), interval='1 year'))

              Date num
1 1908-01-01 1
2 1909-01-01 0
3 1910-01-01 0
4 1911-01-01 0
5 1912-01-01 1
6 1913-01-01 3

Further useful functions for working with dates: Note also date()     The CRAN Task View for Time Series
which returns the current date and time, and Sys.Date() which         Analysis has notes on classes and
returns the date. For information on functions for working with       methods for times and dates, and on
times, see help(ISOdatetime).                                         packages that give useful functionality

4.3.10 Summaries of Information in Data Frames                        The data frame is split according to
                                                                      the grouping elements speciﬁed in
A common demand is to obtain a tabular summary of information         the by argument. The function is then
in each of several columns of a data frame, broken down according     applied to each of the columns in each
to the levels of one or more grouping variables. Consider the data    of the splits.
frame nswdemo (DAAG). Treatment groups are control (trt==0) and
treatment (trt==1) group, with variables re74 (1974 income), re75
(1975) and re78 (1978),

    The following calculates the number of zeros for each of the
three variables, and for rach of the two treatment categories:

## Define a function that counts zeros
countzeros <- function(x)sum(!is.na(x) & x==0)
aggregate(nswdemo[, c("re74", "re75", "re78")],

                  by=list(group=nswdemo$trt),
                  FUN=countzeros)

   group re74 re75 re78
1 0 195 178 129
2 1 131 111 67

    Now ﬁnd the proportion, excluding NAs, that are zero. The result
will be printed out with improved labeling of the rows:

## countprop() counts proportion of zero values
countprop <- function(x){

       sum(!is.na(x) & x==0)/length(na.omit(x))}
78 learning and exploring r

prop0 <-
   aggregate(nswdemo[, c("re74","re75","re78")],
                     by=list(group=nswdemo$trt),
                     FUN=countprop)

## Now improve the labeling
rownames(prop0) <- c("Control", "Treated")
round(prop0 ,2)

         group re74 re75 re78

Control  0 0.75 0.42 0.30

Treated  1 0.71 0.37 0.23

    The calculation can alternatively be handled by two calls to the   The argument z in the ‘in place’
function sapply(), one nested within the other, thus:                  function is a data frame. The argument
                                                                       x to countprop() is a column of a
prop0 <-                                                               data frame.
   sapply(split(nswdemo[, c("re74","re75","re78")],
                           nswdemo$trt),
                FUN=function(z)sapply(z, countprop))

round(t(prop0), 2)

   re74 re75 re78
0 0.75 0.42 0.30
1 0.71 0.37 0.23

4.4 *Classes and Methods (Generic Functions)                           Thus print() calls a method thus:
                                                                       factor: print.factor();
Key language constructs:
  Classes Classes make generic functions (methods) possible.             data frame:
                                                                       print.data.frame(); and so
  Methods Examples are print(), plot(), summary(), etc.                on. Ordered factors “inherit” the
                                                                       print method for factors. For objects
    There are two implementation of classes and methods, the orig-     without an explicit print method,
inal S3 implementation, and the newer S4 implementation that is        print.default() is called.
implemented in the methods package. Here, consider the simpler S3
implementation.                                                        Packages that use S4 classes and
                                                                       methods include lme4, Bioconductor
    All objects have a class. Use the function class() to get this     packages, and most of the spatial
information.                                                           analysis packages.

    For many common tasks there are generic functions – print(),
summary(), plot(), etc., whose action varies according to the class
of object to which they are applied.

    To get details of the S3 methods that are available for a generic
function such as plot(), type, e.g., methods(plot). To get a list
of the S3 methods that are available for objects of class lm, type,
e.g., methods(class="lm")

4.4.1 ∗S4 methods

The S4 conventions and mechanisms extend the abilities available
under S3, build in checks that are not available with S3, and are
more conducive to good software engineering practice.
Example – a spatial class                                                data objects and functions 79

The sp package deﬁnes, among other possibilities, spatial data           Classes deﬁned in the sp package
classes SpatialPointsDataFrame and SpatialGridDataFrame.                 are widely used across R spatial data
                                                                         analysis packages.
    The sp function bubble(), for plotting spatial measurement
data, accepts a spatial data object as argument.7 The function           7 Each point (location) is shown as
coordinates() can be used, given spatial coordinates, to turn a          a bubble, with area proportional to a
data frame or matrix into an object of one of the requisite classes.     value for that point.

    Data from the data frame meuse8, from the sp package, will be        8 Data are from the ﬂoodplain of the
used for an example. A ﬁrst step is to create an object of one of the    river Meuse, in the Netherlands. It
classes that the function bubble() accepts as argument, thus:            includes concentrations of various
                                                                         metals (cadmium, copper, lead,
library(sp)                                                              zinc), with Netherlands topographi-
data(meuse)                                                              cal map coordinates.
class(meuse)

[1] "data.frame"

coordinates(meuse) <- ~ x + y                                                                        zinc
class(meuse)

[1] "SpatialPointsDataFrame"                                                       333000            qq qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq
attr ( ," package ")                                                     Northing  332000  qqqqqqq qqqqqqqq qqqqqqqqqq                                 q 113
[1] "sp"                                                                           331000     qq     qqqqq                                             q 198
                                                                                   330000     qq                                            q         q 326
This has created an object of the class SpatialPointsDataFrame.                              qqq q      q                                   q         q 674.5
    Code that creates the plot, shown in Figure 4.2, is:                                   qqq qqq
                                                                                           qq q       qqq                                             q 1839
bubble(meuse, zcol="zinc", scales=list(tck=0.5),                                           qqq qq qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq
            maxsize=2, xlab="Easting", ylab="Northing")                                              q                                    q

The function bubble() uses the abilities of the lattice package. It                                                                       q    q
returns a trellis graphics object.
                                                                                           q qqqqqq
    The coordinates can be extracted using coordinates(meuse).
Remaining columns from the original data frame are available from                  178500 179500 180500 181500
the data frame meuse@data.                                                                      Easting

    Use slotNames() to examine the structure of the object:              Figure 4.2: Bubble plot for zinc
                                                                         concentrations. Areas of bubbles are
slotNames(meuse)                                                         proportional to concentrations.

[1] "data"  "coords.nrs" "coords"
[4] "bbox"  "proj4string"

Typing names(meuse) returns the column names for the data slot.          Note that meuse@data is shorthand
The eﬀect is the same as that of typing names(meuse@data). To get        for slot(meuse, "data").
a list of the S4 methods that are available for a generic function, use
showMethods(). Section 12.4 has further details.

4.5 Common Sources of Surprise or Diﬃculty

  Character vectors, when incorporated as columns of a data frame,
  become by default factors.
80 learning and exploring r                                             Assignment of new values to an
                                                                        attached data frame creates a new
  Factors can often be treated as vectors of text strings, with values  local data frame with the same name.
  given by the factor levels. Watch however for contexts where the      The new local copy remains in the
  integer codes are used instead.                                       workspace when the data frame is
                                                                        detached.
  Use is.na() to check for missing values. Do not try to test for
  equality with NA. Refer back to Section 4.1.3.

  If there is a good alternative, avoid the attaching of data frames.
  If you do use this mechanism, be aware of the traps.

  The syntax elasticband[,2], extracts the second column from
  the data frame elasticband, yielding a numeric vector. Observe
  however that elasticband[2, ] yields a data frame, rather than
  the numeric vector that the user may require. Use the function
  unlist() to extract the vector of numeric values.

4.6 Summary                                                             Calculations with matrices are likely
                                                                        to be much faster than with data
  Important R data structures are vectors, factors, data frames and     frames.
  lists. Vector modes include numeric, logical, character or complex.
                                                                        Generic functions that may be used
  Factors, used for categorical data, can be important in the use of    with model objects typically include
  many of R’s modeling functions. Ordered factors are appropriate       print(), summary(), fitted(),
  for use with ordered categorical data.                                coef() and resid().

  Use table() for tables of counts, and xtabs() for tables of
  counts or totals.

  R allows the use of inﬁnite Values (Inf or -Inf) and NaNs (not
  a number) in calculations. Introduce such quantities into your
  calculations only if you understand the implications.

  A matrix is a vector that is stacked column upon column into
  a rectangular array that has dimensions given by its dimension
  attribute. A data frame is, by contrast, a list of columns.

  Matrices are in some (not all) contexts handled similarly to data
  frames whose elements are all of one type (typically all numeric).

  Lists are “non-atomic” vectors. Use the function c() (concate-
  nate) to join lists, just as for “atomic” vectors.

  Modeling functions typically output a model object that has a list
  structure. This holds information from the model ﬁt, in a form
  from which generic model functions can then extract commonly
  required forms of output.

 4.7 Exercises

1. Find an R function that will sort a vector. Give an example.
                                                                        data objects and functions 81

2. Modify the function mean.and.sd() so that it outputs, in addi-
    tion to mean and standard deviation, the number of vector ele-
    ments.

3. ∗What is the mode of: (i) a factor; (ii) a dataframe?; (iii) a list
    that is not necessarily a dataframe? Apply the function mode() to
    objects of each of these classes. Explain what you ﬁnd.

4. The attempt to assign values to an expression whose subscripts
    include missing values generates an error. Run the following code
    and explain the error that results:

     y <- c(1, NA, 3, 0, NA)
     y[y > 0]
     y[y > 0] <- c(11, 12)

5. Run the following code:

gender <- factor(c(rep("female", 91), rep("male", 92)))

table(gender)

gender <- factor(gender, levels=c("male", "female"))

table(gender)

gender <- factor(gender, levels=c("Male", "female")) # Note the mistake

                            # The level was "male", not "Male"

table(gender)

rm(gender)                  # Remove gender

The output from the ﬁnal table(gender) is

gender
   Male female
         0 91

    Explain the numbers that appear.

6. In the data set nswpsdi1 (DAAGxtras), do the following for each
    of the two levels of trt:

 (a) Determine the numbers for each of the levels of black;
 (b) Determine the numbers for each of the levels of hispanic;

       item Determine the numbers for each of the levels of marr
       (married).

7. Sort the rows in the data frame Acmena in order of increasing
    values of dbh.
    [Hint: Use the function order(), applied to age to determine the
    order of row numbers required to sort rows in increasing order of
    age. Reorder rows of Acmena to appear in this order.]

     Acmena <- subset(rainforest , species=="Acmena smithii")
     ord <- order(Acmena$dbh)
     acm <- Acmena[ord, ]

    Sort the row names of possumsites (DAAG) into alphanumeric
    order. Reorder the rows of possumsites in order of the row
    names.
82 learning and exploring r

8.(a) Create a for loop that, given a numeric vector, prints out one
       number per line, with its square and cube alongside.

 (b) Look up help(while). Show how to use a while loop to
       achieve the same result.

 (c) Show how to achieve the same result without the use of an
       explicit loop.

9. Here are examples that illustrate the use of paste() and
    paste0():

     paste("Leo", "the", "lion")
     paste("a", "b")
     paste0("a", "b")
     paste("a", "b", sep="")
     paste(1:5)
     paste(1:5, collapse="")

What are the respective eﬀects of the parameters sep and
collapse?

10. The following function calculates the mean and standard deviation
     of a numeric vector.

       meanANDsd <- function(x){
              av <- mean(x)
              sdev <- sd(x)
              c(mean=av, sd = sdev) # The function returns this vector

       }

Modify the function so that: (a) the default is to use rnorm()
to generate 20 random normal numbers, and return the standard
deviation; (b) if there are missing values, the mean and standard
deviation are calculated for the remaining values.

11. Try the following:         # cabbages is in the datasets package

       class(2)
       class("a")
       class(cabbages$HeadWt)
       class(cabbages$Cult)

     Now do sapply(cabbages, class), and note which columns
     hold numerical data. Extract those columns into a separate data
     frame, perhaps named numtinting.

     [Hint: cabbages[, c(2,3)] is not the correct answer, but it is,
     after a manner of speaking, close!]

12. Functions that may be used to get information about data frames
     include str(), dim(), row.names() and names(). Try each
     of these functions with the data frames allbacks, ant111b and
     tinting (all in DAAG).

     For getting information about each column of a data frame, use
     sapply(). For example, the following applies the function
     class() to each column of the data frame ant111b.
                                                             data objects and functions 83

library(DAAG)
sapply(ant111b, class)

For columns in the data frame tinting that are factors, use
table() to tabulate the number of values for each level.
84 learning and exploring r
5
Data Input and Storage
86 learning and exploring r                                              Most data input functions allow
                                                                         import from a ﬁle that is on the web
5.1 ∗Data Input from a File                                              — give the URL when specifying
                                                                         the ﬁle. Another possibility is to
.                                                                        copy the ﬁle, or a relevant part of it,
    Use of the RStudio menu is recommended. This is fast, and            to the clipboard. For reading from
                                                                         and writing to the clipboard under
allows a visual check of the data layout before input proceeds. If       Windows, see http://bit.ly/
input options are incorrectly set, these can be changed as necessary     2sxyOhG. For MacOS, see http:
before proceeding. The code used for input is shown. In those rare       //bit.ly/2t1nX0I
cases where input options are required for which the menu does not
make provision, the command line code can be edited as needed,           It is important to check, when data
before proceeding.                                                       have been entered, that data values
                                                                         appear sensible. Do minimal checks
5.1.1 Managing input is from the RStudio menu                            on: ranges of variable values, the
                                                                         mode of the input columns (numeric
Data input that is initiated from the RStudio menu uses func-            or factor, or . . . ). Scatterplot matrices
tions from the package readr for input of tabular data. The              are helpful both for checking variable
function readr::read_table() replaces read.table(),                      ranges and for identifying impossible
readr::read_csv() replaces read.csv(), and similarly for other           or unusual combinations of variable
read.table() aliases.                                                    values.

    It uses the function readxl::readxl() for Excel spreadsheet          See vignette("semantics",
data. There is provision, also, using functions from the package         package="haven") for details of the
haven, to import data from SPSS (POR and SAV ﬁles), from SAS             way that labelled data and missing
(XPT and SAS ﬁles), and from Stata (DTA ﬁles).                           values are handled, for input from
                                                                         SPSS, SAS, and Stata.
    Output is in all cases to a tibble, which is a specialized form of
data frame. Character columns are not automatically converted to         Non-default option settings can
factors, column names are not converted into valid R identiﬁers,         however, for very large ﬁles, severely
and row names are not set. For subsequent processing, there are          slow data input.
important diﬀerences between tibbles and data frames that users          For factor columns check that the
need to note.                                                            levels are as expected.

5.1.2 Input using the read.table() family of functions                   1 By default, if the ﬁrst row of the ﬁle
                                                                         has one less ﬁeld than later rows, it is
There are several aliases for read.table() that have diﬀerent set-       taken to be a header row. Otherwise, it
tings for input defaults. Note in particular read.csv(), for reading     is taken as the ﬁrst row of data.
in comma delimited .csv ﬁles such as can be output from Excel
spreadsheets. See help(read.table). Recall that                          NB also that count.fields() counts
                                                                         the number of ﬁelds in each record
- Character vectors are by default converted into factors. To prevent    — albeit watch for diﬀerences from
   such type conversions, specify stringsAsFactors=FALSE.                input ﬁelds as detected by the input
                                                                         function.
- Specify heading=TRUE1 to indicate that the ﬁrst row of input has
   column names. Use heading=FALSE to indicate that it holds data.
   [If names are not given, columns have default names V1, V2, . . . .]

- Use the parameter row.names, then specifying a column number,
   to specify a column for use to provide row names.

Issues that may complicate input

Where data input fails, consider using read.table() with the
argument fill=TRUE, and carefully check the input data frame.
Blank ﬁelds will be implicitly added, as needed, so that all records            data input and storage 87
have an equal number of identiﬁed ﬁelds.
                                                                           2 For text with embedded single
    Carefully check the parameter settings2 for the version of the         quotes, set quote = "". For text with
input command that is in use. It may be necessary to change the            # embedded; change comment.char
ﬁeld separators (specify sep), and/or the missing value character(s)       suitably.
(specify na.strings). Embedded quotes and comment characters
(#; by default anything that follows # on the same line is ignored.)       Among other possibilities, there
can be a source of diﬃculty.                                               may be a non-default missing value
                                                                           symbol (e.g., "."), but without using
    Where a column that should be numeric is converted to a factor         na.strings to indicate this.
this is an indication that it has one or more ﬁelds that, as numbers,
would be illegal. For example, a "1" (one) may have been mistyped          There are two calls to scan(), each
as an "l" (ell), or "0" (zero) as "O" (oh).                                time taking information from the
                                                                           ﬁle molclock1.txt. The ﬁrst, with
    Note options that allow the limiting of the number of input rows.      nlines=1 and what="", input
For read.table()) and aliases, set nrows. For functions from               the column names. The second, with
the readr package, set n_max. For scan(), discussed in the next            skip=1 and what=c(list(""),
subsection, set nlines. All these functions accept the argument            rep(list(1),5)))], input the
skip, used to set the number of lines to skip before input starts.         several rows of data.
                                                                           For repeated use with data ﬁles that
5.1.3 ∗The use of scan() for ﬂexible data input                            have a similar format, consider putting
                                                                           the code into a function, with the what
Data records may for example spread over several rows. There               list as an argument.
seems no way for read.table() to handle this.

    The following code demonstrates the use of scan() to read in
the ﬁle molclock1.txt. To place this ﬁle in your working directory,
attach the DAAG package and type datafile("molclock1").

colnam <- scan("molclock1.txt", nlines=1, what="")
molclock <- scan("molclock1.txt", skip=1,

                               what=c(list(""), rep(list(1),5)))
molclock <- data.frame(molclock , row.names=1)

   # Column 1 supplies row names
names(molclock) <- colnam

The what parameter should be a list, with one list element for each
ﬁeld in a record. The "" in the ﬁrst list element indicates that the data
is to be input as character. The remaining ﬁve list elements are set to
1, indicating numeric data. Where records extend over several lines,
set multi.line=TRUE.

5.1.4 The memisc package: input from SPSS and Stata                        Note also the haven package, men-
                                                                           tioned above, and the foreign package.
The memisc package has highly eﬀective abilities for examining and         The foreign package has functions that
inputting data from various SPSS formats. These include .sav, .por,        allow input of various types of ﬁles
and Stata .dta data types. Note in particular the ability to check the     from Epi Info, Minitab, S-PLUS, SAS,
contents of the columns of the dataset before importing part or all of     SPSS, Stata, Systat and Octave. There
the ﬁle.                                                                   are abilities for reading and writing
                                                                           some dBase ﬁles. For further infor-
    An initial step is to use an importer function to create an importer   mation, see the R Data Import/Export
object. As of now, importer functions are: spss.fixed.file(),              manual.
spss.portable.file() ( .por ﬁles), spss.system.file()
(.sav ﬁles), and Stata.file() (.dta ﬁles). The importer object
88 learning and exploring r                                               Additionally, it has also information
                                                                          from further processing of the ﬁle
has information about the variables: including variable labels, value     header and/or the ﬁle proper that is
labels, missing values, and for an SPSS ‘ﬁxed’ ﬁle the columns that       needed in preparation for importing
they occupy, etc.                                                         the ﬁle.

    Functions that can be used with an importer object include:           Use as.data.frame() to coerce
                                                                          data.set objects into data frames. In-
- description(): column header information;                               formation that is not readily retainable
- codebook(): detailed information on each column;                        in a data frame format may be lost in
- as.data.set(): bring the data into R, as a ‘data.set’ object;           the process.
- subset(): bring a subset of the data into R, as a ‘data.set’ object

    The functions as.data.set() and subset() yield ‘data.set’
objects. These have structure that is additional to that in data frames.
Most functions that are available for use with data frames can be
used with data.set class objects.

    The vignette anes48 that comes with the memisc package illus-
trates the use of the above abilities.

Example                                                                   To substitute your own ﬁle, store the
                                                                          path to the ﬁle in path2file.
A compressed version of the ﬁle “NES1948.POR” (an SPSS
‘portable’ dataset) is stored as part of the memisc installation. The
following does the unzipping, places the ﬁle in a temporary direc-
tory, and stores the path to the ﬁle in the text string path2file:

library(memisc)

## Unzip; return path to "NES1948.POR"
path2file <- unzip(system.file("anes/NES1948.ZIP",package="memisc"),

                                      "NES1948.POR",exdir=tempfile())

    Now create an ‘importer’ object, and get summary information:

# Get information about the columns in the file
nes1948imp <- spss.portable.file(path2file)
show(nes1948imp)

SPSS portable file '/var/folders/00/_kpyywm16hnbs2c0dvlf0mwr0000gq/T//Rtmp1uoX7S/file274
              with 67 variables and 662 observations

There will be a large number of messages that draw attention to           Use labels()) to change labels, or
duplicate labels.                                                         missing.values() to set missing
                                                                          value ﬁlters, prior to data import.
    Before importing, it may be well to check details of what is in the
ﬁle. The following, which restricts attention to columns 4 to 9 only,
indicates the nature of the information that is provided.

## Get details about the columns (here, columns 4 to 9 only)
description(nes1948imp)[4:9]

$v480002
[1] "INTERVIEW NUMBER"

$v480003
[1] "POP CLASSIFICATION"
                                                                       data input and storage 89

$v480004                                                               This is more interesting than what
[1] "CODER"                                                            appears for columns (1 - 4).

$v480005                                                               Look also at the vignette:
[1] "NUMBER OF CALLS TO R"
                                                                       vignette("anes48")
$v480006
[1] "R REMEMBER PREVIOUS INT"

$v480007
[1] "INTR INTERVIEW THIS R"

As there are in this instance 67 columns, it might make sense to look
at columns perhaps 10 at a time.

    More detailed information is available by using the R function
codebook(). The following gives the codebook information for
column 5:

## Get codebook information for column 5
codebook(nes1948imp[, 5])

======================================================
     nes1948imp[, 5] 'POP CLASSIFICATION '

------------------------------------------------------

Storage mode: double
Measurement: nominal

Values and labels N Percent

1 'METROPOLITAN AREA' 182 27.5 27.5

2 'TOWN OR CITY'      354 53.5 53.5

3 'OPEN COUNTRY'      126 19.0 19.0

    The following imports a subset of just four of the columns:

vote.socdem.48 <- subset(nes1948imp ,
                         select=c(
                                v480018 ,
                                v480029 ,
                                v480030 ,
                                v480045
                                ))

    To import all columns, do:

socdem.48 <- as.data.set(nes1948imp)

    For more detailed information, type:

## Go to help page for ' importers '
help(spss.portable.file)
90 learning and exploring r                                               The web page:
                                                                            http://www.visualizing.
5.2 ∗Input of Data from a web page
                                                                          org/data/browse/ has an ex-
This section notes some of the alternative ways in which data that        tensive list of web data sources. The
is available from the web can be input into R. The ﬁrst subsection        World Bank Development Indicators
below comments on the use of a point and click interface to identify      database will feature prominently in
and download data.                                                        the discussion below.

    A point and click interface is often convenient for an initial look.  3 This may be especially important
Rather than downloading the data and then inputting it to R, it may       if a data download will be repeated
be better to input it directly from the web page. Direct input into       from time to time with updated data,
R has the advantage that the R commands that are used document            or if data are brought together from a
exactly what has been done.3                                              number of diﬀerent ﬁles, or if a subset
                                                                          is taken from a larger database.
    Note that the functions read.table(), read.csv(), scan(),
and other such functions, are able to read data directly from a ﬁle       GML, or Geography Markup Lan-
that is available on the web. There is a limited ability to input part    guage, is based on XML.
only of a ﬁle.

    Suppose however that the demand is to downlaod data for several
of a large number of variables, for a speciﬁed range of years, and for
a speciﬁed geographical area or set of countries. A number of data
archives now oﬀer data in one or more of several markup formats
that assist selective access. Formats include XML, GML, JSON and
JSONP.

A browser interface to World Bank data: The web page http:                4 Click on COUNTRY to modify
//databank.worldbank.org/data/home.aspx4 gives a point                    the choice of countries. To ex-
and click interface to, among other possibilities, the World Bank         pand (to 246) countries beyond
development indicator database. Clicking on any of 20 country             the 20 that appear by default, click
names that are displayed shows data for these countries for 1991-         on Add more country. Click on
2010, for 54 of the 1262 series that were available at last check.        SERIES and TIME to modify and/or
Depending on the series, data may be available back to 1964. Once         expand those choices. Click on
selections have been made, click on DOWNLOAD to download the              Apply Changes to set the choices
data. For input into R, downloading as a .csv ﬁle is convenient.          in place.

    Manipulation of these data into a form suitable for a motion chart
display was demonstrated in Subsection 6.2.3

Australian Bureau of Meteorology data: Graphs of area-weighted            5 To copy the web address, right
time series of rainfall and temperature measures, for various regions     click on Raw data set and click on
of Australia, can be accessed from the Australian Bureau of Meteo-        Copy Link Location (Firefox) or
rology web page http://www.bom.gov.au/cgi-bin/climate/                    Copy Link Address (Google Chrome)
change/timeseries.cgidemo. Click on Raw data set5 to down-                or Copy Link (Safari).
load the raw data.

    Once the web path to the ﬁle that has the data has been found, the
data can alternatively be input directly from the web. The following
gets the annual total rainfall in Eastern Australia, from 1910 through
to the present’:

webroot <- "http://www.bom.gov.au/web01/ncc/www/cli_chg/timeseries/"
rpath <- paste0(webroot , "rain/0112/eaus/", "latest.txt")
totrain <- read.table(rpath)
                                                                                                         data input and storage 91

A function to download multiple data series: The following ac-
cesses the latest annual data, for total rainfall and average tempera-
ture, from the command line:

getbom <-
function(suffix=c("AVt","Rain"), loc="eaus"){

              webroot <- "http://www.bom.gov.au/web01/ncc/www/cli_chg/timeseries/"
              midfix <- switch(suffix[1], AVt="tmean/0112/", Rain="rain/0112/")
              webpage <- paste(webroot , midfix , loc, "/latest.txt", sep="")
              print(webpage)
              read.table(webpage)$V2
              }
##
## Example of use
offt = c(seaus=14.7, saus=18.6, eaus=20.5, naus=24.7, swaus=16.3,

                qld=23.2, nsw=17.3, nt=25.2,sa=19.5, tas=10.4, vic=14.1,
                wa=22.5, mdb=17.7, aus=21.8)
z <- list()
for(loc in names(offt))z[[loc]] <- getbom(suffix="Rain", loc=loc)
bomRain <- as.data.frame(z)

The function can be re-run each time that data is required that in-
cludes the most recent year.

∗Extraction of data from tables in web pages

The function readHTMLTable(), from the XML package, will prove
very useful for this. It does not work, currenty at least, for pages that
use https:.

Historical air crash datra: The web page http://www.
planecrashinfo.com/database.htm has links to tables of
aviation accidents, with one table for each year. The table for
years up to and including 1920 is on the web page http://www.
planecrashinfo.com/1920/1920.htm, that for 1921 on the page
http://www.planecrashinfo.com/1921/1921.htm, and so on
through until the most recent year. The following code inputs the
table for years up to and including 1920:

library(XML)

url <- "http://www.planecrashinfo.com/1920/1920.htm"
to1920 <- readHTMLTable(url, header=TRUE)
to1920 <- as.data.frame(to1920)

    The following inputs data from 2010 through until 2014:

url <- paste0("http://www.planecrashinfo.com/",
                         2010:2014, "/", 2010:2014, ".htm")

tab <- sapply(url, function(x)readHTMLTable(x, header=TRUE))

## The following less efficent alternative code spells the steps out in more detail
## tab <- vector ( ' list ' , 5)
## k <- 0
## for(yr in 2010:2014){
## k <- k+1
92 learning and exploring r

## url <- paste0("http://www.planecrashinfo.com/", yr, "/", yr, ".htm")
## tab[[k]] <- as.data.frame(readHTMLTable(url, header=TRUE))
## }

    Now combine all the tables into one:

## Now combine the 95 separate tables into one
airAccs <- do.call('rbind', tab)
names(airAccs) <- c("Date", "Location/Operator",

                                      "AircraftType/Registration", "Fatalities")
airAccs$Date <- as.Date(airAccs$Date, format="%d %b %Y")

    The help page help(readHTMLTable) gives examples that
demonstrate other possibilities.

5.2.1 ∗Embedded markup — XML and alternetives                           For details of markup use, as they
                                                                        relate to the World Bank Development
Data are are now widely available, from a number of diﬀeret web         Indicators database, see http://
sites, in one or more of several markup formats. Markup code, de-       data.worldbank.org/node/11.
signed to make the ﬁle self-describing, is included with the data.
The user does not need to supply details of the data structure to the
software reading the data.

    Markup languages that may be used include XML, GML, JSON
and JSONP. Queries are built into the web address. Alternatives to
setting up the query directly may be:

- Use a function such as fromJSON() in the RJSONIO package to
   set up the link and download the data;

- In a few cases, functions have been provided in R packages that
   assist selection and downloading of data. For the World Bank
   Development Indicators database, note WDI() and other functions
   in the WDI package.

Download of NZ earthquake data: Here the GML markup conven-             WFS is Web Feature Service. OGC is
tions are used, as deﬁned by the WFS OGC standard. Details can be       Open Geospatial Consortium. GML is
found on the website http://info.geonet.org.nz/display/                 Geographic Markup language GML,
appdata/Earthquake+Web+Feature+Service                                  based on XML.

    The following extracts earthquake data from the New Zealand         The .csv format is one of several
GeoNet website. Data is for 1 September 2009 onwards, through           formats in which data can be retrieved.
until the current date, for earthquakes of magnitude greater than 4.5.

## Input data from internet
from <-

   paste(c("http://wfs-beta.geonet.org.nz/",
                  "geoserver/geonet/ows?service=WFS",
                  "&version=1.0.0",
                  "&request=GetFeature",
                  "&typeName=geonet:quake",
                  "&outputFormat=csv",
                  "&cql_filter=origintime >='2009-08-01'",
                  "+AND+magnitude >4.5"),

              collapse="")
quakes <- read.csv(from)
z <- strsplit(as.character(quakes$origintime),
                                                                     data input and storage 93

                         split="T")
quakes$Date <- as.Date(sapply(z, function(x)x[1]))
quakes$Time <- sapply(z, function(x)x[2])

World Bank data — using the WDI package Use the function
WDIsearch() to search for indicators. Thus, to search for indica-
tors with “CO2” in their name, enter WDIsearch(’co2’). Here are
the ﬁrst 4 (out of 38) that are given by such a search:

library(WDI)

WDIsearch('co2')[1:4,]

         indicator
[1,] "EN.ATM.CO2E.CP.KT"
[2,] "EN.CO2.TRAN.ZS"
[3,] "EN.CO2.TRAN.MT"
[4,] "EN.CO2.OTHX.ZS"

         name
[1,] "CO2 emissions from cement production (thousand metric tons)"
[2,] "CO2 emissions from transport (% of total fuel combustion)"
[3,] "CO2 emissions from transport (million metric tons)"
[4,] "CO2 emissions from other sectors , excluding residential buildings and commercial and public

Use the function WDI() to input indicator data, thus:

library(WDI)
inds <- c('SP.DYN.TFRT.IN','SP.DYN.LE00.IN', 'SP.POP.TOTL',

 'NY.GDP.PCAP.CD', 'SE.ADT.1524.LT.FE.ZS')
indnams <- c("fertility.rate", "life.expectancy", "population",

                       "GDP.per.capita.Current.USD", "15.to.25.yr.female.literacy")
names(inds) <- indnams
wdiData <- WDI(country="all",indicator=inds, start=1960, end=2013, extra=TRUE)
colnum <- match(inds, names(wdiData))
names(wdiData)[colnum] <- indnams
## Drop unwanted "region"
WorldBank <- droplevels(subset(wdiData , !region %in% "Aggregates"))

The eﬀect of extra=TRUE is to include the additional variables       The function WDI() calls the non-
iso2c (2-character country code), country, year, iso3c (3-           visible function wdi.dl(), which in
character country code), region, capital, longitude, latitude,       turn calls the function fromJSON()
income and lending.
                                                                     from the RJSONIO package. To
    The data frame Worldbank that results is in a form where it      see the code for wdi.dl(), type
can be used with the googleVIS function gvisMotionChart(), as        getAnywhere("wdi.dl").
described in Section 7.5.1

5.3 Creating and Using Databases                                     In addition to the RSQLite, note the
                                                                     RMySQL and ROracle packages. All
The RSQLite package makes it possible to create an SQLite            use the interface provided by the DBI
database, or to add new rows to an existing table, or to add new     package.
table(s), within an R session. The SQL query language can then
be used to access tables in the database. Here is an example. First
create the database:
94 learning and exploring r

library(DAAG)
library(RSQLite)
driveLite <- dbDriver("SQLite")
con <- dbConnect(driveLite , dbname="hillracesDB")
dbWriteTable(con, "hills2000", hills2000 ,

                       overwrite=TRUE)
dbWriteTable(con, "nihills", nihills ,

                       overwrite=TRUE)
dbListTables(con)

[1] "hills2000" "nihills"

The database hillracesDB, if it does not already exist, is created in
the working directory.

    Now input rows 16 to 20 from the newly created database:

## Get rows 16 to 20 from the nihills DB
dbGetQuery (con ,

   "select * from nihills limit 5 offset 15")

   dist climb time timef
1 5.5 2790 0.9483 1.2086
2 11.0 3000 1.4569 2.0344
3 4.0 2690 0.6878 0.7992
4 18.9 8775 3.9028 5.9856
5 4.0 1000 0.4347 0.5756

dbDisconnect(con)

5.4 ∗File compression:                                                   Severer compression: replace
                                                                           gzip -9
The functions for data input in versions 2.10.0 and later of R are able
to accept certain types of compressed ﬁles. This extends to scan()       by
and to functions such as read.maimages() in the limma package,             xz -9e.
that use the standard R data input functions.

    By way of illustration, consider the ﬁles coral551.spot, . . . ,
coral556.spot that are in the subdirectory doc of the DAAGbio pack-
age. In a directory that held the uncompressed ﬁles, they were cre-
ated by typing, on a Unix or Unix-like command line:

gzip -9 coral55?.spot

The .zip ﬁles thus created were renamed back to *.spot ﬁles.
    When saving large objects in image format, specify

compress=TRUE. Alternatives that may lead to more compact ﬁles
are compress="bzip2" and compress="xz".

    Note also the R functions gzfile() and xzfile() that can
be used to create ﬁles in a compressed text format. This might for
example be text that has been input using readLines().

5.5 Summary

  Following input, perform minimal checks that values in the vari-
  ous columns are as expected.
                                                                       data input and storage 95

With very large ﬁles, it can be helpful to read in the data in chunks
(ranges of rows).

Note mechanisms for direct input of web data. Many data archives
now oﬀer one or more of several markup formats that facilitate
selective access.
96 learning and exploring r
6
Data Manipulation and Management
  98 learning and exploring r                                               Data summaries that can lead to mis-
                                                                            leading inferences arise often, from
      Data analysis has as its end point the use of forms of data sum-      a unbalance in the data and/or failure
  mary that will convey, fairly and succinctly, the information that is in  to account properly for important
  the data. The ﬁtting of a model is itself a form of data summary.         variables or factors.

      Be warned of the opportunities that simple forms of data sum-         A data frame is a list of column
  mary, which seem superﬁcially harmless, can oﬀer for misleading           objects, all of the same length.
  inferences. These issues aﬀect, not just data summary per se, but         1 Internally, matrices are one long
  all modeling. Data analysis is a task that should be undertaken with      vector in which the columns follow
  critical faculties fully engaged.                                         one after the other.

 Alternative types of data objects                                          2 These include lme4, the Bioconduc-
                                                                            tor packages, and the spatial analysis
Column objects: These include (atomic) vectors, factors, and dates.         packages.
Date and date-time objects: The creation and manipulations of date

  objects will be described below.
Data Frames: These are rectangular structures. Columns may be

  “atomic” vectors, or factors, or other objects (such as dates) that are
  one-dimensional.
Matrices and arrays: Matrices1 are rectangular arrays in which
  all elements have the same mode. An array is a generalization of a
  matrix to allow an arbitrary number of dimensions.
Tables: A table is a specialized form of array.
Lists: A list is a collection of objects that can be of arbitrary class.
  List elements are themselves lists. In more technical language, lists
  are recursive data structures.
S3 model objects: These are lists that have a deﬁned structure.
S4 objects: These are specialized data structures with tight control
  on the structure. Unlike S3 objects, they cannot be manipulated as
  lists. Modeling functions in certain of the newer packages2 return S4
  objects.

 6.1 Manipulations with Lists, Data Frames and
        Arrays

  Recall that data frames are lists of columns that all have the same
  length. They are thus a specialised form of list. Matrices are two-
  dimensional arrays. Tables are in essence arrays that hold numeric
  values.

 6.1.1 Tables and arrays

  The dataset UCBAdmissions is stored as a 3-dimensional table. If
  we convert it to an array, very little changes:

      It changes from a table object to a numeric object, which aﬀects
  the way that it is handled by some functions. In either case, what we
  have is a numeric vector of length 24 (= 2 × 2 × 6) that is structured
  to have dimensions 2 by 2 by 6.
                                                   data manipulation and management 99

6.1.2 Conversion between data frames and tables

The three-way table UCBAdmissions are admission frequencies, by
Gender, for the six largest departments at the University of Califor-
nia at Berkeley in 1973. For a reference to a web page that has the
details; see the belp page for UCBAdmissions. Type

help(UCBAdmissions)     # Get details of the data

example(UCBAdmissions)

Note the margins of the table:

str(UCBAdmissions)

'table' num [1:2, 1:2, 1:6] 512 313 89 19 353 207 17 8 120 205 ...
- attr(*, "dimnames")=List of 3

 ..$ Admit : chr [1:2] "Admitted" "Rejected"
 ..$ Gender: chr [1:2] "Male" "Female"
 ..$ Dept : chr [1:6] "A" "B" "C" "D" ...

    In general, operations with a table or array are easiest to                 As UCBAdmissions is
conceptualise if the table is ﬁrst converted to a data frame in                 a table (not an array),
which the separate dimensions of the table become columns.                      as.data.frame(UCBAdmissions)
Thus, the UCBAdmissions table will be converted to a data                       will give the same result.
frame that has columns Admit, Gender and Dept. Either use the
as.data.frame.table() command from base R, or use the
adply() function from the plyr package.

    The following uses the function as.data.frame.table() to
convert the 3-way table UCBAdmissions into a data frame in which
the margins are columns:

UCBdf <- as.data.frame.table(UCBAdmissions)
head(UCBdf, 5)

         Admit Gender Dept Freq
1 Admitted Male A 512
2 Rejected Male A 313
3 Admitted Female A 89
4 Rejected Female A 19
5 Admitted Male B 353

   Alternatively, use the function adply() from the plyr package that is de-
   scribed in Section 6.2. Here the identity() function does the manipulation,
   working with all three dimensions of the array:

    library(plyr)
    UCBdf <- adply(.data=UCBAdmissions ,

                               .margins=1:3,
                               .fun=identity)
    names(UCBdf)[4] <- "Freq"

First, calculate overall admission percentages for females and males.
The following calculates also the total accepted, and the total who
applied:

library(dplyr)
100 learning and exploring r

gpUCBgender <- dplyr::group_by(UCBdf, Gender)
AdmitRate <- dplyr::summarise(gpUCBgender ,

                                                      Accept=sum(Freq[Admit=="Admitted"]),
                                                      Total=sum(Freq),
                                                      pcAccept=100*Accept/Total)
AdmitRate

# A tibble: 2 x 4

Gender Accept Total pcAccept

<fct> <dbl> <dbl> <dbl>

1 Male  1198 2691             44.5

2 Female 557 1835             30.4

    Now calculate admission rates, total number of females applying,
and total number of males applying, for each department:

gpUCBgd <- dplyr::group_by(UCBdf, Gender , Dept)
rateDept <- dplyr::summarise(gpUCBgd ,

       Total=sum(Freq),
       pcAccept =100 * sum ( Freq [ Admit == " Admitted "])/ Total )

    Results can conveniently be displayed as follows. First show
admission rates, for females and males separately:

xtabs(pcAccept~Gender+Dept, data=rateDept)

        Dept

Gender        ABCDE                               F
                                           5.898
Male 62.061 63.036 36.923 33.094 27.749    7.038

Female 82.407 68.000 34.064 34.933 23.919

   Now show total numbers applying:

xtabs(Total~Gender+Dept, data=rateDept)

        Dept

Gender  ABCDEF

Male 825 560 325 417 191 373

Female 108 25 593 375 393 341

    As a fraction of those who applied, females were strongly fa-     The overall bias arose because males
vored in department A, and males somewhat favored in departments      favored departments where admission
C and E. Note however that relatively many males applied to A and     rates were relatively high.
B, where admission rates were high. This biased overall male rates
upwards. Relatively many females applied to C, D and F, where
rates were low. This biased the overall female rates downwards.

6.1.3 Table margins                                                   Take margin 2, ﬁrst, then margin 1,
                                                                      gving a table where rows correspond
For working directly on tables, note the function margin.table().     to levels of Gender.
The following retains margin 1 (Admit) and margin 2 (Gender),
adding over Dept (the remaining margin):

## Tabulate by Admit (margin 2) & Gender (margin 1)
(margin21 <- margin.table(UCBAdmissions ,

                                               margin=2:1))
                           data manipulation and management 101

        Admit

Gender Admitted Rejected

Male           1198  1493

Female         557 1278

    Use the function margin.table() to turn this into a table that
has the proportions in each row:

prop.table(margin21 , margin=1)

        Admit

Gender Admitted Rejected

Male    0.4452 0.5548

Female 0.3035 0.6965

6.1.4 Categorization of continuous data                                  The dataset bronchit may alterna-
                                                                         tively be found in the SMIR package.
The data frame bronchit, in the DAAGviz package, has observa-
tions on 212 men in a sample of Cardiﬀ (Wales, UK) enumeration           The argument breaks can be either
districts. Variables are r (1 if respondent suﬀered from chronic bron-   the number of intervals, or it can be
chitis and 0 otherwise), cig (number of cigarettes smoked per day)       a vector of break points such that
and poll (the smoke level in the locality).                              all data values lie within the range
                                                                         of the breaks. If the smallest of the
    It will be convenient to deﬁne a function props that calculates      break points equals the smallest
the proportion of the total in the ﬁrst (or other nominated element) of  data value, supply the argument
a vector:                                                                include.lowest=TRUE.

props <- function(x, elem=1)sum(x[elem])/sum(x)                          It was at one time common practice to
                                                                         categorize continuous data, in order to
Now use the function cut() to classify the data into four categories,    allow analysis methods for multi-way
and form tables:                                                         tables. There is a loss of information,
                                                                         which can at worst be serious.
library(DAAGviz)
catcig <- with(bronchit ,                                                Note that if t() is used with a data
                                                                         frame, a matrix is returned. If neces-
                           cut(cig, breaks=c(0,1,10,30),                 sary, all values are coerced to the same
                                  include.lowest=TRUE))                  mode.

tab <- with(bronchit , table(r, catcig))
round(apply(tab, 2, props, elem=2), 3)

   [0,1] (1,10] (10,30]
   0.072 0.281 0.538

There is a clear increase in the risk of bronchitis with the number of
cigarettes smoked.

    This categorization was purely for purposes of preliminary analy-
sis. Categorization for purposes of analysis is, with the methodology
and software that are now available, usually undesirable. Tables
that are based on categorization can nevertheless be useful in data
exploration.

6.1.5 ∗Matrix Computations

Let X (n by p), Y (n by p) and B (p by k) be numeric matrices. Some
of the possibilities are:
102 learning and exploring r

X+Y          # Elementwise addition
X*Y          # Elementwise multiplication
X %*% B      # Matrix multiplication
solve(X, Y)  # Solve X B = Y for B
svd(X)       # Singular value decomposition
qr(X)        # QR decomposition
t(X)         # Transpose of X

    Calculations with data frames that are slow and time consuming         Section 4.3.7 will discuss the use
will often be much faster if they can be formulated as matrix calcula-     of apply() for operations with
tions. This is in general become an issue only for very large datasets,    matrices, arrays and tables.
with perhaps millions of observations. Section 6.4 has examples. For
small or modest-sized datasets, convenience in formulating the cal-
culations is likely to be more important than calculation eﬃciency.

6.2 plyr, dplyr & reshape2 Data Manipulation

The plyr package has functions that together:

• provide a systematic approach to computations that perform a
   desired operation across one or more dimensions of an array, or of
   a data frame, or of a list;

• allow the user to choose whether results will be returned as an
   array, or as a data frame, or as a list.

    The dplyr package has functions for performing various sum-
mary and other operations on data frames. For many purposes, it
supersedes the plyr package.

    The reshape2 package is, as its name suggests, designed for
moving between alternative data layouts.

6.2.1 plyr

The plyr package has a separate function for each of the nine possi-
ble mappings. The ﬁrst letter of the function name (one of a = array,
d = data frame, l = list) denotes the class of the input object, while
the second letter (the same choice of one of three letters) denotes
the class of output object that is required. This pair of letters is then
followed by ply.

    Here is the choice of functions:

                                   Class of Output Object
                            a (array) d (data frame) l (list)

Class of Input Object       aaply  adply  alply
               a (array)    daply  ddply  dlply
                            laply  ldply  llply
        d (data frame)
                  l (list)

    First observe how the function adply can be used to change
from a tabular form of representation to a data frame. The dimension
names will become columns in the data frame.
                                                                     data manipulation and management 103

detach("package:dplyr")
library(plyr)

dreamMoves <-
     matrix(c(5,3,17,85), ncol=2,
                  dimnames=list("Dreamer"=c("Yes","No"),
                                           "Object"=c("Yes","No")))

(dfdream <- plyr::adply(dreamMoves , 1:2,
                                           .fun=identity))

   Dreamer Object V1
1 Yes Yes 5
2 No Yes 3
3 Yes No 17
4 No No 85

    To get the table back, do:

plyr::daply(dfdream , 1:2, function(df)df[,3])

            Object
Dreamer Yes No

       Yes 5 17
       No 3 85

    The following calculates sums over the ﬁrst two dimensions of      Here, aaply() behaves exactly like
the table UCBAdmissions:                                               apply().

plyr::aaply(UCBAdmissions , 1:2, sum)                                  Notice the use of the syntax .(trt,
                                                                       black) to identify the columns trt
       Gender                                                          and black. This is an alternative to
                                                                       c("trt", "black").
Admit  Male Female

Admitted 1198 557

Rejected 1493 1278

    The following calculates, for each level of the column trt in the
data frame nswdemo, the number of values of re74 that are zero:

library(DAAG, quietly=TRUE)
plyr::daply(nswdemo , .(trt),

           function(df)sum(df[,"re74"]==0, na.rm=TRUE))

   01
195 131

To calculate the proportion that are zero, for each of control and
treatment and for each of non-black and black, do:

options(digits=3)
plyr::daply(nswdemo , .(trt, black),

           function(df)sum(df[,"re75"]==0)/nrow(df))

     black
trt 0 1

   0 0.353 0.435
   1 0.254 0.403
104 learning and exploring r

    The function colwise() takes as argument a function that op-          Here, colwise() operates on the
erates on a column of data, returning a function that operates on
all nominated columns of a data frame. To get information on the          objects that are returned by splitting
proportion of zeros for both of the columns re75 and re78, and for        up the data frame nswdemo according
each of non-black and black, do:                                          to levels of trt and black. Note the
                                                                          use of ddply(), not daply().
plyr::ddply(nswdemo , .(trt, black),
           colwise(function(x)sum(x==0)/length(x),
                         .cols=.(re75, re78)))

trt black re75 re78

10      0 0.353 0.1529

20      1 0.435 0.3412

31      0 0.254 0.0847

41      1 0.403 0.2605

6.2.2 Use of dplyr with Word War 1 cricketer data                         Both plyr and dplyr have functions
                                                                          summarise(). As in the code
Data in the data frame cricketer, extracted by John Aggleton (now         shown, detach plyr before proceeding.
at Univ of Cardiﬀ), are from records of UK ﬁrst class cricketers born     Alternatively, or additionally, specify
1840 – 1960. Variables are                                                dplyr::summarise() rather than
                                                                          summarise()
- Year of birth
- Years of life (as of 1990)                                              Note that a cricketer who was born
- 1990 status (dead or alive)                                             in 1869 would be 45 in 1914, while a
- Cause of death: killed in action / accident / in bed                    cricketer who was born in 1896 would
- Bowling hand – right or left                                            be 18 in 1914.

The following creates a data frame in which the ﬁrst column has the
year, the second the number of right-handers born in that year, and
the third the number of left-handers born in that year. .

library(DAAG)
detach("package:plyr")
library(dplyr)

names(cricketer)[1] <- "hand"
gpByYear <- group_by(cricketer , year)
lefrt <- dplyr::summarise(gpByYear ,

                                               left=sum(hand=='left'),
                                               right=sum(hand=='right'))
## Check first few rows
lefrt[1:4, ]

# A tibble: 4 x 3

year left right

<int> <int> <int>

1 1840 1 6

2 1841  4 16

3 1842  5 16

4 1843  3 25

The data frame is split by values of year. Numbers of left and right
handers are then tabulated.
                                           data manipulation and management 105

    From the data frame cricketer, we determine the range of birth
years for players who died in World War 1. We then extract data for
all cricketers, whether dying or surviving until at least the ﬁnal year
of Workd War 1, whose birth year was within this range of years.
The following code extracts the relevant range of birth years.

## Use subset() from base R
ww1kia <- subset(cricketer ,

                               kia==1 & (year+life)%in% 1914:1918)
range(ww1kia$year)

[1] 1869 1896

    Alternatively, use filter() from dplyr:

ww1kia <- filter(cricketer ,
                               kia==1, (year+life)%in% 1914:1918)

    For each year of birth between 1869 and 1896, the following
expresses the number of cricketers killed in action as a fraction of
the total number of cricketers (in action or not) who were born in
that year:

## Use filter(), group_by() and summarise() from dplyr
crickChoose <- filter(cricketer ,

                                        year%in%(1869:1896), ((kia==1)|(year+life)>1918))
gpByYearKIA <- group_by(crickChoose , year)
crickKIAyrs <- dplyr::summarise(gpByYearKIA ,

                                                          kia=sum(kia), all=length(year), prop=kia/all)
crickKIAyrs[1:4, ]

# A tibble: 4 x 4

year kia all prop

<int> <int> <int> <dbl>

1 1869  1 37 0.0270

2 1870  2 36 0.0556

3 1871  1 45 0.0222

4 1872  0 39 0

   For an introduction to dplyr, enter:

vignette("introduction", package="dplyr")

6.2.3 reshape2: melt(), acast() & dcast()

The reshape2 package has functions that move between a dataframe
layout where selected columns are unstacked, and a layout where
they are stacked. In moving from an unstacked to a stacked layout,
column names become levels of a factor. In the move back from
stacked to unstacked, factor levels become column names.

    Here is an example of the use of melt():

## Create dataset Crimean , for use in later calculations
library(HistData) # Nightingale is from this package
library(reshape2) # Has the function melt()
Crimean <- melt(Nightingale[,c(1,8:10)], "Date")
106 learning and exploring r

names(Crimean) <- c("Date", "Cause", "Deaths")
Crimean$Cause <- factor(sub("\\.rate", "", Crimean$Cause))
Crimean$Regime <- ordered(rep(c(rep('Before', 12), rep('After', 12)), 3),

                                               levels=c('Before', 'After'))
formdat <- format.Date(sort(unique(Crimean$Date)), format="%d %b %y")
Crimean$Date <- ordered(format.Date(Crimean$Date,

                                           format="%b %y"), levels=formdat)

The dataset is now in a suitable form for creating a Florence          The dataset Crimean has been
Nightingale style wedge plot, in Figure C.3.                           included in the DAAGviz package.

Reshaping data for Motion Chart display – an example

The following inputs and displays World Bank Development Indica-
tor data that has been included with the package DAAGviz:

## DAAGviz must be installed , need not be loaded
path2file <- system.file("datasets/wdiEx.csv", package="DAAGviz")
wdiEx <- read.csv(path2file)
print(wdiEx, row.names=FALSE)

Country.Name Country.Code     Indicator.Name Indicator.Code X2010 X2000

Australia     AUS Labor force, total SL.TLF.TOTL.IN 1.17e+07 9.62e+06

Australia     AUS Population , total SP.POP.TOTL 2.21e+07 1.92e+07

China         CHN Labor force, total SL.TLF.TOTL.IN 8.12e+08 7.23e+08

China         CHN Population , total SP.POP.TOTL 1.34e+09 1.26e+09

    A googleVis Motion Chart does not make much sense for this         3 Note also acast(), which outputs
dataset as it stands, with data for just two countries and two years.  an array or a matrix.
Motion charts are designed for showing how scatterplot relation-
ships, here between forest area and population, have changed over a
number of years. The dataset will however serve for demonstrating
the reshaping that is needed.

    For input to Motion Charts, we want indicators to be columns,
and years to be rows. The melt() and dcast()3 functions from the
reshape2 package can be used to achieve the desired result. First,
create a single column of data, indexed by classifying factors:

library(reshape2)
wdiLong <- melt(wdiEx, id.vars=c("Country.Code",

                             "Indicator.Name"),
                             measure.vars=c("X2000", "X2010"))
## More simply: wdiLong <- melt(wdiEx[, -c(2,4)])
wdiLong

Country.Code  Indicator.Name variable value

1 AUS Labor force, total X2000 9.62e+06

2 AUS Population , total X2000 1.92e+07

3 CHN Labor force, total X2000 7.23e+08

4 CHN Population , total X2000 1.26e+09

5 AUS Labor force, total X2010 1.17e+07

6 AUS Population , total X2010 2.21e+07

7 CHN Labor force, total X2010 8.12e+08

8 CHN Population , total X2010 1.34e+09

    Now use dcast() to “cast” the data frame into a form where the     If a matrix or array is required, use
indicator variables are columns:                                       acast() in place of dcast().
                                                                    data manipulation and management 107

names(wdiLong)[3] <- "Year"
wdiData <- dcast(wdiLong ,

                              Country.Code+Year ~ Indicator.Name ,
                              value.var="value")
wdiData

Country.Code Year Labor force, total Population , total

1 AUS X2000  9.62e+06  1.92e+07

2 AUS X2010  1.17e+07  2.21e+07

3 CHN X2000  7.23e+08  1.26e+09

4 CHN X2010  8.12e+08  1.34e+09

    A ﬁnal step is to replace the factor Year by a variable that has the
values 2000 and 2010.

wdiData <- within(wdiData , {
     levels(Year) <- substring(levels(Year),2)
     Year <- as.numeric(as.character(Year))

})
wdiData

Country.Code Year Labor force, total Population , total

1 AUS 2000   9.62e+06  1.92e+07

2 AUS 2010   1.17e+07  2.21e+07

3 CHN 2000   7.23e+08  1.26e+09

4 CHN 2010   8.12e+08  1.34e+09

6.3 Session and Workspace Management                                      Be sure to save the script ﬁle from
                                                                          time to time during the session, and
6.3.1 Keep a record of your work                                          upon quitting the session.

A recommended procedure is to type commands into an editor                Use getwd() to check the name and
window, then sending them across to the command line. This makes          path of the current working directory.
it possible to recover work on those hopefully rare occasions when        Use setwd() to change to a new
the session aborts.                                                       working directory, while leaving the
                                                                          workspace contents unchanged.
6.3.2 Workspace management

For tasks that make heavy memory demands, it may be important to
ensure that large data objects do not remain in memory once they are
no longer needed. There are two complementary strategies:

- Objects that cannot easily be reconstructed or copied from else-
   where, but are not for the time being required, are conveniently
   saved to an image ﬁle, using the save() function.

- Use a separate working directory for each major project.

    Note the utility function dir() (get the names of ﬁles, by default
in the current working directory).

    Several image ﬁles (“workspaces”) that have distinct names can
live in the one working directory. The image ﬁle, if any, that is called
.RData is the ﬁle whose contents will be loaded at the beginning of
a new session in the directory.
108 learning and exploring r                                              As noted in Section 2.2.2, a good
                                                                          precaution can be to make an archive
The removal of clutter: Use a command of the form rm(x, y,                of the workspace before such removal.
tmp) to remove objects (here x, y, tmp) that are no longer required.
                                                                          4 Dumps of S4 objects and environ-
Movement of ﬁles between computers: Files that are saved in the           ments, amongs others, cannot cur-
default binary save ﬁle format, as above, can be moved between            rently be retrieved using source().
diﬀerent computer systems.                                                See help(dump).

Further possibilities – saving objects in text form: An alternative to    5 The same checks are performed
saving objects4 in an image ﬁle is to dump them, in a text format, as     on dump ﬁles as if the text had been
dump ﬁles, e.g.                                                           entered at the command line. These
                                                                          can slow down entry of the data or
volume <- c(351, 955, 662, 1203, 557, 460)                                other object. Checks on dependencies
weight <- c(250, 840, 550, 1360, 640, 420)                                can be a problem. These can usually
dump(c("volume", "weight"), file="books.R")                               be resolved by editing the R source
                                                                          ﬁle to change or remove oﬀending
The objects can be recreated 5 from this “dump” ﬁle by inputting          code.
the lines of books.R one by one at the command line. This is what,
eﬀectively, the command source() does.

source("books.R")

    For long-term archival storage, dump (.R) ﬁles may be prefer-
able to image ﬁles. For added security, retain a printed version. If a
problem arises (from a system change, or because the ﬁle has been
corrupted), it is then possible to check through the ﬁle line by line to
ﬁnd what is wrong.

6.4 Computer Intensive Computations                                       The computationally intensive parts
                                                                          of regression calculations with lm()
Computations may be computer intensive because of the size of             work with matrices, making these
datasets. Or the computations may themselves be demanding, even           relatively eﬃcient.
for data sets that are of modest size.
                                                                          The relatively new Julia language
    Note that using all of the data for an analysis or for a plot is not  appears to oﬀer spectacular im-
always the optimal strategy. Running calculations separately on           provements on both R and Python,
diﬀerent subsets may aﬀord insights that are not otherwise available.     with times that are within a factor
The subsets may be randomly chosen, or they may be chosen to              of 2 of the Fortran or C times. See
reﬂect, e.g., diﬀerences in time or place.                                http://julialang.org/.

    Computation will be slow where computationally intensive cal-
culations are implemented directly in R code, rather than passed to
eﬃcient compiled code that is called from R. Matrix calculations are
passed to highly eﬃcient compiled code.

    Where it is necessary to look for ways to speed up computations,
it is important to proﬁle computations to ﬁnd which parts of the code
are taking the major time. Really big improvements will come from
implementing key parts of the calculation in C or Fortran rather than
in an application oriented language such as R or Python. Python may
do somewhat better than R.

    There can be big diﬀerences between the alternatives that may be
available in R for handling a calculation. Some broad guidelines will
now be provided, with examples of how diﬀerences in the handling
of calculations can aﬀect timings.
                                                              data manipulation and management 109

Use matrices, where possible, in preference to data frames: Most        Biological expression array appli-
of R’s modeling functions (regression, smoothing, discriminant          cations are among those that are
analysis, etc.) are designed to work with data frames. Where an         commonly designed to work with data
alternative available that works with matrices, this will be faster.    that is in a matrix format. The matrix
                                                                        or matrices may be components of a
    Matrix operations can be more eﬃcient even for such a simple        more complex data structure.
operation as adding a constant quantity to each element of the array,
or taking logarithms of all elements. Here is an example:               Timings are on a mid 2012 1.8 Ghz
                                                                        Intel i5 Macbook Air laptop with 8
xy <- matrix(rnorm(5*10^7), ncol=100)                                   gigabytes of random access memory.
dim(xy)

[1] 500000 100

system.time(xy+1)

     user system elapsed
   0.138 0.122 0.261

xy.df <- data.frame(xy)
system.time(xy.df+1)

 user system elapsed
0.436 0.159 0.814

Use eﬃcient coding: Matrix arithmetic can be faster than the
equivalent computations that use apply(). Here are timings for
some alternatives that ﬁnd the sums of rows of the matrix xy above:

   apply(xy,1,sum)        user  system  elapsed
xy %*% rep(1,100)        0.528   0.087    0.617
                         0.019   0.001    0.019
         rowSums(xy)     0.034   0.001    0.035

The bigmemory project: For details, go to http://www.
bigmemory.org/. The bigmemory package for R “supports the cre-
ation, storage, access, and manipulation of massive matrices”. Note
also the associated packages biganalytics, bigtabulate, synchronicity,
and bigalgebra.

The data.table package: This allows the creation of data.table          On 64-bit systems, massive data sets,
objects from which information can be quickly extracted, often in       e.g., with tens or hundreds of millions
a fraction of the time required for extracting the same information     of rows, are possible. For such large
from a data frame. The package has an accompanying vignette. To         data objects, the time saving can be
display it (assuming that the package has been installed), type         huge.

vignette("datatable-intro", package="data.table")

6.5 Summary

  apply(), and sapply() can be useful for manipulations with
  data frames and matrices. Note also the functions melt(),
  dcast() and acast() from the reshape2 package.
110 learning and exploring r

  Careful workspace management is important when ﬁles are large.
  It pays to use separate working directories for each diﬀerent
  project, and to save important data objects as image ﬁles when
  they are, for the time being, no longer required.

  In computations with large datasets, operations that are formally
  equivalent can diﬀer greatly in their use of computational re-
  sources.
7
Graphics – base, lattice, ggplot2, rgl, googleVis. . .
112 learning and exploring r                                             The function plot() accepts a
                                                                         data argument, while lines(),
Base Graphics (mostly 2-D):                                              points() and text() do not.
  Base graphics implements a “traditional” style of graphics
  Functions plot(), points(), lines(), text(),                           lattice and ggplot2 are built on the
                 mtext(), axis(),identify() etc. form                    low-level graphics package grid.
                 a suite that plot points, lines, text, etc.
                                                                           Note also various special types of
Other Graphics                                                           graph. For example word clouds, as
     (i) lattice (trellis) graphics, using the lattice package,          in the wordcloud package, list words
     (ii) ggplot2, implementing Wilkinson’s Grammar of Graphics          with size proportional to frequency.
     (iii) For 3-D graphics (Section 7.5), note rgl, misc3d & tkrplot
     (iv) Motion Charts (Section 7.5.1), show a scatterplot changing
     with movement forward or backward in time.

    Consider ﬁrst base graphics. Relative to lattice and to ggplot2,
the more traditional style of base graphics is less consistent and less
structured. Each system however has its own strengths and uses.

## DAAG has several datasets that will be required
library(DAAG, quietly=TRUE)

7.1 Base Graphics                                                        To see a variety of base (or traditional)
                                                                         graphics plots, enter
The function plot() is the most basic of several functions that
create an initial graph. Other functions can be used to add to an        demo(graphics)
existing graph. Note in particular points() lines() and text().
                                                                         Press Enter to see each new graph.
7.1.1 plot() and allied base graphics functions
                                                                         Plot height vs weight –
The following are alternative ways to plot y against x (obviously x
and y must be the same length):                                          ## Older syntax:
                                                                         with(women ,
plot(y ~ x) # Use a formula to specify the graph
plot(x, y) # Horizontal ordinate, then vertical                                   plot(height, weight))

    The following use the argument data to supply the name of a          ## Graphics formula:
data frame whose column names appear in the graphics formula:            plot(weight ~ height,

plot(distance ~ stretch, data=elasticband)                                        data=women)
plot(ACT ~ year, data=austpop , type="l")
plot(ACT ~ year, data=austpop , type="b")                                1 These functions diﬀer only in the
                                                                         default setting for the parameter type.
    The points() function adds points, while lines() adds lines1         Explicitly setting type = "p" causes
to a plot. The text() function adds text at speciﬁed locations. The      either function to plot points.
mtext() function places text in one of the margins. The axis()
function gives ﬁne control over axis ticks and labels.

    Here is a further possibility

with(austpop , plot(spline(year, ACT), type="l"))
   # Fit smooth curve through points
                          graphics – base, lattice, ggplot2, rgl, googlevis. . . 113

Adding text – an example

Here is a simple example (Figure 7.1) that uses the function text()      Brain weight (g)  1500  q Human
to label the points on a plot. Data is from the dataset primates                           1000
(DAAG). The ﬁrst two lines of data are:

## Data (1st 2 lines)
head(primates , 2)

         Bodywt Brainwt

Potar monkey 10 115

Gorilla  207 406                                                                           500 q Chimp                           q Gorilla

    Code for a simpliﬁed version of the plot is:                                                    qq RPhoetasrums omnoknekyey
                                                                                              0
plot(Brainwt ~ Bodywt , xlim=c(0, 300),
         ylim=c(0,1500), data=primates , fg="gray",                                              0 50 100 150 200 250 300
         xlab="Body weight (kg)",
         ylab="Brain weight (g)")                                                                Body weight (kg)

# Specify xlim to allow room for the labels                              Figure 7.1: Plot of brain weight
with(primates ,                                                          against body weight, for selected
                                                                         primates.
         text(Brainwt ~ Bodywt , cex=0.8,
                  labels=rownames(primates), pos=4))

# pos: pos=1 (below), 2 (left), 3 (above)

Identiﬁcation and Location on the Figure Region                          Section 1.5 described how to terminate
                                                                         the plot, if the limit n is not reached
Draw the graph ﬁrst, then call the required function.                    ﬁrst. For locator(), n is by default
                                                                         set to 500.
- identify(), discussed in Subsection 1.5, labels points.
- locator() prints out the co-ordinates of points. Position the          To store existing settings for later
                                                                         restoration, proceed thus:
   cursor at the location for which coordinates are required, and click
   the left mouse button.                                                oldpar <- par(cex=1.25)
                                                                            # par(oldpar) to restore
7.1.2 Fine control – Parameter settings
                                                                         2 Thus par(cex=1.2) increases plot
In most (not all) instances, parameters can be set either using par(),   symbol size 20% above the default.
or in a call to a plotting function (plot(), points(), . . . ). Changes
made using par() remain in place until changed again, or until a         3 The default is xaxs="r"; x-axis
new device is opened. If made in a call to a plotting function, the      limits are extended by 4% relative to
change applies only to that call.                                        data or xlim limits.

    Some of the more common settings are:

- Plotting symbols: pch (choice of symbol); cex ("character expan-
   sion")2; col (color).

- Lines: lty (line type); lwd (line width); col (color).

- Axis limits: xlim; ylim.
- Closeness of ﬁt to the axis limits: xaxs, yaxs.3 Specify

   xaxs="i" for an exact ﬁt to the data limits.

- Axis annotation and labels: cex.axis (for axis annotation, inde-
   pendently of cex); cex.labels (for axis labels).
114 learning and exploring r                                             4 Parameters such as mar, mgp and oma
                                                                         specify distances in ‘lines’ out from
- Margins and positioning within margin:4 mar (inner margins             the relevant boundary of the ﬁgure
   clockwise from bottom, out of box default mar=c(5.1, 4.1,             region. Lines are in units of mex,
   4.1, 2.1)); oma (outer margins, use when there are multiple           where by default mex=1.
   plots on the one graphics page); positioning within margin: mgp
   (margin line for the axis title, axis labels, and axis line, default  5 This must be set using par()
   mgp=c(3, 1, 0)).
                                                                         For a 1 by 2 layout of plots; specify
- Plot shape: pty="s" gives a square plot.5 (default is pty="m")         par(mfrow=c(1,2)). Subsection
                                                                         3.3.1 has an example.
- Multiple graphs on the one graphics page: par(mfrow=c(m,n))
   gives an m rows by n columns layout.

Type help(par) to get a (very extensive) complete list. Figure C.4
demonstrates some of the possibilities.

7.1.3 Color and Opacity

The function colors() gives access to 657 diﬀerent color names,
some of them repeats of the same colour. The function palette()
can be used to show or set colors that will by default be used for
base graphics. Thus

- palette() lists the colors in the current palette;

- as an example, palette(rainbow(6)) sets the current palette to
   a 6-color rainbow palette;

- palette("default") resets back to the default.

    Run the following code to show the default palette, three se-        See help(palette) for palettes in
quential palettes from grDevices, a color ramp palette given by the      the base R grDevices package.
function colorRampPalette(), and two quantitative palettes from
the RColorBrewer package.

## Load to run code for Supplementary Figure 1
library(RColorBrewer) # Required for Set1 and Dark2 RColorBrewer palettes

colpal <- rev(list(
       "Default palette" = palette()[1:8], cm.colors = cm.colors(12),
       terrain.colors = terrain.colors(12), heat.colors = heat.colors(12),
       blueRamp = colorRampPalette(c(blues9, "white"))(12),
       "Brewer-Set1" = brewer.pal(8, "Set1"),
       "Brewer-Dark2" = brewer.pal(8, "Dark2")))

palnam <- names(colpal)
plot(1, 1, xlim=c(0.5,12.5), ylim=c(0,length(palnam)+0.5), type="n",

         axes=FALSE, xlab="", ylab="")
for(i in 1:length(palnam)){

       len <- length(colpal[[i]])
       points(1:len, rep(i,len), pch=15, col=colpal[[i]], cex=5.5)
       legend(1, i+0.025, palnam[i], adj=0, box.col="white", bg="white",

                    x.intersp=0, y.intersp=0, yjust=0)

Each of these palettes, except the default, allows variation in the
number of colors, up to a maximum. The palettes available from
RColorBrewer include other qualitative palettes, sequential palettes,
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        graphics – base, lattice, ggplot2, rgl, googlevis. . . 115

and diverging (light in the middle; dark at the extremes) palettes. To                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Stretch the graphics window vertically
see the full range of RColorBrewer possibilities, type:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       (pull on an edge) so that rows do not
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              overlap.
display.brewer.all ()
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              While limited use of light colors is
Qualitative schemes that may be suited for use in plots are "Set1"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ﬁne for coloring regions on a map,
with yellow (the 6th color out of nine) omitted, or "Dark2", or "Ac-                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          light colors do not show up well when
cent" with the 4th color (out of 8) omitted. To extract these, do for                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         coloring points on a graph.
example:

Set1 <- brewer.pal(8, "Set1")[-6]
## Check out the palette
plot(1:7, pch=16, cex=2, col=Set1)

Opacity, and graphs with many points

            A: 100% opacity                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  B: 40% opacity             25000       C: Color density plot     Figure 7.2: In Panel A, points are
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              plotted with the 100% opacity, i.e., no
25000       qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq  25000                                                                        transparency. In Panel B, alpha=0.4,
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              i.e., 40% opacity. Panel C uses the
re78                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             re78                                   re75                                  function smoothScatter() to show a
     15000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            15000                                  15000                            smoothed color density representation
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              of the data.
0 5000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           0 5000                                 0 5000
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              An opacity of 0.4 has the eﬀect that,
            0 5000       15000  25000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        0 5000       15000  25000              0 5000      15000  25000  for an isolated point, 60% of the white
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              background shows through.
                    re75                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             re75                                   re74
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              The plots show a sample of 3000 of
## Sample from the 15992 rows                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 the points. Plotting all the points gives
dfsamp <- cps1[sample(nrow(cps1), 3000), ]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    an incoveniently large graphics ﬁle,
plot(re78 ~ re75 , data=dfsamp , pch=20, cex=0.5,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             while not giving a more informative
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              graph.
         col="black", las=0, fg="gray")
mtext(side=3, line=0.5, "A: 100% opacity", adj=0)
plot(re78 ~ re75 , data=dfsamp , pch=20, cex=0.5, las=0,

         col=adjustcolor("black", alpha=0.4), fg="gray")
mtext(side=3, line=0.5, "B: 40% opacity", adj=0)
blueRamp <- colorRampPalette(c("white", blues9))
with(dfsamp, smoothScatter(re75~re74, , fg="gray",

                                                 las=0, colramp=blueRamp))
mtext(side=3, line=0.5, "C: Color density plot",

           adj=0)

With alpha=0.4, two overlapping points have a combined opacity
of 80%, so that 20% of the white background shows through. Three
or more overlapping points appear as completely black.

    Compare three plots shown in Figure 7.2. Points overlap to such
an extent that Panel A, gives very limited information about the
density of points. Panel B, where the color opacity is 40%, gives
a better indication of variation in the density of points. Panel C
uses the function smoothScatter() to provide a color density
representation of the scatterplot. This is a more nuanced way to
show the density of points.
116 learning and exploring r

7.1.4 The shape of the graph sheet

Aspect ratio, i.e., the ratio of x-distance to y-distance, has a large say
in what is visually obvious. Figures 7.3A and 7.3B show the same
data: Features that are at an angle that is close to the horizontal or

A: Aspect ratio approx 1:1             B: Aspect ratio approx 1:3.5

 1.0   q       qq      qq       qq      1.0      q                     qq             qq                        q                         q
 0.5  q                          q qq   0.5  q                     qq                                               q                 qq
 0.0                                    0.0                                       q
−0.5  q            q       q           −0.5          q                                        q             q
−1.0                  q                −1.0
          qq                                                                                                            q

                                q

                             q     q                                                                     q                         q
                                                                                                                           qq
          q        qq      q    qq                      q                  qq                    q
            q       q       q                                   q              q                     q

           q                                                q

      0 5 10 15 20 25                        0 5 10 15 20 25

the vertical are hard to detect visually. Patterns of change or other             Figure 7.3: Figures A and B show the
features should, to be visually obvious, be oﬀset by an angle of at               same data, but with widely diﬀerent
least 20◦ from both the horizontal and the vertical.                              aspect ratios.
For each of Figures 7.3A and 7.3B the code, after setting the dimen-
sions of the ﬁgure page, is:

plot((1:30)*0.92, sin((1:30)*0.92),
         xlab="", ylab="")

    The dimensions of the graphics display can be speciﬁed when
a graphics window is opened. Once opened, the shape and size of
a screen device can be changed by clicking and dragging on one
corner.

    The R for Windows functions win.graph() or x11() that set
up the Windows screen take the parameters width (in inches),
height (in inches) and pointsize (in 1/72 of an inch). The set-
ting of pointsize (default =12) determines character heights. It is
the relative sizes that matter for screen display or for incorporation
into Word and similar programs.

7.1.5 Multiple plots on the one page

The parameter mfrow can be used to conﬁgure the graphics sheet                    For a layout in which columns are
so that subsequent plots appear row by row, one after the other in                ﬁlled before moving to a new row, use
a rectangular layout, on the one page. The following presents four                mfcol in place of mfrow.
diﬀerent transformations of data from the dataset Animals (MASS),
in a two by two layout:

## Supplementary figure 9.2

library(MASS)

oldpar <- par(pch=16, pty="s", mfrow=c(2,2))

with(Animals, {                 # bracket several R statements

plot(body, brain)

plot(sqrt(body), sqrt(brain))

plot(body^0.1, brain^0.1)
                                                                   graphics – base, lattice, ggplot2, rgl, googlevis. . . 117

plot(log(body), log(brain))

}) # close both sets of brackets

par(oldpar)  # Restore former settings

    A more ﬂexible alternative is to use the graphics parameter fig
to mark out the part of the graphics page on which the next graph
will appear. The following marks out, successively, a plot region that
occupies the upper 62% of the plot region, then the lower 38%.

par(fig = c(0, 1, 0.38, 1), mgp=c(3,0.5,0))                                                    par(fig = c(0,1,0.38,1))
                  # xleft, xright, ybottom , ytop                                              marks out a plot region that is
                                                                                               the total width, starts 38% of the
## Panel A                                                                                     way up, and extends to the top.
par(fig = c(0, 1, 0, 0.38), new=TRUE)                                                          par(fig=c(0,1,0,0.38),
## Plot graph B                                                                                new=TRUE) marks out the lower 38%
par(fig = c(0, 1, 0, 1)) # Restore settings                                                    of the page.

The eﬀect of new=TRUE is, somewhat counter-intuitively, “assume a
new page is already open; do not open a new page”.

7.1.6 Plots that show the distribution of data values                                          Density plots are much preferable, for
                                                                                               most purposes, to histograms. Both
We discuss histograms, density plots, boxplots and normal prob-                                have limitations.
ability plots. Normal probability plots are a specialised form of
cumulative density plot.

Histograms and density plots

A: Breaks at 72.5, 77.5,...                                        B: Breaks at 75, 80, ...    Figure 7.4: The two panels show the
                                                                                               same data, but with a diﬀerent choice
0.10                                                               0.10                        of breakpoints.
0.08                                                               0.08
0.06                                                               0.06                        The argument freq=FALSE gives a
0.04                                                               0.04                        vertical scale that is the number of
0.02                                                               0.02                        points per unit interval, i.e., it is the
0.00                                                               0.00                        “density” estimate that is given by
                                                                                               the upper bar of each rectangle. This
            75 80 85 90 95                                                 75 80 85 90 95 100  is needed for the superposition of a
Density                                                                                        density curve onto the histogram.
                                                          Density

             Total length                                          Total length

    The shapes of histograms depend on the placement of the breaks,
as illustrated by Figure 7.4. The following code plots the histograms
and superimposes the density plots.

par ( mgp =c (3 ,0 .5 ,0))
ftotlen <- subset(possum , sex=="f")[, "totlngth"]
## Left panel: breaks at 72.5, 77.5,..
hist(ftotlen , breaks = 72.5 + (0:5)*5, freq=FALSE,

         xlab="Total length", ylim=c(0,0.11),
         main ="A: Breaks at 72.5, 77.5,...")
## Now superimpose a density curve, as in Fig. 7.3
lines(density(ftotlen))
##
## Panel B: breaks at 75, 80, ...
hist(ftotlen , breaks = 75 + (0:5)*5, freq=FALSE,
118 learning and exploring r                                              Neither histograms nor density plots
                                                                          are eﬀective for checking normality.
         xlab="Total length", ylim=c(0,0.11),                             For that, use a normal probability plot.
         main="B: Breaks at 75, 80, ...")
                                                                          6 Thus, a failure time distribution will
    The height of each rectangle of a histogram provides a crude den-     have a sharp cutoﬀ at zero, which may
sity estimate. These estimates change in jumps, at breakpoints that       also be the mode.
are inevitably chosen somewhat arbitrarily. A smoothly changing
density estimate, such as given by the superimposed density curves
in the panels of Figure 7.4, makes better sense than an estimate that
changes in jumps.

    Unless samples are very large, the shape of both histograms and
density plots will show large statistical variability. Density plots are
helpful for showing the mode, i.e., the density maximum.

    The following gives a density plot, separately from the his-
tograms that are shown in 7.4.

## Supplementary figure 9.3
with(subset(possum, sex=="f"),

         plot(density(totlngth), type="l"))

    For use of density plots with data that have sharp lower and/or
upper cutoﬀ limits, it may be necessary to specify the x-axis limit or
limits.6 Use the parameters from and/or to for this purpose. This
issue most commonly arises with a lower cutoﬀ at 0.

Boxplots                                                                                 q

Boxplots use a small number of characteristics of a distribution                       75 80 85 90 95
to characterize it. Look up help(boxplot) for details. It can be
insightful to add a “rug” that shows the individual values, by default    Figure 7.5: Distribution of lengths
along the horizontal axis (side=1). Figure 7.5 is an example. Code        of female possums. The vertical bars
for the plot is:                                                          along the x-axis (together making up a
                                                                          ’rug’) show actual data values.
## Code
with(subset(possum, sex=="f"),

         {boxplot(totlngth, horizontal=TRUE)
           rug(totlngth)} )

Normal probability plots                                                  A point pattern that is not consistent
                                                                          with random deviation from a line
The function qqnorm(y) gives a normal probability plot of the             indicates a non-normal distribution.
values of y. In such a plot, data from a normal distribution will be
scattered about a line. To calibrate the eye to recognise plots that
indicate non-normal variation, it helps to compare the plot for the
data in hand with several normal probability plots that use rnorm()
to generate random values. Figure 7.6 is an example.

## Q-Q plot for the data (top left panel)
ftotlen <- subset(possum , sex == "f")[, "totlngth"]
qqnorm(ftotlen, xlab="",

            ylab=expression(bold("Data")))
## Code for a plot with random normal data
qqnorm(rnorm(43), xlab="", ylab="Simulated")
                                                                                                                               graphics – base, lattice, ggplot2, rgl, googlevis. . . 119

                  Normal Q−Q Plot                                                    Q−Q: Simulated                                              Q−Q: Simulated                                                                Q−Q: Simulated

              95                                             q  q                                                              q                                                                     q                      2 qqq q
              90     q qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq                                                                                                                                 q
              85                                                      Simulated  1                                          q     Simulated                                                                     Simulated                                           qqqqqq
              80                                                                 0                                                           2 qq
                                                                                             qqqqqqqqqqqqqqqqqqqqqqqqqqqqq                                                                                                  1 qq
   Data                                                                                                                                      1 qqq                                                                          0 qqqqqqqqqqqqqqqqqqqqq
                                                                                                                                                      qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq                                      −1 qqqqqqqqq
                                                                                 −1 qqqqqqqq                                                  0     qq
                                                                                                                                             −1                                                                                   q

                                                                                         qq                                                  −2 qq                                                                               −2 −1 0 1 2

              75 q                                                               −2 q q                                                          q
                    −2 −1 0 1 2
                                                                                     −2 −1 0 1 2                                                 −2 −1 0 1 2

                  Q−Q: Simulated                                                     Q−Q: Simulated                                              Q−Q: Simulated                                                                Q−Q: Simulated

                                                               qq                2q                                                                                                             q  q                       2.0 q

   Simulated   1                                       qqq            Simulated                               qqqqqq q            Simulated                                                  q                  Simulated  1.5 q
               0               qqqqqqqqqqqqqqqqqqqqqqqqqqqqqq                                qqqqqqqqqqqqqqqqqqqqqqqq                                                                                                                                                 q
              −1     q qqqqqq                                                    1                                                           1 qqqqq                                                                      1.0                  qqqqqqqqqqqqqqqqqqqqqqqqqqqq
              −2                                                                 0                                                           0 qqqqqqqqqqqqqqqqqqqqqqqqqq                                                 0.5    q qqqqqqqqqq
                                                                                                                                                                                                                          0.0
                                                                                 −1            qqq                                           −1              qq                                                          −0.5
                                                                                             qq                                                     q qqqqq                                                              −1.0

                  q                                                              −2 q qqqqq                                                  −2 q                                                                        −1.5 q

                  −2 −1 0 1 2                                                        −2 −1 0 1 2                                                 −2 −1 0 1 2                                                                   −2 −1 0 1 2

There is one unusually small value. Otherwise the points for the                                                                                                                                Figure 7.6: Normal probability plots.
female possum lengths are as close to a straight line as in many of                                                                                                                             The top left panel shows the 43
the plots for random normal data.                                                                                                                                                               lengths of female possums. Other
                                                                                                                                                                                                panels are for independent normal
                                                                                                                                                                                                random samples of size 43.

7.1.7 ∗Plotting Text that Includes Technical Symbols

The functions expression() and substitute() can be used to create                                                                                                                               Axis labels can be expressions, in
mathematical expressions, for later evaluation or for printing onto a                                                                                                                           lattice and ggplot2 as well as in base
graph. For example, expression(x^2) will print, when supplied to                                                                                                                                graphics. Tick labels can for example
text() or mtext() or another such function (this includes lattice                                                                                                                               be vectors of expressions.
and ggplot2 functions), as x2.
                                                                                                                                                                                                Items that are separated by an asterisk
    For purposes of adding text that includes mathematical and other                                                                                                                            (*) are juxtaposed side by side. The
technical symbols, the notion of expression is generalized, to allow                                                                                                                            initial text is followed by a degree
“expressions” that it does not make sense to try to evaluate. For                                                                                                                               symbol, and then by the ﬁnal text.
example, expression("Temperature (" * degree * "C)")
prints as: Temperature (◦C).                                                                                                                                                                                   80 q

    The following indicate some of the possibilities:                                                                                                                                                          60
                                                                                                                                                                                                                                                            q
- Letters such as a, b, c, x, . . . are printed literally.
                                                                                                                                                                                                               40
- alpha denotes the Greek letter α, while Alpha denotes the upper                                                                                                                                                                               q
   case symbol. Similarly for other Greek letters.
                                                                                                                                                                                                               20
- hat(x) denotes xˆ.                                                                                                                                                                                                               q

- italic(x), bold(x), bolditalic(x), and plain(x) have the                                                                                                                                                             q
                                                                                                                                                                                                                      12345
   obvious meaning.
                                                                                                                                                                                                                        Radius (r)
-  frac(a,b)         denotes                                    a  .                                                                                                                            Figure 7.7: A mathematical expressionArea = πr 2
                                                                b                                                                                                                               is included as part of the y-axis label..

    Figure 7.7 demonstrates the use of an expression to provide y-
axis labeling. The code is:

yl <- expression("Area = " * pi * r^~2)
plot(1:5, pi*(1:5)^2, xlab="Radius (r)", ylab=yl)

The tilde (~) in r^~2 is used to insert a small space.
120 learning and exploring r

    Use substitute() in place of expression() when symbols in
the expression are to be replaced by values that will be provided at
the time of forming the expression.

    See help(plotmath) for further details of the conventions, and
of the symbols that are available. Type demo(plotmath) to see a
wide range of examples of what is possible.

7.2 Lattice Graphics                                                     The lattice package is included in all
                                                                         R binary distributions that are avail-
Lattice Graphics:                                                        able from a CRAN (Comprehensive
  Lattice Lattice is a ﬂavour of trellis graphics                        R Archive Network) mirror. It im-
              (the S-PLUS ﬂavour was the original)                       plements a trellis style of graphics,
                                                                         as in the S-PLUS implementation of
  Lattice Lattice is more structured, automated and stylized.            the S language. It is built on the grid
  vs base For standard purposes, much is automatic.                      low-level graphics system, described
                                                                         in Part II of Paul Murrell’s R Graphics
  Lattice Lattice syntax is consistent and tightly regulated
  syntax For lattice, graphics formulae are mandatory.                   To see some of the possibilities that
                                                                         lattice graphics oﬀers, enter
    Lattice (trellis) graphics functions allow
    the use of the layout on the page to reﬂect meaningful aspects       demo(lattice)
of data structure. Groups can be readily distinguished within data,
either using diﬀerent colors and/or symbols and/or line types within     Functions that give styles of graph
panels or using diﬀerent panels. Multiple columns of data can be         that are additional to those described
plotted, either distinguished within panels or using diﬀerent panels.    here include contourplot(),
    Functions in the latticeExtra package further extend what is         levelplot(), cloud(),
available.                                                               wireframe(), parallel(),
    In the discusssion that follows, there will be use of the layering   qqmath() and tmd().
abilities provided by functions in latticeExtra. Note that loading
latticeExtra will at the same time load lattice, which latticeExtra has  These abilities, due to Felix Andrews,
as a dependency.                                                         make it possible to build up lattice
                                                                         graphics objects layer by layer.
library(latticeExtra , quietly=TRUE)
                                                                                                    q
7.2.1 Lattice graphics – basic ideas
                                                                                  1200
Figure 7.8 was obtained using the lattice function xyplot(). In this
simple case, the syntax closely matches that of the base graphics                 1000
function plot(). Code is:
                                                                         Brainwt  800
## On the command line: Create and print object
xyplot(Brainwt ~ Bodywt, data=primates)                                           600                     q
                                                                                  400 q
Lattice graphics functions return graphics objects
                                                                                  200 q
Note an important diﬀerence between lattice and base graphics.                                   q
Lattice graphics functions do not print graphs.7 Instead they return
trellis graphics objects. The graph appears when the object is printed                  0 50 100 150 200

                                                                                                  Bodywt

                                                                         Figure 7.8: Use of lattice function
                                                                         xyplot() to give a graph.

                                                                         7 This applies also to ggplot2.
                              graphics – base, lattice, ggplot2, rgl, googlevis. . . 121

(use print() or plot()). Sending the output from a lattice graph-       The graph will however be printed if
ics function to the command line invokes print() and the graph is       xyplot(...) is the ﬁnal statement in
plotted, as was done for Figure 7.8.                                    a function that returns its result to the
                                                                        command line.
    A Brainwt versus Bodywt scatterplot for the primates data,
such as was given earlier, might alternatively have been obtained
using the function the function xyplot() from the lattice package.

## Save the result as a trellis graphics object
# [For plot(), this is not possible.]
## Create trellis object
gph <- xyplot(Brainwt ~ Bodywt, data=primates)
## Print graph; a graphics device must now be open
print(gph)

The object gph need not be printed at this point. It can be kept for
printing at some later time. Or it can be updated, using the function
update(), and then printed, thus:

gph <- xyplot(Brainwt ~ Bodywt, data=primates)
gph2 <- update(gph, xlab="Body wt (kg)",

                           ylab="Brain wt (g)")
print(gph2) # Or it is enough to type ' gph2 '

    Inside a function or in a ﬁle that is sourced, print() must ordi-
narily be used to give a graph, thus:

print(xyplot(ACT ~ year, data=austpop))

Addition of points, lines, text, . . .                                  8 Do not try to use points() and
                                                                        other such base graphics functions
For adding8 to a plot that has been created using a lattice function,   with lattice graphs.
use panel.points(), panel.text(), and other such functions, as
will be described in Subsection 7.2.8.

    Mechanisms for the control of a wide variety of stylistic features
are best discussed in the context of multi-panel graphs, which we
now consider.

7.2.2 Panels of scatterplots

Graphics functions in the lattice package, are designed to allow        See the help page for ais for details.
row by column layouts of panels. Diﬀerent panels are for diﬀerent
subsets of the data. Additionally, points can be distinguished, within
panels, according to some further grouping within the data.

    The ais dataset (DAAG) has data from elite Australian athletes
who trained at the Australian Institute of Sport. These included
height, weight, and other morphometric measurements, as well as
several types of blood cell counts. A breakdown of the total of 202
athletes by sex and sport gives:

with(ais, table(sex,sport))

sport

sex B_Ball Field Gym Netball Row Swim T_400m T_Sprnt Tennis W_Polo

f 13 7 4  23 22 9             11  470
122 learning and exploring r

m 12 12 0                                  0 15 13        18         11  4  17

    Figure 7.9 demonstrates the use of xyplot(), for the rower

and swimmer subset os the ais dataset. The two panels distinguish
the two sports, while diﬀerent plotting symbols (on a color device,
diﬀerent colors will be used) distinguish females from males.

                                           50  60 70 80 90                  Figure 7.9: Height (ht) versus Weight
                                                                            (wt), for rowers (Row) and swimmers
                          Row                        Swim                   (Swim). Diﬀerent plotting symbols
                                                                            are used to distinguish males from
                                  q                                         females.

                               q qq     q               qqq q
                               q qqq
    190                                                           q
                                qq q q
    180                                                        q

    170                        q                  q qq q             f
                                                                     mq
                       q                             q

ht  160                                           q

                                               q

    50 60 70 80 90

                                      wt

Suitable code is:                                                           Use
                                                                            auto.key=list(columns=2) to
xyplot(ht ~ wt | sport, groups=sex, data=ais,                               generate a simple key, with items side
            par.settings=simpleTheme(pch=c(4,1)),                           by side in two columns rather than
            scales=list(tck=0.5),                                           stacked in a single column as is the
            auto.key=list(space="right"),                                   default columns=1.
            subset=sport%in%c("Row","Swim"))
                                                                            Subsection 7.2.3, which now follows,
    In the graphics formula ht ~ wt | sport, the vertical bar               explains the use of the argument
indicates that what follows, in this case sport, is a conditioning          par.settings, and its call to
variable or factor. The graphical information is broken down by             simpleTheme().
levels of the factor sport. The parameter aspect controls the ratio
of dimensions in the y and x directions.                                    Settings that are not available us-
                                                                            ing simpleTheme() can if required
7.2.3 Setting stylistic features                                            be added to the theme object that
                                                                            simpleTheme() returns. See Subsec-
The function simpleTheme() creates a “theme”, i.e., a list of set-          tion 7.2.6 has details.
tings, that can be supplied via the argument par.settings in the
graphics function call. Use of the argument par.settings to a               9 Simple variations on the default
lattice function makes the settings locally, for the speciﬁc graphics       theme can be created by a call to
object that results.                                                        simpleTheme().

    The function simpleTheme() accepts arguments col, alpha,
cex, pch, lty, lwd, font, fill, border, plus col.points,
col.line, alpha.points and alpha.line. These allow sepa-
rate control (of color and of opacity) for points and lines.

    The function trellis.device() opens a new graphics device,
with settings that have in mind the use of lattice functions. The
function trellis.par.set() sets or changes stylistic features for
the current device. Both these functions accept an argument theme.9
                                                                       graphics – base, lattice, ggplot2, rgl, googlevis. . . 123

Settings made by trellis.device() or trellis.par.set() will
be over-written by any local settings that are stored as part of the
graphics object.

7.2.4 Groups within data, and/or columns in parallel

Table 7.1 shows selected rows from the data set grog (DAAG pack-
age). Each of three liquor products (drinks) has its own column.
Rows are indexed by the factor Country.

                                       Beer Wine Spirit Country             Year    Table 7.1: Apparent annual alcohol
                                                                                    consumptiom values, obtained by
                                 1 5.24 2.86 1.81 Australia 1998                    dividing estimates of total available
                                                                                    alcohol by number of persons aged
                                 2 5.15 2.87 1.77 Australia 1999                    15 or more. These are based on
                                                                                    Australian Bureau of Statistics and
                                 ....                                               Statistics New Zealand ﬁgures.

                                 9 4.57 3.11 2.15 Australia 2006

                                 10 4.50 2.59 1.77 NewZealand 1998

                                 11 4.28 2.65 1.64 NewZealand 1999

                                 ....

                                 18 3.96 3.09 2.20 NewZealand 2006

    Figure 7.10 is one of several possible displays that might be used
to summarize the information in Table 7.1. It has been created by
updating the following simpliﬁed code:

## Simple version of plot
grogplot <- xyplot(

                         Beer+Spirit+Wine ~ Year | Country,
                         data=grog, outer=FALSE,
                         auto.key=list(space="right"))

Amount consumed (per person)                      1998 2000 2002 2004 2006          Figure 7.10: Australian and New
                                                                                    Zealand apparent per person annual
                                       Australia           NewZealand               consumption (in liters) of the pure
                                                                                    alcohol content of liquor products, for
                              5  qqqqqqqqq                 qqqqqqqqq                1998 to 2006.
                              4
                                                                            Beer q
                              3                                             Spirit
                                                                            Wine

                              2

                              1

                                 1998 2000 2002 2004 2006

    Observe that:

- Use of Beer+Spirit+Wine gives plots for each of Beer, Spirit
   and Wine. The eﬀect of outer=FALSE is that these appear in the
   same panel.

- Conditioning by country (| Country) gives separate panels for
   separate countries.
124 learning and exploring r

    The following updates the object to give Figure 7.10:               Notice the use of the function
                                                                        simpleTheme() to set up a “theme”
## Update trellis object, then print                                    that was used to control point and line
ylab <- "Amount consumed (per person)"                                  settings.
parset <- simpleTheme(pch=c(1,3,4))
finalplot <- update(grogplot , ylim=c(0,5.5),

                                      xlab="", ylab=ylab,
                                      par.settings=parset)
print(finalplot)

    Figure 7.10 used diﬀerent symbols, in the one panel, to distin-
guish drinks, with diﬀerent countries in diﬀerent panels. For separate
panels for the three liquor products (diﬀerent levels of Country can
then use the same panel), specify outer=TRUE:

xyplot(Beer+Spirit+Wine ~ Year,
            groups=Country , outer=TRUE,
            data=grog, auto.key=list(columns=2) )

    Where plots are superposed in the one panel and, e.g., regression
lines or smooth curves are ﬁtted, this is done separately for each
diﬀerent set of points. Diﬀerent colors, and/or by diﬀerent symbols
and/or line styles, can be used to make the necessary distinctions.

    Here is a summary:

Break data down a/c to levels of the factor Country:

      Overplot (a single panel):        Separate panels:
Beer ∼ Year, groups=Country       Beer ∼ Year | Country

Plot columns in parallel, as in Beer+Wine+Spirit ∼ Year:

Overplot (a single panel):        Separate panels:
      outer=FALSE                  outer=TRUE

7.2.5 Keys – auto.key, key and legend                                   The argument auto.key sets up a
                                                                        call key=simpleKey(). If necessary,
The argument auto.key=TRUE gives a basic key. If not otherwise          use legend=NULL when updating, to
speciﬁed, colors, plotting symbols, and line type use the current       remove an existing key and allow the
settings for the device. The argument text has levels(groups) as        addition of a new key.
its default. that identiﬁes colors, plotting symbols and names for the
groups. For greater ﬂexibility, auto.key can be a list. Settings that   c(0,0) is the bottom left corner of
are often useful are:                                                   the legend, etc.

- points, lines: in each case set to TRUE or FALSE.
- columns: number of columns of keys.
- x and y, which are coordinates for the whole display area. Use

   with corner set to one of c(0,0), c(1,0), c(1,1) and c(0,1).
- space: one of "top", "bottom", "left", "right".

∗Use of textGrob() to add legends

The function textGrob() (grid) creates a text object which can
then be supplied to the lattice function. This mechanism for supply-
                                        graphics – base, lattice, ggSpltroiptp2l,ort golf ,cguockoogoledvaitsa. . . 125

ing legends can be used when multiple legends are required.                                  wren    qqq qqqqq qqq
    The following code adds an initial legend, as in Figure 7.11:                       tree.pipit             q qqqq qqqqqqq
                                                                                                               q qqqqqq qq q
plotnam <- "Stripplot of cuckoo data"                                                        robin            q qqqqq qqqq q q
stripplot(species ~ length, xlab="", data=cuckoos,                                 pied.wagtail
                                                                                  meadow.pipit      q q qq qqqqqqqqqqqqqqqqq qq
   legend=list(top=list(fun=grid::textGrob ,                                    hedge.sparrow                q qq qqq qqqq q
                                          args=list(label=plotnam ,
                                                            x=0))))                                    20 21 22 23 24 25

# x=0 is equivalent to x=unit(0,"npc")                                          Figure 7.11: The argument legend
# npc units are on a scale from 0 to 1                                          has been used to add text, supplied as
                                                                                a ’grob’.. Here, it would be easier to
Additional legends are supplied by adding further list elements, for            use of the argument main.
example a list element bottom as well as a list element top.

7.2.6 Lattice settings – further notes

In general, use themes to make point, line and ﬁll color settings. Use          For a visual display that shows default
the scales argument, in the call to the lattice function, for axes, tick        settings for points, lines and ﬁll color,
marks, and tick labels.                                                         enter:

    For changes that go beyond what simpleTheme() allows, ﬁrst                  trellis.device(color=FALSE)
identify the names under which settings are stored. Type:                       show.settings()
                                                                                trellis.device(color=TRUE)
> names(trellis.par.get())                                                      show.settings()

[1] "fontsize"       "background"                                       "clip"

...

[28] "par.sub.text"

The following sets the fontsize, separately for text and points:

trellis.par.set(fontsize = list(text = 7,
                                                          points = 4))

Parameters that aﬀect axes, tick marks, and axis labels

These are manipulated by use of the scales argument to the lattice
function. The code for Figure 7.12 provides an example.

    The following gives a basic graph, which will then be updated:

## 1. Create a basic version of the graphics object
jobsB.xyplot <-

   xyplot(Ontario+Quebec+BC+Alberta+Prairies+Atlantic ~ Date,
                data=jobs, type="b", layout=c(3,2), outer=TRUE,
                ylab="Number of jobs",
                scales=list(y=list(relation="sliced", log=TRUE)))

Now make several enhancements:

- Change the y-axis labels to show number of jobs, with                         10 Refer back to Subsection 4.3.9.
  log(number) in parentheses underneath.                                        11 This avoids overlap of tick labels.

- Use dates of the form Jan95 to label the x-axis.10

- Reduce tick marks in length (tck=0.6, i.e., 60% of the default).

- The argument between=list(x=0.5, y=0.5) adds horizontal
   and vertical space between the panels.11
126 learning and exploring r

                                                                                                  Jan95 Jul95 Jan96 Jul96 Jan97

                                     Alberta                                               1012                Prairies                                                        Atlantic
                                                                                          (6.92)
                 1422                                                                  q                                                                         q    973                q
                (7.26)                                                               q      992                                                             q       (6.88)
Number of jobs                                                qqqqqqqq                     (6.9)  qqqqqqqqqq q qqqqqqqq q                                                   qqqqqqqqqqq     q
                 1394                                       q                                                                qq                                       953                     q qqqqq
                (7.24)                                   q                                  973                                                                     (6.86)                       q qqqq
                        qqqqqqqqqqqq                                                      (6.88)
                 1366                                                                                                                                                 934
                (7.22)                                                                                                                                              (6.84)

                 5432                Ontario                                                                                Quebec                                   1845      BC
                 (8.6)                                                                                                                                              (7.52)
                        qqqqqqqqqqqqqqqqqqqqqqqq                                           3294                                                                                                                  q
                 5324                                                                      (8.1)                                                                     1808
                (8.58)                                                                                                                                               (7.5)                                    q
                                                                                           3229
                 5219                                                                     (8.08)                                qqqqq                                1772                                qq
                (8.56)                                                                                                                                              (7.48)
                                                                                           3165                             qq                                                                      qqq  q
                                                                                          (8.06)                                                                     1737                   qqq            q
                                                                                                                                                                    (7.46)
                                                                                                  qqqqqqqqq q                             q     qqqqq                       q qqqqqqqqqq

                                                                                                                                             q

                5115                                                                                                                                                        q

                (8.54)                                                                                                                                                      Jan95 Jul95 Jan96 Jul96 Jan97
                         Jan95 Jul95 Jan96 Jul96 Jan97

                                                                                                              Figure 7.12: Jobs growth in Canadian
                                                                                                              provinces, between January 1995 and
                                                                                                              December 1996.

## 2. Code for the enhancements to jobsB.xyplot
ylabpos <- exp(pretty(log(unlist(jobs[,-7])), 100))
ylabels <- paste0(round(ylabpos),"\n(", log(ylabpos), ")")
## Create a date object ' startofmonth ' ; use instead of ' Date '
atdates <- seq(from=95, by=0.5, length=5)
datelabs <- format(seq(from=as.Date("1Jan1995", format="%d%b%Y"),

                                         by="6 month", length=5), "%b%y")
update(jobsB.xyplot , xlab="", between=list(x=0.5, y=0.5),

            scales=list(x=list(at=atdates , labels=datelabs),
                                  y=list(at=ylabpos , labels=ylabels), tck=0.6) )

7.2.7 Lattice plots that show distributions                                                                                                                         Diﬀerences between dotplot() and
                                                                                                                                                                    stripplot() are mainly cosmetic.
Stripplots, dotplots and boxplots
                                                                                                                                                                    Figure 7.13: A stripplot and a dotplot
Because the syntax for stripplot() and boxplot() are very                                                                                                           appear side by side.
similar, we demonstrate suitable code side by side. Figure 7.13
summarizes cuckoo egg length data, from the dataset cuckoos from
DAAG:

             wren        qqq qqqqq qqq                                                                 wren            q           q  qq
        tree.pipit                   q qqqq qqqqqqq                                               tree.pipit                  q
                                     q qqqqqq qq q                                                            qqq
             robin                  q qqqqq qqqq q q                                                   robin             q       q
   pied.wagtail                                                                              pied.wagtail                   q
  meadow.pipit          q q qq qqqqqqqqqqqqqqqqq qq                                         meadow.pipit
hedge.sparrow                      q qq qqq qqqq q                                        hedge.sparrow                           q

                            20 21 22 23 24 25                                                                     20 21 22 23 24 25

                        Cuckoo egg length (mm)                                                                Cuckoo egg length (mm)

stripplot(species ~ length, data=cuckoos,
                  xlab="Cuckoo egg length (mm)")
                                                                                       graphics – base, lattice, ggFoprlosltig2h,tlrygilm,pgroovoegdlleabveilsi.n.g., 127
                                                                                                                             precede the code with:

bwplot(species ~ length, data=cuckoos,                                                        levels(cuckoos$species) <-
            xlab="Cuckoo egg length (mm)")                                                     sub(".", " ",
                                                                                                 levels(cuckoos$species),
The aspect argument determines the ratio of distance in the y-                                   fixed=TRUE)
direction to distance in the x-direction.

Lattice style density plots

Here is a density plot (Figure 7.14), for data from the possum data
set (DAAG), that compares sexes and Vic/other populations.

                                     40 45 50 55                                              Figure 7.14: Lattice style density
                                                                                              plot comparing possum earconch
               fm                                                                             measurements, separately for males
                                                                                              and females, between Victorian and
Density  0.25                                                                          Vic    other populations. Observe that the
         0.20                                                                          other  scatter of data values is shown along
         0.15                                                                                 the horizontal axis.
         0.10
         0.05  qqq qqqqqqqqqqqq q qqqqqqqqqqqqq  qqqqqqqqqqqqqqqqqqq qq qqqqqqqqqqqqq
         0.00

               40 45 50 55

                                                 earconch

## Code
colset <- c("gray","black")
densityplot(~ earconch | sex, groups=Pop,

                      data=possum ,
                      par.settings=simpleTheme(col=colset),
                      auto.key=list(space="right"))

The functions densityplot() and histogram() do not allow
a name on the left of the ∼ symbol. The function histogram(),
which is otherwise similar to densityplot(), does not accept a
groups argument.

7.2.8 Panel functions                                                                         Subsection 7.2.9 will describe a
                                                                                              radical extension of this basic scheme.
Each lattice function that creates a graphics object has its own panel                        Further layers, created using layer()
function. Creation of one’s own panel function allows detailed con-                           and allied functions in the latticeExtra
trol of panel contents. Or update() can be used to modify the panel                           package can be “added” (the operator
or panels.                                                                                    is “+”) to a trellis graphics object.

    A user panel function will typically include, or consist of, calls to                     12 When a groups argument is sup-
several of the variety of panel functions that are provided in lattice.                       plied, panel.xyplot() calls the
The function xyplot() has the panel function panel.xyplot().12                                function panel.superpose().
The following are equivalent:

xyplot(species ~ length, xlab="", data=cuckoos)
xyplot(species ~ length, xlab="", data=cuckoos,

            panel=panel.xyplot)

A user function, used in place of panel.xyplot(), might for ex-
ample call panel.superpose(), followed or preceded by other
available panel functions.

    Available panel functions include:
128 learning and exploring r

• panel.points(), panel.lines(), panel.text(),                            Note that an alternative to
   panel.rect(), panel.arrows(), panel.segments(),                        panel.points() is lpoints().
   panel.polygon()                                                        Similarly for the other functions.
   (all documented on the same help page as panel.points());
                                                                                         q Human
• panel.abline(), panel.curve(), panel.rug(),
   panel.fill(), panel.average(),                                                  1200
   panel.mathdensity(), panel.refline(),
   panel.loess(), panel.lmline()                                                   1000
   (all documented on the same help page as panel.abline()).
                                                                          Brainwt  800
    The following graphics object gph will be used as a starting
point, in the discussion that now follows:                                         600                       q Gorilla
                                                                                   400 q Chimp
 gph <- xyplot(Brainwt ~ Bodywt, data=primates ,
                          xlim=c(0,300))                                           200 q Rhesus monkey

    Now create a panel function that both plots the points and adds                          q Potar monkey
labels. The graphics object can then be updated, as in the code that
now follows, to use this panel function:                                                 50 100 150 200 250

 my.panel <- function(x,y){                                                                     Bodywt
    panel.xyplot(x,y)
    panel.text(x,y, labels=rownames(primates),                            Figure 7.15: Addition of labels, as
                        cex=0.65, pos=4)                                  here, can be done by updating a graph
                                                                          that has the points, by use of a panel
 }                                                                        function that both plots points and and
 update(gph, panel=my.panel ,                                             adds labels, or by adding a new layer.

             scales=list(tck=0.6))

    Note that we could have supplied a panel function that plots the
points and adds the labels in the initial function call, thus:

 xyplot(Brainwt ~ Bodywt, data=primates ,
             xlim=c(0,300), panel=my.panel)

    A further possibility is to add a new layer that has the labels,
as in Subsection 7.2.9 which now follows. However the plot is ob-
tained, Figure 7.15 shows the result.

7.2.9 The addition of new layers

The layering mechanism greatly extends the range of possibilities.
The code that follows gives a simple and somewhat trivial example
of its use – an alternative the use of a panel function for adding
labeling to Figure 7.15.

    Note again the graphics object gph, created above:

 gph <- xyplot(Brainwt ~ Bodywt, data=primates ,
                          xlim=c(0,300))

The following uses the function layer(), from the latticeExtra
package, to create a second layer that has the labels. The layer that is
thus created is added to the graphics object gph:

 gph + latticeExtra::layer(panel.text(x,y,
                                           labels=rownames(primates),
                                          pos=4))
graphics – base, lattice, ggplot2, rgl, googlevis. . . 129

Note also layer_(), which reverses the order of the layers, equiva-       Other convenience functions are
lent to using layer() with under=TRUE.                                    glayer() and glayer_(). These
                                                                          are equivalent, respectively, to call-
    The function layer() allows as arguments, passed via the ...          ing layer() and layer_() with
argument, any sequence of statements that might appear in a panel         superpose=TRUE. The layer is drawn
function. Such statements can refer to panel function arguments,          once for each level of any group in the
including ’x’, ’y’ and ’subscripts’. Additionally, named column           plot.
objects can be passed through an optional data argument.
                                                                          For using playwith, the GTK+ toolkit
    The function as.layer() creates a layer from a trellis graphics       must be installed. For details, go
object. This can then be “added” in the usual way.                        to the website http://playwith.
                                                                          googlecode.com/.
7.2.10 Interaction with plots – latticist and playwith                    13 More limited abilities are available
                                                                          to interact with other plots.
Here will be noted the abilities in the latticist and playwith packages,
for interaction with lattice plots.13

latticist(): When called with a data frame as argument, the
function latticist() (in the latticist package) opens a window
that has graphical summary information on the columns of the data
frame. Additionally, it opens a GUI interface to the lattice and vcd
packages, allowing rapid creation of plots that may be useful in their
own right, or may be a ﬁrst step in creating more carefully crafted
plots. Various annotation features are available from the GUI.

playwith(): The playwith() function (from the playwith pack-
age) was used for Figure 7.16. The menu that appears to the left of
the graph can be used to initiate single click identiﬁcation, to add
annotation or arrows, or to mark out a rectangle on the graph for
zooming in or out. If labels are not speciﬁed, row names are used.

## Code that initiates interactive display
library(playwith)
playwith(xyplot(age ~ distance , data=hotspots),

                labels=hotspots$name)
130 learning and exploring r

                                                                      Figure 7.16: This playwith GUI
                                                                      window was generated by wrapping
                                                                      the call to xyplot() in the func-
                                                                      tion playwith(), then clicking on
                                                                      Identify. Click near to a point to see
                                                                      its label. A second click adds the label
                                                                      to the graph. A color version appears
                                                                      as C.2.

    Note that playwith() can be used, also, for more limited inter-   Alternative code for Figure 7.16:
action with plots created using base graphics, or using ggplot2.
                                                                      gph <-
7.3 ggplot2 – A Grammar of Graphics                                          xyplot(age ~ distance ,
                                                                                            data=hotspots)
The ggplot2 syntax is consistent, but less stylized than the lattice
syntax. As with lattice, ggplot2 functions return a graphics object.  library(playwith)
The graphics objects that ggplot2 functions return can be saved for   playwith(update(gph),
later use, or updated, or printed directly on to the graphics page.
Each diﬀerent type of ggplot2 graphic display – scatterplot, his-            labels=hotspots$name)
togram, density plot, histogram, etc. – is a diﬀerent plot geom, or
“geometry”. These can be overlaid.                                    The ggplot2 syntax is a variant of
                                                                      Wilkinson’s “Grammar of Graphics”
    The following loads the ggplot2 package:                          (Springer, 2nd edn, 2005).

library(ggplot2)
                                                                       graphics – base, lattice, ggplot2, rgl, googlevis. . . 131

7.3.1 Examples that demonstrate ggplot2 abilities

Brain weight versus body weight

Figure 7.17 repeats Figure 3.1B from Chapter 3, now using ggplot2
abilities:

                                                                          qq  Figure 7.17: Plot of brain weight (gm)
                                                                              versus body weight (kg). Log scales
                                                          q                   have been used on both axes. The
                                                                              function coord_equal(), used with a
                                                                       q      logarithmic scale, ensures that a given
                                                                 qqq q        distance (e.g., 1cm) on either axis
                                                          q                   represents the same relative change.
                                                              q

       100                                         qq          q q qq
          1                                           qq  qq

brain                                        qqqq               q

                                                            q

                               qq  q qqqq
                                   qqqq q
                               q q qqqqq
                           q              q  q
                           qq
                                 q qq

                        qq q

                  q  q  q
             q       q

                        1e−01                  1e+01                   1e+03

                                             body

Code is:                                                                      In subsequent discussion, the abbre-
                                                                              viated name qplot will be used in
library(MASS)                                                                 place of quickplot.
quickplot(body, brain, data=mammals , log="xy") +

   coord_fixed()

Notice that quickplot() has been used to create an initial plot,
with coord_equal() then used (“added”) to specify that a given
distance will represent the same change on both axes. As a loga-
rithmic scale is used, this implies that the same relative change will
be given by the same distance. Here, observe that grid lines in both
directions are the same distance apart, with the distance representing
a change by a factor of 100,

    The following adds a regression line:

quickplot(body, brain, data=mammals , log="xy") +
   coord_fixed() +
   geom_smooth(method=lm)

This “addition” of new functions that add to or modify the initial
graph can in principle proceed without limit.

    As the name hints, the function qplot() (or quickplot())
shortcuts the more detailed ggplot2 syntax. The call

quickplot((body, brain, data=mammals , log="xy")

when written out using the detailed syntactic steps, becomes:

ggplot(mammals , aes(body, brain)) +
   geom_point() +
   scale_x_continuous(trans="log") +
   scale_y_continuous(trans="log")

The successive “+” operators combine output from function calls to
create a single graphics object. In the detailed syntactic steps, the
132 learning and exploring r

call to geom_point() plots the points, while the subsequent calls       Note that cex and size are syn-
                                                                        onyms, as are color and colour.
change the x- and y-axis scales to logarithmic scales.                  Also type is a synonym for geom.

    In the call to ggplot(), the data argument is the only manda-

tory argument. It can be repeated in the call(s) to one or more of the
later geom functions. This allows diﬀerent geoms, if required, to take
their data from diﬀerent data frames.

    Changes to color or size or shape settings can be made
separately for each diﬀerent geom. Changing geom_point() to
geom_point(size=2.5) aﬀects only the points.

Aesthetic mappings vs settings

Distinguish between settings and aesthetic mappings:

          Use of quickplot()                          Plots based on ggplot()
                                                      size=3
Settings  size=I(3) or cex=3                          aes(size=3) or aes(size=sport)

Aesthetic mappings size=3 or size=sport

The function aes() maps variables in the data to visual properties      14 Where base graphics has pch,
(“aesthetics”) of geoms. In aes(body, brain above, the mappings         ggplot2 has shape.
are to the x− and y−axes of the plot. Other possible mappings are
to color (use color to distinguish groups within the data), shape14
(distinguish by shape), size and fill.

    Use of the argument size=3 in a call to quickplot() does
change the point size, but it adds an extraneous key. The same
happens if the argument mapping=aes(size=3) is supplied to
ggplot() or to geom_point() or to another such function.

    A further possibility is to use quickplot() (or qplot()) to
create an initial graphics object, then adding to this object. The
following code uses this approach to create Figure 7.20:

qplot(Year, mdbRain , data=bomregions2015 ,
           geom="point",
           xlab="", ylab="Av. rainfall , M-D basin") +

   geom_smooth(span=0.5, se=TRUE)

    In all cases, a ggplot object is created. This can be printed
immediately, or it can be saved as a named object. The graph is
created using the print method for a ggplot object.

7.3.2 An overview of ggplot2 technicalities

Available geometries and settings

Table 7.2 has details of a number of the geometries that are available
for ggplot objects. Table 7.3 lists some of the settings, in addition
to those already noted, that are available:

Example — Measurements on Australian athletes

Figure 7.18 plots height against weight, by sex, for the ais data.
Additionally, boxplots show the distributions of heights, and there
                                      graphics – base, lattice, ggplot2, rgl, googlevis. . . 133

quickplot()  ggplot()                                                Table 7.2: Available geoms.
geom=
"point"      + geom_point()           Available arguments to the geom function
"line"       + geom_line()            (data, mapping, color, fill, alpha, plus . . . )
             + geom_path()1           size, shape, etc.
"path"       + geom_smooth()          size, linetype
"smooth"     + geom_histogram()
"histogram"  + geom_density()         size, linetype
"density"    + geom_density2d()       linetype, weight, se (TRUE or FALSE).
"density2d"                           linetype, weight
                                      weight, linetype, size
                                      weight, linetype, size

1 Use geom_path() to connect observations, in the original order.

Title     Argument to qplot()                                                  Table 7.3: Control of ggplot2 graphics
Axes      main="mytitle"                                                       features. Functions such as xlab()
                                                                               and scale_x_continuous() that re-
          see help(qplot)                                                      late to the x-axis all have counterparts
                                                                               with y in place of x. .
Axis labels e.g., xlab="myxlab"
                                      ggplot() or qplot()1
log axes  log="x", (or "y", or "xy")  + labs(title="mytitle")
Facets5   facets=sex ~ sport          + scale_x_continuous()2

Aspect ratio e.g., asp=1                 [or scale_x_discrete() or scale_x_date()]
                                      + xlab("myxlab")3
Theme     —                           + scale_x_log10()4

Graph title e.g., main="maintitle"    + facet_grid(sex ~ sport)
                                      + coord_equal()6

                                      + ggtitle("mytitle")

1 Recall that quickplot() (or qplot()) returns a ggplot object. Functions

such as xlab() or scale_x_continuous() can be used, just as for any other

ggplot2 object, to update objects returned by quickplot().
2 Available arguments include limits, breaks (locations for the ticks), labels

(labels for the breaks), and trans (e.g., trans="log").
3 This is an alternative to using name (e.g., name="myxlab") as an argument to

scale_x_continuous() or scale_x_discrete().
4 This is an alternative to using trans="log10" as an argument to

scale_x_continuous() or scale_x_discrete(). Note also trans="log"

and trans="log2").
5 Facets give Lattice style conditioning.
6 By default (ratio=1), a given distance, e.g., 1cm, represents the same range

along both x− and y−axes.
7 Themes control such graphical attributes as background color, gridlines, and size

and color of fonts. See help(ggtheme) for details of other available themes.
134 learning and exploring r

are two-dimensional density contours estimates. The graph is a tad
crowded.

                                    f                                                                                               m                                                                                                Figure 7.18: Height versus weight,
                                                                                                                                                                                                                                     by sex, for Australian athletes in the
                                                                                                                                       qq                                                                                            ais data set. Boxplots that show the
                                                                                                                                                                                                                                     distributions of heights, and two-
                                                                                                                                          q                                                                                          dimensional density contours have
                                                                                                                                                                                                                                     been added.
             200                                                                                                                       q
             180                                                                                                                    qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq
             160            qq                                                                              q
                            q                                                                              q

Height (cm)                                  qq                                                                                                                                                                                   q
                  qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq q
                                                                                                                                 q                                                                                             q
                                                                                                                                 q                                                                                          q
                                                                                                                                q

                                                                                                                             q  q

                                                                                                                q

                  qqqq      qqq

                  qq        q                                                                              100      125 50          75 100 125

                        50      75                                                                              Weight (kg)

    The following gives a simpliﬁed version of the plot:                                                                                                                                                                                 200                                q

## Overlay with boxplots and density contours                                                                                                                                                                                            190                             qqq      q  sport
quickplot(wt, ht, data=ais,                                                                                                                                                                                                                                              q qqq
                                                                                                                                                                                                                                         180                        qqq               q Row
                  geom=c("boxplot", "point", "density2d"),                                                                                                                                                                                                           q    qq q q            Swim
                  facets = . ~ sex)                                                                                                                                                                                                      170                        qqq
                                                                                                                                                                                                                                                          q              q           sex
To set axis labels, show the boxplot outline in gray, show contour                                                                                                                                                                                     q  qqqq qqq
lines in gray (the default is blue), and make various other changes as                                                                                                                                                               ht                                               qf
in Figure 7.18, specify:                                                                                                                                                                                                                                     qqqqq                    qm

quickplot(wt, ht, xlab="Weight (kg)",                                                                                                                                                                                                    160
                  ylab="Height (cm)", data=ais,
                  facets = . ~ sex) +                                                                                                                                                                                                              q

   geom_boxplot(aes(group=sex),                                                                                                                                                                                                                 50 60 70 80 90
                           outlier.size =1 .75 ,
                           outlier.colour="gray",                                                                                                                                                                                                              wt
                           color="gray") +
                                                                                                                                                                                                                                     Figure 7.19: Use color for distin-
   geom_point(shape=2, size=1) +                                                                                                                                                                                                     guishing sexes, shapes for sports.
   geom_density2d(color="gray")

    The facets argument has the form row.var ~ col.var,
where row.var indexes rows of panels, col.var indexes columns,
and “.” serves as a placeholder when there is one row or one column
only.

    Code for the next plot will work with a subset of the ais data,
limiting attention to rowers and swimmers:

## Extract from ais data for rowers and swimmers
aisRS <- subset(ais, sport %in% c("Row","Swim"))
aisRS$sport <- droplevels(aisRS$sport)

    Here are alternative code fragments that can be used to create
Figure 7.19, one using quickplot() and the other using successive
calls to ggplot() and to geom_point():
                                                                                                                       graphics – base, lattice, ggplot2, rgl, googlevis. . . 135

1: Use quickplot():                                                                                     2: ggplot() + geom_point():

quickplot(wt, ht,                                                                                       ggplot(aisRS) +
                  data=aisRS ,                                                                             geom_point(aes(wt, ht,
                  geom="point",                                                                                                    color =sex ,
                  size=I(2),                                                                                                       shape=sport),
                  colour =sex ,                                                                                                size=2)
                  shape=sport)

    Multiple aesthetics can be used for the one distinction, here be-
tween sexes:

## Distinguish sex by color & shape
## Different sports have different panels
quickplot(wt, ht, data=aisRS , geom="point",

                  size=I(2.5), color=sex, shape=sex,
                  facets = . ~ sport)

    Here are further possibilities:

## Identify sex by color, sport by shape (1 panel)
quickplot(wt, ht, data=aisRS , geom="point",

                    color=sex, shape=sport, size=I(2.5))
## Identify sex by color, sport by size (1 panel)
quickplot(wt, ht, data=aisRS , geom="point",

                  color=sex, size=sport)

Australian rain data                                                                                                                                                Arguments size (e.g.,
                                                                                                                                                                    size=I(2.5)), color (e.g.,
Figure 7.20 plots annual rainfall for Australia’s Murray-Darling                                                                                                    color=I("red"), etc, can be
basin region. The following code uses the function quickplot():                                                                                                     supplied, aﬀecting both points
                                                                                                                                                                    and the added smooth curve. NB:
library(DAAG)                                                                                                                                                       size=I(2.5), not size=2.5.
library(ggplot2)
## Default loess smooth, with SE bands added.                                                                                                                       Figure 7.20: Annual rainfall, from
quickplot(Year, mdbRain , data=bomregions2015 ,                                                                                                                     1901 to 2012, for the Murray-Darling
                                                                                                                                                                    basin region of Australia. The curve is
                  geom=c("point","smooth"), xlab="",                                                                                                                ﬁtted using the default loess smoother.
                  ylab="Av. rainfall , M-D basin")                                                                                                                  The pointwise standard error bands
                                                                                                                                                                    assume that errors about the curve
                         800                                                                                                                              q         are independent; this is unlikely to be
                                                                                                                                                                    strictly true. To suppress these bands,
                                                                                  qq                                                                                specify se=FALSE.

Av. rainfall, M−D basin                                                                                        q

                                                                                                                   q

                                                                                                                             q

                                                   q                                     qq
                                    q qq
                         600                                                                                                                               q
                         400                                                      q
                                                  qq            q                                                          q    qq               qq
                                                                           q            qq                             q                           q
                                                                                    q             q                qq                        qq
                              q                                   qq q q                         q          q                   qq         q
                                       qq                                                               qqq
                                                                                            qqqq q                                                           q
                                    q
                                                                q                                                                 q
                                   q                                                                                            q                      qq
                                    q qq   q              q  q             q                         q                                        q qq q             q
                              q                          q                           qq                                                 q                       q
                                          q                                                                                      q                 qq
                               q            q                      q  q q qq q                                        q
                                                                                                                        q
                                               q      q                                                                   q                                   q

                                           qq            q            qq                                        q                          q
                                                q          q                                qq

                                                                          q                          q                                                qq
                                                                               q                                         q
                              q

                              1900                1925                            1950                  1975                                  2000

                         Code that shows the detailed syntactic steps is:
136 learning and exploring r

ggplot(bomregions2015 , aes(x=Year, y=mdbRain)) +

geom_point() +                         # Scatterplot

geom_smooth(span=0.5, se=TRUE) + # Add smooth

xlab("") +                # Blank out x-axis label

ylab("Av. rainfall , M-D basin")

## NB: aes() has supplied x- and y-axis variables

As before, the successive “+” operators combine output from func-
tion calls to create a single graphics object.

    Try also the following. This requires both the quantreg package
and the splines package:

library(quantreg)                                                      The normal spline basis ns(x,5) is
library(splines)                                                       supplied to the function that estimates
## Supplementary figure 4                                              the quantile curves, so that 5 d.f.
quickplot(Year, mdbRain , data=bomregions2015) +                       spline curves are ﬁtted at the 20%,
                                                                       50% and 80% quantiles.
                  geom_quantile(formula = y ~ ns(x,5),
                  quantiles=c(0.2,0.5,0.8) )

Florence Nightingale’s Wedge Plot                                      Florence Nightingale’s Crimean War
                                                                       experience prepared her for later
Figure C.3 in Appendix C is a “wedge” plot, showing the mortality      major work in the reform of army and
of British troops according to cause in the Crimean war over 1854–     civilian hospitals and public health
1856. It shows the abilities of the ggplot2 package to spectacular     administration, and to wider social
eﬀect. The plot is obtained by using polar coordinates for plotting a  reform. Her inﬂuence extended to the
stacked bar chart! Use of areas to convey numerical information is     army and civilian administration in
however not ideal, especially when as here the areas overlap.          India.

7.4 Static graphics – additional notes

7.4.1 Multiple graphs on a single graphics page

For base graphics, refer back to Subsection 7.1.5. The following
demonstrates use of the fig argument to par() to select a part of
the display region for plotting:

par(fig = c(0, 1, 0.38, 1))

# xleft, xright, ylow, yhigh

## Plot graph A

par(fig = c(0, 1, 0, 0.38), new=TRUE)

## Plot graph B

par(fig = c(0, 1, 0, 1))      # Resets to default

For lattice graphs, the location of the graph can be determined by
the argument position, when print() is called. The following
demonstrates its use:

cuckoos.strip <- stripplot(species ~ length , xlab="", data=cuckoos)
print(cuckoos.strip , position=c(0,0.5,1,1))

                                  # xleft, ybottom , xright, ytop
cuckoos.bw <- bwplot(species ~ length , xlab="", data=cuckoos)
print(cuckoos.bw , position=c(0,0,1,0.5), newpage=FALSE)

Note the use of newpage=FALSE for the second plot.
                                                                graphics – base, lattice, ggplot2, rgl, googlevis. . . 137

Base and trellis plots on the same graphics page

The following uses the base graphics command mtext() to label a
lattice plot:

plot(0:1, 0:1, type="n", bty="n", axes=FALSE,
         xlab="", ylab="")

lab <- "Lattice bwplot (i.e., boxplot)"
mtext(side=3, line=3, lab)
cuckoos.bw <- bwplot(species~length , data=cuckoos)
print(cuckoos.bw, newpage=FALSE)

Inclusion of graphs in Microsoft Word                                      Figure 7.21: Snapshot of a 3-D dy-
                                                                           namic display, for the nihills data
Graphs may not import well from the clipboard into Word on the             from the DAAG package. The display
Macintosh under OS X. On Windows systems, an eﬀective option               has been dragged to a position where
is to use win.metafile() to write graphics output to a Windows             points very nearly fall on a line.
metaﬁle format that should import without problem into a Word or
Power Point document.

7.5 Dynamic Graphics – rgl

This section will describe a range of abilities that create dis-
plays which the user can then manipulate dynamically. Note
in particular the rgl and googleVis packages, designed for in-
teractive exploration of dynamic changes in relationships with
time. The googleVis package reproduces most of the abilities
of Google’s Public Data Explorer, which can be accessed at
http://www.google.com/publicdata/home

                                log(climb)

                                                                log(dist)

                          log(time)

    The rgl package provides three-dimensional dynamic graphics.
Use of the functions scatter3d() and identify3d() from the car
package may be more convenient for novices than the rgl functions
138 learning and exploring r

that they call. Figure 7.21 shows a snapshot of the plot obtained for
the nihills data from the DAAG package.
The following loads the needed packages:

## The car and rgl packages must be installed
library(rgl, quietly=TRUE)
library(car, quietly=TRUE)
rgl::setupKnitr()
knit_hooks$set(rgl=hook_rgl)

Code for the ﬁgure is:

library(DAAG, quietly=TRUE)

open3d()         # Precedes the call to par3d()

par3d(cex=0.75)  # Optional

                 # Other params: see help(par3d)

with(nihills, scatter3d(x=log(dist), y=log(climb),

                        z=log(time),

                        grid=FALSE ,

                        surface =FALSE ,

                        point.col="black",

                        axis.scales=FALSE))

## NB: Use middle or right mouse button to drag a

## rectangle around a point that is to be labeled.

    Use the function identify3d() to start the identiﬁcation of          Use rgl.snapshot() to save the
points. Following the call to identify3d(), use the middle (or           current plot into a ﬁle.
maybe right) mouse button to drag a rectangle around any point that
is to be labeled. To cease identifying points, make a middle (or right)
click on an empty region of the plot. The labels may appear only at
this point. Here, for identiﬁcation of points shown in Figure 7.21, is
suitable code:

with(nihills, identify3d(x=log(dist), y=log(climb),
                                             z=log(time),
                                             labels=row.names(nihills),
                                             col="gray"))

    Such a plot can be helpful in identifying high leverage
points, e.g., in the regression of log(time) on log(dist) and
log(climb). The plot needs to be rotated to give a view in which
the leverage is apparent.

The rggobi package

The rggobi package oﬀers a wider range of features, via an interface
to the GGobi system. For installation details go to http://www.
ggobi.org/. Windows users can use the following to install all
the required ﬁles from an R session that has access to a live internet
connection:

source("http://www.ggobi.org/downloads/install.r")
graphics – base, lattice, ggplot2, rgl, googlevis. . . 139

7.5.1 The googleVis Package                                                15 An internet connection is needed
                                                                           to access Google’s API (Application
This provides an interface to the abilities of Google’s Public Data        Program Interface) when the chart is
Explorer. While these abilities can be accessed from the web page          displayed.
noted below, there are obvious advantages in setting up the display
from one’s own computer.15                                                 16 Various controls are placed in
                                                                           the margins of the graph. Move the
Google’s Public Data Explorer                                              pointer over one or other control
                                                                           feature to get information on its
Upon accessing Google’s web page http://www.google.com/                    purpose, or over a point to display
publicdata/home, the display will cycle through examples                   information about that point. For
of the use of Motion Charts, and other related charts. Click on            changing the x- and/or y- variables,
Explore Data to go to the interactive version of the relevant dis-         or for changing the variable that
play.16 These charts, which are interesting in themselves, show the        determines point size, click on the
abilities that googleVis is designed to emulate. See the annotations in    relevant downward pointing selector
Figure C.1 below for details that should be enough to get started.         arrow. Scales, separately for the
                                                                           two axes, can be either linear or
    A slider below the graph can be moved to show how the relation-        logarithmic.
ships that are plotted change over the available timespan, commonly
1960 through to 2010 (but note that not all data will be available for     To display the vignette, type:
all years). Click on the solid right-pointing triangle on the left of the  vignette("googleVis")
slider scale to see the graph changing dynamically in moving from
the currently shown year through to 2010.

Use of googleVis to create motion charts

The details given here should be supplemented with examination
of the vignette that accompanies the googleVis package. Note espe-
cially Figure 1 on page 5 of the vignette.

    Creation of a motion chart, once the data is in place, is remark-
ably straightforward. The starting point is a data frame in that has
a column (e.g. Countries) that can be used as an id variable, a col-
umn (e.g. Year) that has a timevar variable, and columns that can
be used to supply x- and y- variables. Optionally, columns may be
identiﬁed for use as a colorvar and/or a sizevar.

    The dataset grog from the DAAG package has a
suitable structure. One can create a motion chart thus:

library(googleVis)
M <- gvisMotionChart(grog, id="Country", timevar="Year")
## This next line requires a live internet connection ,
## and Adobe Flash must be installed.
plot(M)

If the browser window that appears displays ’Flash’ in gray in the
middle of the screen, click there to proceed. A browser window with
a gray display region should appear.

    For the grog dataset, the Motion Chart does a less satisfactory
job than Figure 7.10 in Section 7.2.4. Motion charts come into their
own for the examination of steady changes over time in a bivari-
ate relationship, with diﬀerent patterns of relationship for diﬀerent
140 learning and exploring r

subgroups of the data.                                                   The code used to download the data
    A plot that allows the display of various World Bank develop-        and display the motion chart will
                                                                         appear on your screen.
ment indicators can be obtained by typing:
                                                                         17 Both WorldBank and M should
demo(WorldBank)                                                          be in your workspace after running
                                                                         demo(WorldBank). The data are also
This can take a while to start up – data has to be downloaded from       alternatively available from the image
the World Bank web site. Hover the mouse pointer over features that      ﬁle WorldBank.RData at the url
appear in the margins of the display to see annotation that indicates    noted on the reverse of the title page.
how you can change or manipulate various aspects of the display.

    The data from the World Bank site is stored into a data frame
WorldBank. The command that creates a gvis object M is:17

M <- gvisMotionChart(WorldBank , idvar="country",
                  timevar="year",
                  xvar="life.expectancy",
                  yvar="fertility.rate",
                  colorvar="region", sizevar="population",
                  options=list(width=700, height=600))

## Now display the motion chart
plot(M)

Change width and height as needed to make better use of the              18 The gvis object M comprises
screen display.                                                          Javascript code that can be included
                                                                         on a web page. This should display
    If arguments are supplied, security setting issues on the user       correctly when the web page is ac-
computer can result in an initial assignment of columns that does not    cessed.
accord with the supplied arguments.18 The drop-down menus should
however function correctly, and can be used to obtain a display that
accords with any choice of arguments that the user may want.

    For a further example, load the image ﬁle wdiSel.RData, avail-
able from the url noted on the reverse of the title page. This will
make available the data frame wdiSel. This has a larger number of
indicators, but for 26 countries only. Figure C.1 (with the ﬁgures that
are shown in color) shows an annotated version of a motion chart
that was created from this dataset.

    The following code generated the initial chart. The change to a
log scale on the vertical axis was made interactively:

xnam <- "Electric power consumption (kWh per capita)"
ynam <- "Mobile cellular subscriptions (per 100 people)"
M <- gvisMotionChart(wdiSel, idvar="Country.Name", timevar="Year",

                                      xvar=xnam, yvar=ynam,
                                      colorvar="region", sizevar="Population , total",
                                      options=list(width=600, height=500),
                                      chartid="wbMotionChartSel")
plot(M)

7.6 Summary

  Base graphics functions plot a graph. Lattice and ggplot2 func-
  tions return a graphics object. which can then stored or updated or
  plotted (printed).
                                                                  graphics – base, lattice, ggplot2, rgl, googlevis. . . 141

    A powerful feature, both of ggplot2 graphics and of lattice graph-
    ics when the layering abilities of the latticeExtra package is used,
    is the ability to build a graph up layer by layer.

    The R system makes available, via its various package, a wide
    variety of other graphics abilities. This includes dynamic and
    other 3-dimensional graphics.

 7.7 Exercises

 In the following exercises, if there is no indication of whether to use
 base or lattice graphics, use whichever seems most suitable.

1. Exercise 3 in Section 2.6.2 showed how to create the data frame
    molclock. Plot AvRate against Myr. Use abbreviate() to
    create abbreviated versions of the row names, and use these to
    label the points.

2. Compare the following graphs that show the distribution of head
    lengths (hdlngth) in the possum data set. What are the advan-
    tages and disadvantages of these diﬀerent forms of display?

       a) a histogram (hist(possum$hdlngth));
       b) a stem and leaf plot (stem(qqnorm(possum$hdlngth));
       c) a normal probability plot (qqnorm(possum$hdlngth)); and
       d) a density plot (plot(density(possum$hdlngth)).

3. This exercise uses the data set hotspots (DAAG package).
    Plot age against distance. Use identify() to determine which
    years correspond to the two highest mean levels. That is, type

     plot(age ~ distance , data=hotspots)
     with(hotspots , identify(age ~ distance , labels=name))

    Use the left mouse button to click on the highest two points on the
    plot. (Right click in the ﬁgure region to terminate labeling.)

4. Use mfrow() to set up the layout for a 3 by 4 array of plots. In
    the top 4 rows, show normal probability plots for four separate
    ‘random’ samples of size 10, all from a normal distribution. In the
    middle 4 rows, display plots for samples of size 100. In the bot-
    tom four rows, display plots for samples of size 1000. Comment
    on how the appearance of the plots changes as the sample size
    changes.

5. The function runif() can be used to generate a sample from a
    uniform distribution, by default on the interval 0 to 1. Print out the
    numbers you get from x <- runif(10). Then repeat exercise 6
    above, but taking samples from a uniform distribution rather than
    from a normal distribution. What shape do the points follow?
 142 learning and exploring r

6. The data frame airquality that is in the base package has
    columns Ozone, Solar.R, Wind, Temp, Month and Day. Plot
    Ozone against Solar.R for each of three temperature ranges, and
    each of three wind ranges.

7. Create a version of the data frame Pima.tr2 that has anymiss as
    an additional column:

     missIND <- complete.cases(Pima.tr2)
     Pima.tr2$anymiss <- c("miss","nomiss")[missIND+1]

 (a) Use strip plots to compare values of the various measures for
       the levels of anymiss, for each of the levels of type. Are there
       any columns where the distribution of diﬀerences seems shifted
       for the rows that have one or more missing values, relative to
       rows where there are no missing values?
       Hint: The following indicates how this might be done eﬃ-
       ciently:

        library(lattice)
        stripplot(anymiss ~ npreg + glu | type, data=Pima.tr2 , outer=TRUE,

                           scales=list(relation="free"), xlab="Measure")

 (b) Density plots are in general better than strip plots for compar-
       ing the distributions. Try the following, ﬁrst with the variable
       npreg as shown, and then with each of the other columns ex-
       cept type. Note that for skin, the comparison makes sense
       only for type=="No". Why?

        ## Exercise 7b
        library(lattice)
        ## npreg & glu side by side (add other variables , as convenient)
        densityplot( ~ npreg + glu | type, groups=anymiss , data=Pima.tr2 ,

                              auto.key=list(columns=2), scales=list(relation="free"))
8
Regression with Linear Terms and Factors
144 learning and exploring r

Linear Models, in the style of lm():

 Linear model Any model that lm() will ﬁt is a “linear” model.
                     lm() can ﬁt highly non-linear forms of response!

Diagnostic  Use plot() with the model object as argument,
plots       to get a basic set of diagnostic plots.

termplot()  If there are no interaction terms, use termplot()
            to visualize the contributions of the diﬀerent terms.
Factors
Model       In model formulae, factors model qualitative eﬀects.
matrices
            The model matrix shows how coeﬃcients should be
            interpreted. (This is an especial issue for factors.)

GLMs        Generalized Linear Models are an extension of
            linear models, commonly used for analyzing counts.

Modern      This can use smoothers – spline and other functions
regession   of explanatory variables that adapt to suit the data.

[NB: lm() assumes independently & identically distributed (iid)
errors, perhaps after applying a weighting function.]

    In this chapter, the chief focus will be on the lm() (linear model)   Thus spline ﬁts are formed as a linear
function, discussed earlier in Section 3.3. The lm() function is the      combination from a kitset of curves.
most widely used of a huge range of model ﬁtting abilities, available
in the various R packages.

    Linear models are linear in the model parameters, not necessarily
in the variables. A linear model can perfectly well ﬁt a combination
of basis curves.

8.1 Linear Models in R – Basic Ideas                                      1 The standard errors become in-
                                                                          creasingly unrealistic as the number
Here, we ﬁt a straight line, which is very obviously a linear model!      of possible choices of model terms
This simple starting point gives little hint of the range of models that  (variables, factors and interactions)
can be ﬁtted using R’s linear model lm() function.                        increases.

    The lm() function returns, as well as estimates, standard errors      2 Wilkinson, GN and Rogers, CE,
for parameters and for predictions. The standard error and p-value        1973. Symbolic description of models
information provided by the lm() function assumes that the random         in analysis of variance, Applied
term is i.i.d. (independently and identically distributed) normal. The    Statistics 22: 392-399.
independence assumption can be crucial.

    The standard errors assume, also, a single model that is known
from the start and on which the analysis is based.1 If this assumption
is incorrect, it can be important to resort to the use of empirical
methods for assessing model performance – perhaps some variation
of training/test methodology, or the bootstrap.

    The symbolic notation2 that is available in R for describing lin-
ear models makes it straightforward to set up quite elaborate and
intricate models.
                                                        regression with linear terms and factors 145

Scatterplot with ﬁtted line – an example                                                   30 q

The following plots data from the data frame roller (as in Figure                          25                                   q
8.1) from the DAAG package.                                                                                                  q
                                                                               depression
library(DAAG)                                                                              20 q q
plot(depression ~ weight, data=roller, fg="gray")
                                                                                           15
    The formula depression ~ weight can be used either as a
graphics formula or as a model formula. The following ﬁts a straight                       10 q
line, then adding it to the above plot:
                                                                                           5         qq     6                   8 10 12
plot(depression ~ weight, data=roller, fg="gray")                                               q   q
roller.lm <- lm(depression ~ weight , data=roller)
# For a line through the origin, specify                                                   0             4
# depression ~ 0 + weight
abline(roller.lm)                                                                                2

Figure 8.2 repeats the plot, now with a ﬁtted line added.                                                   weight
    The diﬀerent explanatory variables in the model are called
                                                                               Figure 8.1: Plot of depression
terms. In the above, there is one explicit term only on the right,             versus weight, using data from the
i.e., weight. This is in addition to the intercept, which is included          data frame roller in the DAAG
by default.                                                                    package.

                                                                                           30 q

                                                                                           25                                   q
                                                                                                                             q
                                                                               depression
                                                                                           20 q q

                                                                                           15

8.1.1 Straight line regression – algebraic details                                         10 q

The standard form of simple straight line model can be written                             5         qq
                                                                                                q   q
      depression = α + β × weight + noise.
                                                                                           0             4
Now write y in place of depression and x in place of weight, and                                            6                   8 10 12
add subscripts, so that the observations are: (x1, y1), (x2, y2), . . . ,(xn,                    2
yn). Then the model can be written:
                                                                                                            weight

                   yi = α + βxi + εi.                                          Figure 8.2: This repeats Figure 8.1,
                                                                               now adding a ﬁtted line.

The α + βxi term is the “ﬁxed” component of the model, and εi is
the random noise.

    The line is chosen so that the sum of squares of residuals is as
small as possible, i.e., the intercept α and the slope β chosen to mini-

mize               n

                     (yi − α − βi xi)2

                   i=1

The R function lm() will provide estimates a of α and b of β.

The straight line

                        y = a + bx

can then be added to the scatterplot.
    Fitted or predicted values, calculated so that they lie on the esti-

mated line, are obtained using the formula:

                    y1 = a + bx1, y2 = a + bx2, . . . .

The residuals, which are the diﬀerences between the observed and
ﬁtted values, give information about the noise.

                   e1 = y1 − y1, e2 = y2 − y2, . . . .          (8.1)
146 learning and exploring r

8.1.2 Syntax – model, graphics and table formulae:

The syntax for lm() models that will be demonstrated here is used,
with modiﬁcation, throughout the modeling functions in R. A very
similar syntax can be used for specifying graphs and for certain
types of tables.

Model objects                                                           Components of model objects can
                                                                        be accessed directly, as list objects.
The following code returns a model object to the command line.          But it is usually better to use an
                                                                        extractor function. Note in particular
lm(depression ~ weight, data=roller)                                    residuals() (can be abbreviated
                                                                        to resid()), coefficients()
Call:                                                                   (coef()), and fitted.values()
lm(formula = depression ∼ weight, data = roller)                        (fitted()). For example:

                                                                          coef(roller.lm)

Coefficients:     weight
(Intercept)          2.67

           -2.09

When returned to the command line in this way, a printed summary
is returned.

    Alternatively, the result can be saved as a named object, which is
a form of list.

roller.lm <- lm(depression ~ weight , data=roller)

    The names of the list elements are:

names(roller.lm)

[1] "coefficients" "residuals"  "effects"
                                "qr"
"rank"                          "terms"

[5] "fitted.values" "assign"

"df.residual"

[9] "xlevels"     "call"

"model"

8.1.3 Matrix algebra – straight line regression example

In order to write the quantity

                                          10

                                 (yi − a − bxi)2

                                       i=1

that is to be minimized in matrix form, set:
                                                                                                                                                                                                                                                                                      regression with linear terms and factors 147

      1                                               1.9                                                         2                                                                                                                  2 − (a + 1.9b) 
                                                                            
X  =                                                1  3.1                                                 ;  y  =                                                1                                                 ;  e  =  y − Xb  =                                                 1 − (a + 3.1b)                                                 where b =  a
                                                    1  3.3                                                                                                        5                                                                                                                    5 − (a + 3.3b)                                                            b
                                                    1  4.8                                                                                                        5                                                                                                                    5 − (a + 4.8b)
                                                    1  5.3                                                                                                        20                                                                                                                  20 − (a + 5.3b)
                                                    1  6.1                                                                                                        20                                                                                                                  20 − (a + 6.1b)
                                                    1  6.4                                                                                                        23                                                                                                                  23 − (a + 6.4b)
                                                    1  7.6                                                                                                        10                                                                                                                  10 − (a + 7.6b)
                                                    1  9.8                                                                                                        30                                                                                                                  30 − (a + 9.8b)
                                                    1  12.4                                                                                                       25                                                                                                                  25 − (a + 12.4b)

    Here a and b are chosen to minimize the sum of squares of ele-
ments of e = y − Xb, i.e., to minimize

                                                                                                              e e = (y − Xb) (y − Xb)

The least squares equations can be solved using matrix arithmetic.

Recap, and Next Steps in Linear Modeling

For this very simple model, the model matrix had two columns only.
Omission of the intercept term will give an even simpler model
matrix, with just one column.

    Regression calculations in which there are several explanatory
variables are handled in the obvious way, by adding further columns
as necessary to the model matrix. This is however just the start to the
rich range of possibilities that model matrices open up.

8.1.4 A note on the least squares methodology                                                                                                                                                                                                                                                           The assumptions of independence and
                                                                                                                                                                                                                                                                                                        identical distribution (iid) are crucial.
More fundamental than least squares is the maximum likelihood                                                                                                                                                                                                                                           The role of normality is commonly
principle. If the “error” terms are independently and identically                                                                                                                                                                                                                                       over-stated.
normally distributed, then least squares and maximum likelihood are
equivalent.                                                                                                                                                                                                                                                                                             3 Weighted least squares is however
                                                                                                                                                                                                                                                                                                        justiﬁed by maximum likelihood if it
    Least squares will not in general yield maximum likelihood                                                                                                                                                                                                                                          is known how the variances change
estimates, and the SEs returned by lm() or by predict() from an                                                                                                                                                                                                                                         with xi, or if the pattern of change
lm model will be problematic or wrong if:                                                                                                                                                                                                                                                               can be inferred with some reasonable
                                                                                                                                                                                                                                                                                                        conﬁdence.
• Variances are not homogeneous3;
                                                                                                                                                                                                                                                                                                        Simplifying the model, in ways
• Observations are not independent;                                                                                                                                                                                                                                                                     that do not much aﬀect coeﬃcients
                                                                                                                                                                                                                                                                                                        that remain in the model, may be
• The sampling distributions of parameter estimates are noticeably                                                                                                                                                                                                                                      acceptable.
   non-normal.

• Model terms (variables, factors and/or interactions) have been
   chosen from some wider set of possibilities (the theory assumes a
   specﬁc known model).

    Normality of the model ’errors’ is more than is in practice re-
quired. Outliers, and skewness in the distribution, do often mean that
the theory cannot be satisfactorily used as a good approxation.
148 learning and exploring r

8.2 Checks — Before and After Fitting a Line

Consider here a female versus male comparison of record times for
Northern Island hill races.

  A: Untransformed scales                               q                                  B: Logarithmic scales                                                     q  Figure 8.3: Graphs compare female
                                                                                                                                                                        with male record times, for Northern
6                                                                                      5.0                                                                              Ireland hill races. Least squares lines
                                                                                                                                                                        are added, and marginal boxplots are
Female times5                                                                                                                                                           shown on the horizontal axis. Panel
                                                             Female times (log scale)                                                                                   A has untransformed scales, while
4                                                                                                                                                                 q     Panel B has log transformed scales.
                                                                                                                                                                        For the code, see the script ﬁle for this
                                                                                       2.0 q                                                                            chapter.

3                                                                                                             qq

                                              q                                        1.0             q
                                                                                               qqq
2q
                                                                                                          qq
                       qq                                                                      qqqqqqqqqqq

1 qqqqqqqqqqqq q                                                                       0.5

         q                                                                                  q

                           qq                              q                                                                                            qq           q

                          time                                                                               time
   0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0                                                          0.5 1.0 2.0

                           Male times                                                       Male times (log scale)

Untransformed vs transformed scales: Figure 8.3 shows two alter-
native views of the data. Least squares line have in each case been
added.

    In Panel A, a single data point at the top right lies well away
from the main body of data. In Panel B, points are more evenly
spread out, though still with a tail out to long times.

    The following ﬁts a regression line on the untransformed scale:

mftime.lm <- lm(timef ~ time, data=nihills)

    The line appears to ﬁt the data quite reasonably well. Is this an
eﬀective way to represent the relationship? An obvious problem is
that data values become increasingly sparse as values increase, with
one point widely separated from other data. That one data point,
widely separated from other points, stands to have a disproportionate
eﬀect in determining the ﬁtted line.

    The coeﬃcients for the line that is ﬁtted on a logarithmic scale
is:

mflogtime.lm <- lm(log(timef) ~ log(time),
                                  data=nihills)

round(coef(mflogtime.lm), 3)

(Intercept) log(time)

   0.267                                         1.042

The coeﬃcient of 1.042 for log(time) implies that the relative rate
of increase of female times is 4.2% greater than the relative rate of
increase of male times.
                                                                             regression with linear terms and factors 149

The use of residuals for checking the ﬁtted line:

In Figure 8.3, departures from the line do not stand out well rela-
tive to the line. To make residuals stand out, Figures 8.4A and 8.4B
rotate the lines, for the untransformed and transformed data respec-
tively, ∼45◦ clockwise about its mid-point, to the horizontal.

   A: Residuals, unlogged data                                                    B: Residuals, logged data               Figure 8.4: In Panel A, residuals from
                                                                                                                          the line for the unlogged data have
0.2 q                                                                      0.10              q                         q  been plotted against male times. Panel
resid(mftime.lm)                                                                                                          B repeats the same type of plot, now
                                                      resid(mflogtime.lm)0.1qqqqq q          q    q          q            for the regression for the logged data.
 0.0    qqqqq q                                                                              qqq                    q
−0.1                                                                       0.05                                           A residual of -0.1 denotes a time that
                                                                                                                          is about 10% (more accurately 9.5%)
                                                                                          q          q                    less than the ﬁtted value on the line. A
                                                                                                                          residual of 0.1 denotes a time that is
      qq             q                                                      0.00             qqq                          about 10% (more accurately 10.5%)
                                                                           −0.05                                          more than the ﬁtted value.
      q          qq                                                                            q  qq
      q                                                                                      q        q

−0.2             q

−0.3                                                                       −0.10                  qq
         0.5                                                                                           q

                              q                                                                           q

                     1.5 2.5     3.5                                              −1.0 0.0 0.5 1.0

                        time                                                                      log(time)

Notice that, in Figure 8.4A, all residuals except that for the largest
time lie very nearly on a line. The point with the largest ﬁtted value,
with the largest male (and female) time, is pulling the line out of
whack. There is a mismatch between the data and the model. The
picture in Figure 8.4B is much improved, though there still is an
issue with the point for the longest time.

    Residuals on the vertical scale of Figure 8.4B are on a scale
of natural logarithms (logarithms to base e). As the range is small
(roughly between -0.1 and 0.1), the values can be interpreted as
relative diﬀerences on the scale of times.

The common beneﬁts of a logarithmic transformation: Where
measurement data have a long tail out to the right, it commonly
makes sense to work with logarithms of data values, as in Figure
8.3B. Often, working with data on a logarithmic scale has several
useful consequences:

- The skewness is reduced

- The variation at the high end of the range of values is reduced,
   relative to variation at the low end of the range of values.

- Working on a logarithmic scale is equivalent to working with
   relative, rather than absolute, change. Thus a change from 10 to
   20 is equivalent to a change from 20 to 40, or from 40 to 80. On a
  logarithmic scale, these are all changes by an amount of log(2).

- By default, the function log()) returns natural logarithms, i.e.,
   logarithms to base e. On this scale, a change of 0.05 is very close
   to a change of 5%. A change of 0.15 is very roughly a change
   of 15%. [A decrease of 0.15 is a decrease of 13.9%, while an
   increase of 0.15 is a increase of 16.2%]
150 learning and exploring r                                                             4 Statistics that try to provide an
                                                                                         overall evaluation focus too much on
    Once the model is ﬁtted, checks can and should be made on the                        a speciﬁc form of departure, and do
extent and manner of diﬀerences between observations and ﬁtted                           a poor job at indicating whether the
model values. Graphical checks are the most eﬀective,4 at least                          departure from assumptions matters.
as a starting point. Mostly, such checks are designed to highlight
common types of departure from the model.                                                Section 8.3 demonstrates the use of
                                                                                         simulation to help in judging between
    Figure 8.4B provided a simple form of diagnostic check. This                         genuine indications of model depar-
is one of several checks that are desirable when models have been                        tures and features of the plots that may
ﬁtted.                                                                                   well reﬂect statistical variation.

8.2.1 ∗Diagnostics – checks on the ﬁtted model

For lm models, the R system has a standard set of diagnostic plots
that users are encouraged to examine. These are a starting point for
investigation. Are apparent departures real, or may they be a result
of statistical variation? For the intended use of the model output, do
apparent departures from model assumptions matter.

    For drawing attention to diﬀerences between the data and what
might be expected given the model, plots that show residuals are in
general much more eﬀective than plots that show outcome (y) vari-
able values. Additionally, plots are needed that focus on common
speciﬁc types of departure from the model.

All four diagnostic plots

Figure 8.5 shows the default diagnostic plots for the regression with
the untransformed data:

      Residuals vs Fitted                       Normal Q−Q                  Scale−Location                                                                                                  Residuals vs Leverage

                                        4 Seven Sevensq             2.0 Seven Sevensq                                                                                                      4 Seven Sevensq
                                                                                                  qAnnalong Horseshoe
                                        2
                                        0 qqqqqqqqqqqqqqqqqqq q     1.5
                                       −2 qDonard & Commedagh                        qDonard & Commedagh
Residuals
                                                      Standardized residualsqAnnalong Horseshoe
                                                                                                             Standardized residuals−2 −1 0 1 2
                                                                                                                                                                   Standardized residuals
0.2 Seven Sevensq                            Theoretical Quantiles

 0.1  qqqqqqqqqqqq  q                                               1.0 q                                                                                                                  2                       01.5
 0.0    qq                                                                  qqqq qqq                                                                                                       0 qqqqqqqqqqqq          01.5
−0.1      qqqq                                                                  q

−0.2  qDonard & Commedagh                                           0.5 qqqqqqq       q                                                                                                    −2 qDonard & Commedagh
−0.3              qAnnalong Horseshoe
                                                                                                                                                                                                      q AnnCaloonogkH'sorsdeisshtoaence
      12345                                                         0.0                                                                                                                    −4

         Fitted values                                                         12345                                                                                                           0.0 0.2 0.4 0.6 0.8

                                                                                Fitted values                                                                                                            Leverage

Simpliﬁed code is:                                                                       Figure 8.5: Diagnostic plots from the
                                                                                         regession of timef on time.
mftime.lm <- lm(timef ~ time, data=nihills)
plot(mftime.lm , cex.caption=0.8)                                                        Two further plots are available; specify
                                                                                         which=4 or which=6, e.g.
The ﬁrst of these plots has similar information to Figure 8.4A above.
A diﬀerence is that residuals are now plotted against ﬁtted values. It                     plot(mftime.lm, which=4.
is immaterial, where there is just one explanatory variable, whether                     These give a diﬀerent slant on what
residuals are plotted against ﬁtted values or against x-values – the                     is shown in the fourth default plot
diﬀerence between plotting against a + bx and plotting against x                         (which=5).
amounts only to a change of labeling on the x-axis.

    Figure 8.6 shows the default diagnostic plots for the transformed
data. Simpliﬁed code is:
                                                                                                              regression with linear terms and factors 151

plot(mflogtime.lm , cex.caption=0.8)
par(opar)

               Residuals vs Fitted                                Normal Q−Q                                         Scale−Location                                                            Residuals vs Leverage

                                                                                             Seven Sevensq    1.5 Seven Sevensq
Residuals                 Seven Sevensq                   2                                                                                                                                              Seven Sevensq
0.10                                                  Standardized residualsq
                                                                                                             Standardized residualsq                                                                                             1
                                                                                                                                                                   Standardized residuals                                        0.5
                                                          1 qqqqqq                                                                  qDonard & Commedagh                                    2
                                                          0 qqqqq                                                    q qSlieve Bearnagh                                                               q

0.05           qqqq q     q                                                        qqq                               q  qq                                                                 1 qqqqq q
                                                                                qq                                   qqq
                       q                                 −1 q                                                 1.0                  q     qq
                                                                         qq                                            q
            q  qqq                                                    qSlieve Bearnagh                                                q                                                        q
 0.00           qqq                                      −2 qDonard & Commedagh                                                                                                                qqq
−0.05          qq                                             −2 −1 0 1 2                                                                                                                  0        q

                                                               Theoretical Quantiles                          0.5 q  q qq q                                                                    qqq
                                                                                                                                                                                               qq
                             q                                                                                                                                                                           qAnnalong Horseshoe 0.5

−0.10             qq                                                                                                         q                                                             −1  qq                                   1
                      q SlievqeDBoenaarrndag&hCommedagh                                                                        qq                                                          −2
                                                                                                                                                                                               q q DonaCrdo&oCko'ms mdeisdataghnce
                                                                                                              0.0

−1.0 0.0 0.5 1.0 1.5                                                                                          −1.0 0.0 0.5 1.0 1.5                                                             0.0 0.1 0.2 0.3 0.4

          Fitted values                                                                                                 Fitted values                                                                    Leverage

The point for the largest time still has a very large leverage and, as                                                                       Figure 8.6: Diagnostic plots from
indicated by its position relative to the Cook’s distance contours,                                                                          the regression of log(timef) on
a large inﬂuence on the ﬁtted regression line. This may, in part or                                                                          log(time).
entirely, be a result of a variance that, as suggested by the scale-
location plot in Panel 3, tends to increase with increasing ﬁtted
value. The normal Q-Q plot (Panel 2) suggests an overall distri-
bution of residuals that is acceptably normal. The large residual
associated with the largest time in Panel 1 would look much less out
of place if there was an adjustment that allowed for a variance that
increases with increasing ﬁtted value.

    These diﬀerences from the assumed model are small enough that,
for many purposes, the line serves as a good summary of the data.
The equation is:

mflogtime.lm <- lm(log(timef) ~ log(time),
                                  data=nihills)

round(coef(mflogtime.lm), 3)

(Intercept) log(time)

0.267                           1.042

The coeﬃcient that equals 1.042 can be interpreted as a relative rate                                                                        To obtain this second plot only,
of increase, for female time relative to male time. Consider a race                                                                          without the others, type:
for which the male record time is 100 minutes. The predicted female
time is:                                                                                                                                     plot(mftime.lm , which=2)

       exp(0.267 + 1.042 log(100/60)) = 2.223h = 133.4m.

An increase of one minute, or 1%, in the male time, is predicted to
lead to an increase of close to 1.042 × 1% in the female time. The
predicted increase is 133.4 × 1.042m.

Panel 2 — A check for normality: The second panel in Figure 8.5
identiﬁes two large negative residuals and one large positive resid-
ual. This seems inconsistent with the assumption that residuals have
a normal dsitribution. Again, Figure 8.6 shows an improvement.

    Modest departures from normality are not a problem per se.
Heterogeneity of variance, and outliers in the data, are likely to be
the more serious issues.
152 learning and exploring r

Panel 3 — Is the variance constant?: The third panel is designed        To obtain this third plot only, without
to check whether variation about the ﬁtted line, as measured by the     the others, type:
variance, is constant. For this, there should be no trend up or down
in the points. The large upward trend in the third panel of 8.5 has     plot(mftime.lm , which=3)
largely disappeared in the third panel of Figure 8.6.
                                                                        To obtain this fourth plot only, with-
Panel 4 — a check for high leverage points: The fourth panel is         out the others, type:
designed to check on points with large leverage and/or large inﬂu-
ence. In straight line regression, the most extreme leverage points     plot(mftime.lm , which=5)
are points that are separated from the main body of points, and are at
the high or (less commonly) low end of the range of x-values.           For working within the main range
                                                                        of the data values, we might prefer
    The combined eﬀect of leverage and magnitude of residual            to use the regression line that is
determines what inﬂuence a point has. Large leverage translates         obtained when ‘Seven Sevens’ is
into large inﬂuence, as shown by a large Cook’s distance, when the      omitted. If ‘Seven Sevens’ is omitted
residual is also large. Points that lie within the region marked out    in estimating the regression line, this
by the 0.5 or (especially) the 1.0 contour for Cook’s distance have     should be made clear in any report,
a noticeable inﬂuence on the ﬁtted regression equation. Even with       and the reason explained. The large
the logged data, the point for the largest time (‘Seven Sevens’) is     residual for this point does hint that
skewing the regression line noticeably.                                 extrapolation much beyond the upper
                                                                        range of data values is hazardous.
    Note that there is no reason to suspect any error in this value.
Possibly the point is taking us into a part of the range where the
relationship is no longer quite linear. Or this race may be untypical
for more reasons than that it is an unusually long race.

    The following shows the change when ‘Seven Sevens’ is omit-
ted:

round(coef(mflogtime.lm), 4)

(Intercept) log(time)

0.2667         1.0417

omitrow <- rownames(nihills)!="Seven Sevens"
update(mflogtime.lm , data=subset(nihills , omitrow))

Call:
lm(formula = log(timef) ∼ log(time), data = subset(nihills , omitrow))

Coefficients:

(Intercept) log(time)

0.239          0.991

8.2.2 The independence assumption is crucial

A key assumption is that observations are independent. The indepen-
dence assumption is an assumption about the process that generated
the data, about the way that it should be modeled. There is no one
standard check that is relevant in all circumstances. Rather the ques-
tion should be: “Are there aspects of the way that the data were
                                                                                                                              regression with linear terms and factors 153

generated that might lead to some form of dependence?” Thus, when
data are collected over time, there may be a time series correlation
between points that are close together in time.

    Another possibility is some kind of clustering in the data, where
observations in the same cluster are correlated. In medical applica-
tions, it is common to have multiple observations on the one individ-
ual. Where clusters may be present, but there is no way to identify
them, dependence is hard or impossible to detect.

    Issues of dependence can arise in an engineering maintenance
context. If the same mechanic services two aircraft engines at the
same time using replacement parts from the same batch, this greatly
increases the chances that the same mistake will be made on the two
engines, or the same faulty part used. Maintenance faults are then
not independent. Independence is not the harmless assumption that it
is often made out to be!

    There may be further checks and tests that should be applied.
These may be speciﬁc to the particular model.

8.3 ∗Simulation Based Checks

A good way to check whether indications of departures from the                                                                                              If the assumption of independent
model may be a result or random variation is to compare the plot                                                                                            random errors is wrong, patterns in
with similar plots for several sets of simulated data values, as a                                                                                          the diagnostic plots that call for an
means of verifying that the mismatch is, if residuals from the line                                                                                         explanation may be more common
are independent and normally distributed, real. This is the motiva-                                                                                         than suggested by the simulations.
tion for Figure 8.7.
                                                                                                                                                            Figure 8.7: The plots are four simu-
                                           Simulated residuals q                    Actual residuals q                                                      lations of residuals, from the model
                                                                                                                                                            that is ﬁtted to the unlogged data. The
                                              1234                                                                            1234                          coeﬃcients used, and the standard
                                                                                                                                                            deviation, are from the ﬁtted least
                       Simulation1            Simulation2                           Simulation3                                      Simulation4            squares line.

            0.3     q                                                                                                                      q
            0.2                                                                                                               qq
Residuals   0.1  q                         q                                     q                                                                       q
            0.0                                                                                                                           q              q
           −0.1  qqqqqqqqqqqqqqqqq q q     q  qqqqqqqqqqqqqqqqqqqqqqqqqqqq q        qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq     q               q
           −0.2   qqqqqqqqqqq q                 qq q                                                                               qqqqqqqqqqqqqqq
                  q                     q                                        q                                   q               qqqqqqqqqqqq q q
                  qq                                                                                                 q        qq
                                                                                                                                     q qq
                                                                              q
                                                                                                                                                      q
                                              qq                                    qq
                                                                                                                              4
                                  q                               q                            q                           3

                       123                 4                                        12

                                                                                 Time (h) for males

## Code
gph <- plotSimScat(obj=mftime.lm , show="residuals",

                                  type=c("p","smooth"),
                                  layout=c(4,1))
update(gph, xlab="Time (h) for males",
           ylab="Residuals")

    The simulations indicate that there can be a pattern in the smooth
curve that is largely due to the one point that is widely separated
from other data. On the other hand, the very large residual seen in
the actual data is not matched in any of the simulations.

    This type of check can be repeated for the other diagnostic plots:
154 learning and exploring r

- A check for normality (Panel 2: which=2. Type:

    plotSimDiags(obj=mftime.lm , which=2, layout=c(4,1))

- Is the variance constant? (Panel 3: which=3. Type:

    plotSimDiags(obj=mftime.lm , which=3, layout=c(4,1))

- Are there issues of leverage and inﬂuence? (Panel 4: which=5.
   Type:

    plotSimDiags(obj=mftime.lm , which=5, layout=c(4,1))

Scatterplots that are derived from the simulation process

To see scatterplots that are derived from the simulation process,
use the function plotsimscat(), from the DAAG package. For
example, try, working with the untransformed data:

 gph <- plotSimScat(mftime.lm , layout=c(4,1))
 update(gph, xlab="Male record times (h)",

             ylab="Female record times (h)")

Observe that the largest simulated value lies consistently above the
data value. Other simulated values, for male times of more than
around one hour, tend to lie below the actual data. This is much
easier to see in the plots of residuals. A scatterplot that shows the
actual data values is not a good tool for making these diﬀerence
visually obvious.

8.4 Key questions for the use of models

Key questions are:
• Modeling and analysis

  – Which model?
  – Do we want to make predictions? Or is the interest in getting

      parameter estimates that are interpretable?
  – How will model performance be measured?
  – How close can we get to measuring the performance that mat-

      ters?

• Interpretation

  – The task is easier if the aim is prediction, rather than interpreta-
      tion of model parameters.

  – Can model parameters be interpreted in scientiﬁcally meaning-
      ful ways?
      [This is a mineﬁeld, with huge scope for getting it wrong.]

    More detailed comments will now follow on some of the issues
raised above.
regression with linear terms and factors 155

The choice of method: Note the use of the word “method”, not
algorithm. Algorithms specify a sequence of computational steps.
Something more than an algorithm is needed, if results are to have
some use that generalizes beyond the speciﬁc data used.

    There are many diﬀerent methods. How should the analyst
choose between them? What are good ways to assess the perfor-
mance of one or other algorithm? A credible measure of model
performance is needed, evaluated on test data that closely reﬂects the
context in which the model will be applied.

Which are the important variables? Often, the analyst would like           5 Rosenbaum, P.R, 2002. Observa-
to know which data columns (variables, or features) were important         tional Studies, 2nd edn. Springer-
for, e.g., a classiﬁcation. Could some of them be omitted without          Verlag.
loss?

    The analyst may wish to attach an interpretation to one or more
coeﬃcients? Does the risk of heart attack increase with the amount
that a person smokes? For a meaningful interpretation of model
parameters, it is necessary to be sure that:

• All major variables or factors that aﬀect the outcome have been
   accounted for.

• Those variables and factors operate, at least to a ﬁrst order of
   approximation, independently.

    In some cases, a diﬀerent but equivalent choice of parameters
will be more meaningful. For working with the Northern Ireland
hillrace data in Subsection 8.6, the parameters dist and climb
clearly do not exercise their eﬀects independently, making their
coeﬃcients diﬃcult to interpret. It is better to work with log(dist)
and log(dist/climb), which are very nearly independent.

    See Rosenbaum’s Observational Studies5 for comments on ap-
proaches that are often useful in the attempt to give meaningful
interpretations to coeﬃcients that are derived from observational
data.

8.5 Factor Terms – Contrasts                                               Another special type of term is one
                                                                           that allows smooth functions of
Here, we show how regression models can be adapted to ﬁt terms             explanatory variables. Again, linear
involving factors.                                                         models can be adapted to handle such
                                                                           terms.
    Additive A is conc nutrient, B is 3x conc nutrient, and C
is 2-4-D + conc nutrient. For convenience, we label the factor
levels Water, A, B, and C, in that order.

lev <- c("Water", "A", "B", "C")
tomato[, "trt"] <- factor(rep(lev, rep(6,4)),

                                               levels=lev)

Taking Water as the initial level the eﬀect, in the ﬁrst analysis that is
given below, that it is treated as a reference level.
156 learning and exploring r

Water              A                B                                                      C             Table 8.1: Root weights (weight) (g)
(Water only)       (Additive 1)     (Additive 2)                                           (Additive 3)  of tomato plants, grown with water
                   1.50             1.90                                                   1.00          only and grown wth three diﬀerent
          1.50     1.20             1.60                                                   1.20          treatments. Data are in the data frame
          1.90     1.20             0.80                                                   1.30          tomato (DAAG 1.17 or later).
          1.30     2.10             1.15                                                   0.90
          1.50     2.90             0.90                                                   0.70          Figure 8.8: Termplot summary of
          2.40     1.60             1.60                                                   0.80          the one-way analysis of variance
          1.50     0.983            1.75                                                   0.983         result — A: for the analysis that uses
Mean = 1.683                                                                                             weights as the outcome variable, and
                                                                                                         B: for the analysis that works with
8.5.1 Example – tomato root weight                                                                       log(weight)

The model can be ﬁtted either using the function lm() or using the
function aov(). The two functions give diﬀerent default output. The
main part of the calculations is the same whether lm() or aov() is
used.

    For model terms that involve factor(s), there are several diﬀer-
ent ways to set up the relevant columns of the model matrix. The
default, for R and for many other computer programs, is to take one
of the treatment levels as a baseline or reference, with the eﬀects
of other treatment levels then measured from the baseline. Here it
makes sense to set Water as the baseline.

    Table 8.2 shows the model matrix when Water is taken as the
baseline. Values of the response (tomato$weight) have been added
in the ﬁnal column. Also included, in the column headers, is infor-
mation from the least squares ﬁt.

    The following uses aov() for the calculations:

## Analysis of variance: tomato data (from DAAG)
tomato.aov <- aov(weight ~ trt, data=tomato)

    Figure 8.8A is a useful summary of what the analysis has
achieved. The values are called partials because the overall mean
has been subtracted oﬀ. Figure 8.8B that is shown alongside shows
the eﬀect of working with the logarithms of weights. The scatter
about the mean for the treatment still appears much larger for the
controls than for other treatments.

   A: weight                                                                    B: log(weight)

1.5 q                                                                        0.8 q

Partial for treatment1.0 q                                                  0.6  q      q
                                                      Partial for treatment 0.4
                q                                                           0.2  q      q       q
                                                                            0.0         q       q
0.5 q              q                                                       −0.2  q
                                                                                 q      q       q
                qq                                                                                 q
                                                                                                   q
0.0 q           q
                                                                                                   q
      q                    q                                                                       q
                           q                                                                       q
                qq                                                         −0.4                    q
                           q                                               −0.6
−0.5               q       q                                                                    q  C
                   q       q                                                                    q
                           q
      Water     A  B                                                             Water  A       B
                           C

                Treatment                                                               Treatment

Code for Figures 8.8A and 8.8B is:
                   regression with linear terms and factors 157

## Panel A: Use weight as outcome variable
tomato.aov <- aov(weight ~ trt, data=tomato)
termplot(tomato.aov , xlab="Treatment",

                ylab="Partial for treatment",
                partial.resid=TRUE, se=TRUE, pch=16)
mtext(side=3, line=0.5, "A: weight", adj=0, cex=1.2)
## Panel B: Use log(weight) as outcome variable
logtomato.aov <- aov(log(weight) ~ trt, data=tomato)
termplot(logtomato.aov , xlab="Treatment",
                ylab="Partial for treatment",
                partial.resid=TRUE, se=TRUE, pch=16)
mtext(side=3, line=0.5, "B: log(weight)", adj=0,
           cex=1.2)

    Residuals, if required, can be obtained by subtracting the ﬁtted
values in Table 8.2 from the observed values (y) in Table 8.1.

    Coeﬃcient estimates for the model that uses weight as the de-
pendent variable, taken from the output summary from R, are:

round(coef(summary.lm(tomato.aov)),3)

      Estimate Std. Error t value Pr(>|t|)

(Intercept) 1.683  0.187 9.019 0.000

trtA  0.067        0.264 0.253 0.803

trtB  -0.358       0.264 -1.358 0.190

trtC  -0.700       0.264 -2.652 0.015

   The row labeled (Intercept) gives the estimate (= 1.683) for
the baseline, i.e., Water. The remaining coeﬃcients (diﬀerences
from the baseline) are:

  A: weight diﬀers by 0.067.

  B: weight diﬀers by −0.358.

  C: weight diﬀers by −0.700.

Regression calculations have given us a relatively complicated way
to calculate the treatment means! The methodology shows its power
to better eﬀect in more complex forms of model, where there is no
such simple alternative.

    Examination of the model matrix can settle any doubt about how
to interpret the coeﬃcient estimates, The ﬁrst four columns of Table
8.2 comprise the model matrix, given by:

model.matrix(tomato.aov)

The multipliers determined by least squares calculations are
shown above each column. Also shown is the ﬁtted value,
which can be calculated either as fitted(tomato.aov) or as
predict(tomato.aov).

8.5.2 Factor terms – diﬀerent choices of model matrix

In the language used in the R help pages, diﬀerent choices of con-
trasts are available, with each diﬀerent choice leading to a diﬀerent
158 learning and exploring r

Water: 1.683  A: +0.067       B: −0.358  C: −0.700  Fitted                Table 8.2: The model matrix for the
                                                    value                 analysis of variance calculation for
1             0               0          0          1.683                 the data in Table 8.1 is shown in gray.
1             0               0          0          1.683                 A fourth column has been added that
....                                                                      shows the ﬁtted values. At the head
1             0               0          0          1.683                 of each column is the multiple, as
1             1               0          0          1.750                 determined by least squares, that is
1             1               0          0          1.750                 taken in forming the ﬁtted values.
....
1             1               0          0          1.750                 Be sure to choose the contrasts that
1             0               1          0          1.325                 give the output that will be most
1             0               1          0          1.325                 helpful for the problem in hand. Or,
....                                                                      more than one run of the analysis
1             0               1          0          1.325                 may be necessary, in order to gain
1             0               0          1          0.983                 information on all eﬀects that are of
1             0               0          1          0.983                 interest.
....
1             0               0          1          0.983

model matrix and to diﬀerent regression parameters. The ﬁtted val-
ues remain the same, the termplot in Figure ﬁg:tomatotermA is
unchanged, and the analysis of variance table is unchanged.

    Where there is just one factor, the constant term can be omitted,
i.e., it is eﬀectively forced to equal zero. The parameters are then the
estimated treatment means. Specify:

## Omit constant term from fit;
## force parameters to estimate treatment means
tomatoM.aov <- aov(weight ~ 0 + trt, data=tomato)

    The ﬁrst nine rows of the model matrix are:

mmat <- model.matrix(tomatoM.aov)
mmat[1:9, ]

   trtWater trtA trtB trtC
1 1000
2 1000
3 1000
4 1000
5 1000
6 1000
7 0100
8 0100
9 0100

## ... ... ... ...

Observe that there is now not an initial column of ones. This is ﬁne
when there is just one factor, but does not generalize to handle more
than one factor and/or factor interaction.

    The default (treatment) choice of contrasts uses the initial factor
level as baseline, as we have noted. Diﬀerent choices of the baseline
                                                                             regression with linear terms and factors 159

or reference level lead to diﬀerent versions of the model matrix.
The other common choice, i.e., sum contrasts, uses the average of
treatment eﬀects as the baseline.

The sum contrasts

Here is the output when the baseline is the average of the treatment
eﬀects, i.e., from using the sum contrasts:

oldoptions <- options(contrasts=c("contr.sum",
                                                             "contr.poly"))

tomatoS.aov <- aov(weight ~ trt, data=tomato)
round(coef(summary.lm(tomatoS.aov)),3)

      Estimate Std. Error t value Pr(>|t|)

(Intercept) 1.435           0.093 15.381 0.000

trt1        0.248           0.162 1.534 0.141

trt2        0.315           0.162 1.946 0.066

trt3        -0.110          0.162 -0.683 0.502

options(oldoptions) # Restore default contrasts                              The estimates (means) are:
                                                                               Water: 1.435 + 0.248 = 1.683.
The baseline, labeled (Intercept), is now the treatment mean.                  A: 1.435 + 0.315 = 1.750.
This equals 1.435. Remaining coeﬃcients are diﬀerences, for Water              B: 1.435 − 0.110 = 1.325.
and for treatment levels A and B, from this mean. The sum of the               C: 1.435 − 0.452 = 0.983.
diﬀerences for all three treatments is zero. Thus the diﬀerence for C
is (rounding up)

               −(0.2479 + 0.3146 − 0.1104) = −0.4521.

    Yet other choices of contrasts are possible; see
help(contrasts).

Interaction terms

The data frame cuckoos has the lengths and breadths of cuckoo
eggs that were laid in the nexts of one of six diﬀerent bird species.
The following compares a model where the regression line of
breadth against length is the same for all species, with a model that
ﬁts a diﬀerent line for each diﬀerent cuckoo species:

cuckoos.lm <- lm(breadth ~ species + length , data=cuckoos)
cuckoosI.lm <- lm(breadth ~ species + length + species:length , data=cuckoos)
print(anova(cuckoos.lm , cuckoosI.lm), digits=3)

Analysis of Variance Table

Model 1: breadth ∼ species + length

Model 2: breadth ∼ species + length + species:length

Res.Df RSS Df Sum of Sq F Pr(>F)

1 113 18.4

2 108 17.2 5        1.24 1.56 0.18

Here, the model cuckoos.lm, where the regression lines are parallel
(the same slope for each species), appears adequate.

    An alternative way to compare the two models is:
160 learning and exploring r

anova(cuckoos.lm , cuckoosI.lm , test="Cp")

The Cp statistic (smaller is better) compares models on the basis of
an assessment of their predictive power. Note the use of the argu-
ment test="cp", even though this is not a comparison that is based
on a signiﬁcance text.

8.6 Regression with two explanatory variables

Data exploration

The dataset nihills in the DAAG package has record times for
Northern Ireland mountain races. First, get a few details of the data:

str(nihills)

'data.frame ':                                23 obs. of 4 variables:
 $ dist : num                                7.5 4.2 5.9 6.8 5 4.8 4.3 3 2.5 12 ...
 $ climb: int                                1740 1110 1210 3300 1200 950 1600 1500 1500 5080 ...
 $ time : num                                0.858 0.467 0.703 1.039 0.541 ...
 $ timef: num                                1.064 0.623 0.887 1.214 0.637 ...

    The following Figure 8.9 repeats Figure 3.6 from Chapter 3.4.
The left panel shows the unlogged data, while the right panel shows
the logged data:

                          q                             q                     q6                                                           qqq
                                                                                   5
                                                                           q                             456                                                                                       1.5 0.5 1.5
                                                                       q
                                                            qqqqqqqqqqq           4                                                     q                                 q                              q       1.0
                                                                                                                                       q                           q                                 q
                                                        q4                            timef 3                                                                                                                   0.5 ltimef
                       q                          q          3                                                 q qqqqqqqqqqqqqqqqq                qqqqqqqqqqqqqqq  qq                qqqqqqqqqqqqqqqq
                     q                       q                                                           2       q                             q                   q             q                                             0.0
                                                                                                                                           q                                 q
qqqqqqqqqqqqqqqqq            qqqqqqqqqqqqqq  qq                                   123                    1                                                                                                  −1.0 0.0 −0.5
                                             q                                                                                                                                                                                −1.0

                          q                                                                                 q                                                                                                                                    q

                                                                              34                                                                                                   1.0 0.00.51.0

                                                                                                                                     q                                    q        0.5                                                   q
                                                                                                                                    q                              q                                                                   q
                                                                                                                                                                                   0.0 ltime 0.0
                       q                          q           time            2q                                  q             q                     q            qq                                                          qqq
                     q                                                                                                           q            qqqqqqqqqqqqqq       q                            −0.5                    qqqqqqqqqqqqq
                                             q    6000     12                                   q              q qqqqqqqqqqqqqqq           q                                    −1.0 0.0 −1.0                       q

qqqqqqqqqqqqqqqqqqq          qqqqqqqqqqqqqq  qq                               1 qqqqqqqqqqq
                                             q
                                                                                  q
                                                                                                               q
                                                                                                   q
                          q                                                              qqq q              q                           q 9.0                                                                    q                                  q
                                                                                      qqqqqqqqqqq           q                                          8.0 8.5 9.0                                      q                                 q
                               8000                                               q
                                                                                                                                    q 8.5
                              6000                                                              qq
                     q                                                    q           qqqqqqqqqqqqqqqqq                        q    q      8.0 lclimb8.0                            q         q      q                        q        q
                                  climb4000                                                                           qq                                                                     q                          qq
                                                              qqq q                                                                                      7.5
   q qq              q       2000 2000                     qqqqqqqqqqqqq                                       q qqqqqqqqqqqqq q                                                   qqqqqqqqqqqqqqqq                 qqqqqqqqqqqqqqqq
qqqqqqqqqqqqq q                                                                                                  q                         7.07.58.0 7.0                        q                               q
                                                                                                                                                                                                            q
                                                        q                                                        3.0                                                         q                                                              q

      10 15                                                                                                    2.5 2.0 2.5 3.0                                     qq                                qq                                qq
15

10 dist 10                                   qq                      qq                                          2.0 ldist 2.0                        q              q                       qq                         qq
                                                           qqqqqqqqqqqqqqqqq                                                                     qq                q
5 10 5                           q                                                                                              1.5           qqqqqqqqq                               q      q                           qq      q
                             qqqqqqqqqqqqqq                                                                    1.0 1.5 2.0                                         q            qqqqqqqqqqq                         qqqqqqqqqqq
                                               q                                                                                                      q                         q                                   q
                                             q                                                                                  1.0        qq                                   qq                                  qq
                                             q
                                                                                                                                                    q
                                                                                                                                                                                q                                   q

                                                  Scatter Plot Matrix                                                                                              Scatter Plot Matrix

    The relationships between explanatory variables, and between                                                                                                   Figure 8.9: Scatterplot matrices for
the dependent variable and explanatory variables, are closer to linear                                                                                             the Northern Ireland mountain racing
when logarithmic scales are used. Just as importantly, the point with                                                                                              data. In the right panel, code has been
the largest unlogged values (the same for all variables) will have a                                                                                               added that shows the correlations.
leverage, inﬂuencing the ﬁtted regression, that is enormously larger                                                                                               This repeats Figure 3.6 from Chapter
than that of other points.                                                                                                                                         3.4.
                                                                             regression with linear terms and factors 161

    The log transformed data are consistent with a form of parsimony
that is well-designed to lead to a simple form of model. We will see
that this also leads to more readily interpretable results. Also the
distributions for individual variables are more symmetric.

    Here again is the code:

## Unlogged data
library(lattice)
## Scatterplot matrix; unlogged data
splom(~nihills)

    The right panel requires a data frame that has the logged data

## Logged data
lognihills <- log(nihills)
names(lognihills) <- paste0("l", names(nihills))
## Scatterplot matrix; log scales
splom(~ lognihills)

8.6.1 The regression ﬁt

The following regression ﬁt uses logarithmic scales for all variables:

lognihills <- log(nihills)
lognam <- paste0("l", names(nihills))
names(lognihills) <- lognam
lognihills.lm <- lm(ltime ~ ldist + lclimb ,

                                    data=lognihills)
round(coef(lognihills.lm),3)

(Intercept)      ldist   lclimb
         -4.961  0.681    0.466

Thus for constant climb, the prediction is that time per mile will      The ﬁtted equation gives predicted
decrease with increasing distance. Shorter races with the same climb    times:
will involve steeper ascents and descents.
                                                                                 e3.205 × dist0.686 × climb0.502
    A result that is easier to interpret can be obtained by regressing     = 24.7e3.205 × dist0.686 × climb0.502
log(time) on log(dist) and log(gradient), where gradient
is dist/climb.

nihills$gradient <- with(nihills , climb/dist)
lognihills <- log(nihills)
lognam <- paste0("l", names(nihills))
names(lognihills) <- lognam
lognigrad.lm <- lm(ltime ~ ldist + lgradient ,

                                  data=lognihills)
round(coef(lognigrad.lm),3)

(Intercept)      ldist lgradient
         -4.961
                 1.147   0.466

Thus, with gradient held constant, the prediction is that time will
increase at the rate of dist1.147. This makes good intuitive sense.

    We pause to look more closely at the model that has been ﬁtted.
Does log(time) really depend linearly on the terms ldist and
log(lclimb)? The function termplot() gives a good graphical
indication (Figure 8.10).
162 learning and exploring r

                                                                                q  1.5                                                 Figure 8.10: The vertical scales
                                                                                                                                       in both “term plot” panel show
1.5                                                                                                                                    log(time), centered to a mean of
                                                                                                                                       zero. The partial residuals in the left
1.0Partial for ldist                q                                              1.0                                                 panel are for ldist, while those in the
                                                      Partial for lgradientq                                                           right panel are for lgradient, i.e.,
                                                                                                                                       log(climb/dist). Smooth curves
 0.5                          q                                                    0.5                                        q        (dashes) have been passed through the
 0.0                                                                                                                                q  points.
−0.5                    q  q                                                                                            q qq
                      qq
                                                                                                          qq     q      qq
                qqqq                                                               0.0                    q          q
              qqqqq                                                                              qqqqqqq
                                                                                              q               q

                                                                                            q

      q qq q                                                                       −0.5

      1.0 1.5 2.0 2.5                  3.0                                                       5.4 5.6 5.8 6.0 6.2 6.4

                   ldist                                                                                  lgradient

## Plot the terms in the model
termplot(lognigrad.lm , col.term="gray", partial=TRUE,

                col.res="black", smooth=panel.smooth)

    The vertical scales show changes in ltime, about the mean of
ltime. The lines show the estimated eﬀect of each explanatory
variable when the other variable is held at its mean value. The lines,
which are the contributions of the individual linear terms (“eﬀects”)
in this model, are shown in gray so that they do not obtrude unduly.
The dashed curves, which are smooth curves that are passed through
the residuals, are the primary features of interest.

    Notice that, in the plot for ldist, the smooth dashed line does
not quite track the ﬁtted line; there is a small but noticeable in-
dication of curvature that can be very adequately modeled with a
quadratic curve. Note also that until we have modeled eﬀectively the
clear trend that seems evident in this plot, there is not much point in
worrying about possible outliers.

  8.7 Variable Selection – Stepwise and Other                                                                                          The points made here can have highly
                                                                                                                                       damaging implications for analyses
   Common variable selection methods include various versions of for-                                                                  where it is important to obtain inter-
   ward and backward selection, and exhaustive (best subset) selection.                                                                pretable regression coeﬃcients. In
   These or other variable selection methods invalidate standard model                                                                 such analyses, changes to the initial
   assumptions, which assume a single known model.                                                                                     model should be limited to simpliﬁca-
                                                                                                                                       tions that do not modify the model in
       There are (at least) three inter-related issues for the use of results                                                          any substantial manner. Following the
   from a variable selection process:                                                                                                  selection process, check coeﬃcients
                                                                                                                                       against those from the full model. Any
(i) Use of standard theoretically based model ﬁtting procedures,                                                                       large changes should ring a warning
     applied to the model that results from the model selection process,                                                               bell.
     will lead to a spuriously small error variance, and to a spuriously
     large model F-statistic. Coeﬃcient estimates will be inﬂated, have                                                                  The implications for prediction are,
     spuriously small standard errors, and spuriously large t-statistics.                                                              relatively, much more manageable.
     (Or to put the point another way, it is inappropriate to refer such                                                               The key requirement is to use indepen-
     statistics to a standard t-distribution.)                                                                                         dent data to show that any selective
                                                                                                                                       process has genuinely improved model
(ii) Commonly used stepwise and other model selection processes are                                                                    performance.
     likely to over-ﬁt, i.e., the model will not be optimal for prediction
     on test data that are distinct from the data used to train the model.
                                                                                 regression with linear terms and factors 163

      The selected model may in some instances be inferior, judged
      by this standard, to a model that uses all candidate explanatory
      variables. (There are alternative ways to use all variables. Should
      low order interactions be included? Should some variables be
      transformed?)

(iii) Coeﬃcients may change, even to changing in sign, depending on
      what else is included in the model. With a diﬀerent total set of
      coeﬃcients, one has a diﬀerent model, and the coeﬃcients that
      are common across the two models may be accordingly diﬀerent.
      (They will be exactly the same only in the unusual case where
      “variables” are uncorrelated.) There is a risk that variable selec-
      tion will remove variables on whose values (individually, or in
      total eﬀect) other coeﬃcient estimates should be conditioned. This
      adds uncertainty beyond what arises from sampling variation.

       Note that these points apply to pretty much any type of regres-
   sion modelling, including generalized linear models and classiﬁca-
   tion (discriminant) models.

       Where observations are independent, items (i) and (ii) can be
   addressed, for any given selection process, by splitting the data into
   training, validation and test sets. Training data select the model,
   with the validation data used to tune the selection process. Model
   performance is then checked against the test data.

       Somewhat casual approaches to the use of backward (or other)
   stepwise selection may be a holdover from hand calculator days,
   or from times when computers grunted somewhat to handle even
   modest sized calculations. This may be one of the murky dark alleys
   of statistical practice, where magic incantations and hope too often
   prevail over hard evidence.

       Appropriate forms of variable selection process can however be
   eﬀective in cases where a few only of the coeﬃcients have predic-
   tive power, and the relevant t-statistics are large – too large to be
   substantially inﬂated by selection eﬀects.

8.7.1 Use of simulation to check out selection eﬀects:                 6 See also Section 6.5, pp. 197-198, in:
                                                                       Maindonald, JH and Braun, WJ, 2010.
The function bestsetNoise() (DAAG) can be used to experiment           Data Analysis and Graphics Using R
with the behaviour of various variable selection techniques with data  – An Example-Based Approach, 3rd
that is purely noise. For example, try:6                               edition. Cambridge University Press.

bestsetNoise(m=100, n=40, nvmax=3)
bestsetNoise(m=100, n=40, method="backward",

                       nvmax=3)

The analyses will typically yield a model that appears to have highly
(but spuriously) statistically signiﬁcant explanatory power, with one
or more coeﬃcients that appear (again spuriously) signiﬁcant at a
level of around p=0.01 or less.
  164 learning and exploring r                                                                                  Select 'best' 3 variables

 The extent of selection eﬀects – a detailed simulation: As above,                                   0.75 q
 datasets of random normal data were created, always with 100 obser-
 vations and with the number of variables varying between 3 and 50.       p−values for t−statistics     0.5       qq
 For three variables, there was no selection, while in other cases the
 “best” three variables were selected, by exhaustive search.                                          0.25   qq
                                                                                                             qqqqqqqq qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq
     Figure 8.11 plots the p-values for the 3 variables that were se-                                 0.05
 lected against the total number of variables. The ﬁtted line estimates                               0.01                                  q
 the median p-value. Code is:                                                                        0.001

  library(DAAG)                                                                          0 10 20 30 40 50
  library(quantreg)
  library(splines)                                                                 # of variables from which to select
  set.seed(37) # Use to reproduce graph shown
  bsnVaryNvar(m=100, nvar=3:50, nvmax=3, fg="gray")                       Figure 8.11: p-values, versus number
                                                                          of variables available for selection,
     When all 3 variables are taken, the p-values are expected to         when the “best” 3 variables were
 average 0.5. Notice that, for selection of the best 3 variables out      selected by exhaustive search. The
 of 10, the median p-value has reduced to about 0.1.                      ﬁtted line estimates the median p-
                                                                          value.
 Examples from the literature The paper cited in the sidenote7 gives
 several examples of published spurious results, all for the use of       7 Ambroise, C and McLachlan, GJ,
 discriminant methods with microarray data. The same eﬀects can           2001. Selection bias in gene extraction
 arise from model tuning.                                                 on the basis of microarray gene-
                                                                          expression data. Proceedings of the
 8.7.2 Variable and model selection – strategies                          National Academy of Sciences USA,
                                                                          99: 6562-6566.
 Several alternative mechanisms are available that can yield reason-
 able standard errors and other accuracy measures. These include:         If however the coeﬃcients are not
                                                                          themselves very meaningful, what is
a) Fit the model to test data that have played no part in the model       the point?
    selection and tuning process;

b) use cross-validation. The model selection and ﬁtting process must
    be repeated at each cross-validation fold;

c) repeat the whole analysis, selection and all, with repeated boot-
    strap samples, using variation between the diﬀerent sample results
    to assess the accuracy of one or other statistic;

d) simulate, including all selection and tuning steps, from the ﬁtted
    model.

 For b) and c), there will be somewhat diﬀerent selections for each
 diﬀerent cross-validation fold or bootstrap sample. This is itself
 instructive.

     One possibility, following stepwise or other selection, is that the
  p-values of one or more coeﬃcients may be so small that they are
 very unlikely to be an artefact of the selection process. In general, a
 simulation will be required, in order to be sure.

Model selection more generally:                                           Use of test data that are separate from
                                                                          data used to develop the model deals
More generally, the model may be chosen from a wide class of              with this issue.
                                                                             regression with linear terms and factors 165

models. Again, model selection biases standard errors to be smaller
than indicated by the theory, and coeﬃcients and t-statistics larger.
The resulting anti-conservative estimates of standard errors and other
statistics should be regarded sceptically.

    A further issue, which use of separate test data does not address,
is that none of the models on oﬀer is likely to be strictly correct.
Mis-speciﬁcation of the ﬁxed eﬀects will bias model estimates, at the
same time inﬂating the error variance or variances. Thus it will to an
extent work in the opposite direction to selection eﬀects.

8.8 1970 cost for US electricity producers

There is a wide range of possible choices of model terms. Figure
8.12 shows the scatterplot matrices of the variables. Code is:

library(car)
library(Ecdat)
data(Electricity)
spm(Electricity , smooth=TRUE, reg.line=NA,

       col=adjustcolor(rep("black",3), alpha.f=0.3))

                      0 40000 100000              0.05 0.15 0.25               0.1 0.2 0.3 0.4                  0.3 0.5 0.7

           cost                                                                                                                                 600
                                                                                                                                                400
                                                                                                                                                200
                                                                                                                                                0

120000                q
100000                              pl

 80000
 60000
 40000
 20000

        0

                                                                                                                12000

                                                                                                                10000 cost: total cost

                                                                                                                8000
                                                                                                                6000

                                                                                                                            q: total output

0.30                                              sl                                                                                                           pl: wage rate
0.25                                                            pk
0.20                                                                          sk                                                                               sl: cost share, labor
0.15
0.10
0.05

                                                                                                                90                                             pk: capital price index
                                                                                                                80

                                                                                                                70

                                                                                                                60

                                                                                                                50 sk: cost share, capital
                                                                                                                40

                                                                                                                30

                                                                                                                                                               pf: fuel price

0.4                                                                                                                                                            sf: cost share, fuel
0.3
0.2                                                                                             pf 50
0.1                                                                                                                                                        40
                                                                                                                                                           30
0.8                                                                                                                                                        20
0.7                                                                                                                                                        10
0.6
0.5                                                                                                           sf
0.4
0.3                                   6000 10000                  30 50 70 90                   10 20 30 40 50

       0 200 400 600

                                                                                                                                                               Figure 8.12: Scatterplot matrix,
                                                                                                                                                               for the variables in the data set
                                                                                                                                                               Electricity, in the Ecdat pack-
                                                                                                                                                               age. Density plots are shown in the
                                                                                                                                                               diagonal.
    166 learning and exploring r                                              Removal of terms with p > 0.15 or
                                                                              p > 0.2 rather than p > 0.05 greatly
   8.8.1 Model ﬁtting strategy                                                reduces the risk that estimates of other
                                                                              parameters, and their standard errors,
   The analysis will start by checking for clearly desirable transfor-        will change in ways that aﬀect the
   mations to variables. Then, for obtaining a model whose whose              interpretation of model results.
   parameters are as far as possible interpretable, a strategy is:
                                                                                        log(cost)  2 4 6 8 10 12
 (i) Start with a model that includes all plausible main eﬀects (vari-                                                                                             6
      ables and factors). Ensure that the model is parameterised in a         12                                                                                   4
      way that makes parameters of interest as far as possible inter-         10                                                                                   2
      pretable (e.g., in Subsection 3.4 above, work with distance and                                                                                              0
      gradient, not distance and climb)                                        8                                                                                   −2
                                                                               6
(ii) [21pt] Model simpliﬁcation may be acceptable, if it does not              4                          log(q)
      change the parameters of interest to an extent that aﬀects inter-        2
      pretation. The common p > 0.05 is too severe; try instead p =
      0.15 (remove terms with p > 0.15) or p = 0.20.                                −2 0 2 4 6

(iii) Variables and/or factors that have no detectable main eﬀect are in      Figure 8.13: Scatterplot matrix for
      general unlikely to show up in interactions. Limiting attention to      the logarithms of the variables cost
      the main eﬀects that were identiﬁed in (ii) above, we then compare      and q. Density plots are shown in the
      a model which has only main eﬀects with a model that inludes all        diagonal.
      2-way interactions. Then, using p 0.15 or p 0.2 as the cutoﬀ,
      remove interaction terms that seem unimportant, and check that
      there are no changes of consequence in terms that remain.

(iv) In principle, the process may be repeated for order 3 interactions.

 (v) Use the function add1() to check for individual highly signiﬁcant
      terms that should be included. For this purpose, we might set
      p = 0.01 or perhaps p = 0.001.

   The strategy is to be cautious (hence the cutoﬀ of p = 0.2) in re-
   moving terms, whether main eﬀects or ﬁrst order interactions. In a
   ﬁnal check whether there is a case for adding in terms that had been
   omitted, we include a term only if it is highly statistically signiﬁcant.
   This limits the scope for selection eﬀects.

   Distributions of variables

   The distributions of cost and q are highly skew. The relationship
   between these two variables is also very close to linear. We might try
   taking logarithms of both these variables.

       Figure 8.13 examines the scatterplot matrix for the logarithms of
   the variables cost and q. Code is:

    varlabs <- c("log(cost)", "log(q)")
    spm(log(Electricity[,1:2]), var.labels=varlabs,

            smooth=TRUE, reg.line=NA,
            col=adjustcolor(rep("black",3), alpha.f=0.5))

   We start with a model that has main eﬀects only:

    elec.lm <- lm(log(cost) ~ log(q)+pl+sl+pk+sk+pf+sf,
                              data=Electricity)
                                                                                                                                                                                                                                                                                                                                                                                           regression with linear terms and factors 167

Partial for log(q)             qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq                q                                                                                                                                                                                                                                                                                                                                                                Figure 8.14: Termplot summary for
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       the model that has been ﬁtted to the
                     2                                                                                                   Partial for pl   2                                                                                                qq   Partial for sl   2                                                                                                     Partial for pk   2                                                                                              Electricity dataset.
                     0                                                                                                                    0 qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq                        0 qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq qqqqqqqqqqq q                   0 qqqqqqqqq qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq
                    −2
                    −4                                                                                                                   −2                                                                                                                     −2                                                                                                                     −2

                        q qqq                                                                                                            −4                                                                                                                     −4                                                                                                                     −4

                    −6                                                                                                                   −6                                                                                                                     −6                                                                                                                     −6
                                                                                                                                                6000                                                                                                               0.05                                                                                                                   30
                        −6 −4 −2 0 2                                                                                                                   10000                                                                                                                0.15 0.25                                                                                                         50 70  90

                               log(q)                                                                                                                 pl                                                                                                                       sl                                                                                                                pk

Partial for sk      2                                                                                                    Partial for pf   2                                                                                                     Partial for sf   2

                    0   qq  qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq  qq      q  q                   0        qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq qq                         qq   qq qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq qq
                                                                                                               qq
                                                                                                                q                               q                                                                                                                0

                    −2                                                                                                                   −2                                                                                                                     −2

                    −4                                                                                                                   −4                                                                                                                     −4

                    −6         0.2 0.3                                                                         0.4                       −6                                                                                                                     −6          0.5 0.7
                        0.1                                                                                                                                                                                                                                            0.3
                                   sk                                                                                                         10 20 30 40 50                                                                                                                 sf

                                                                                                                                                      pf

    Now examine the termplot (Figure 8.14): Code is:

termplot(elec.lm, partial=T, smooth=panel.smooth ,
                transform.x=TRUE)

Notice that in the partial plot for q, the dashed curve that is ﬁtted
to the residuals closely tracks the ﬁtted eﬀect (linear on a scale of
log(q). This conﬁrms the use of log(q), rather than q, as explana-
tory variable.

    Now examine the model output:

round(coef(summary(elec.lm)),5)

                                                                                                               Estimate Std. Error t value Pr(>|t|)

(Intercept) -5.41328 0.70720 -7.6545 0.00000

log(q)                                                                                                                0.89250 0.00994 89.8326 0.00000

pl -0.00002 0.00001 -1.9341 0.05499

sl 2.48020 0.74898 3.3114 0.00116

pk 0.00083 0.00127 0.6562 0.51272

sk 0.62272 0.70837 0.8791 0.38076

pf 0.03042 0.00228 13.3338 0.00000

sf -0.30965 0.69091 -0.4482 0.65467

    The p-values suggest that pk, sk, and sf can be dropped from
the model. Omission of these terms makes only minor diﬀerences to
the coeﬃcients of terms that remain.

elec2.lm <- lm(log(cost) ~ log(q)+pl+sl+pf,
                           data=Electricity)

round(coef(summary(elec2.lm)),5)

                                                                                                               Estimate Std. Error t value Pr(>|t|)

(Intercept) -5.28641 0.13701 -38.585 0.00000

log(q)                                                                                                                0.88901 0.00986 90.167 0.00000

pl -0.00002 0.00001 -2.072 0.03994

sl 2.69722 0.32464 8.308 0.00000

pf 0.02659 0.00191 13.934 0.00000

   Now check whether interaction terms should be included:

elec2x.lm <- lm(log(cost) ~ (log(q)+pl+sl+pf)^2,
                             data=Electricity)

anova(elec2.lm, elec2x.lm)

Analysis of Variance Table
168 learning and exploring r

Model 1: log(cost) ∼ log(q) + pl + sl + pf
Model 2: log(cost) ∼ (log(q) + pl + sl + pf)∧2

    Res.Df RSS Df Sum of Sq F Pr(>F)

1 153 5.00

2 147 2.81 6           2.19 19.1 2.3e-16

The case for including ﬁrst order interactions seems strong. The
coeﬃcients and SEs are:

round(coef(summary(elec2x.lm)),5)

         Estimate Std. Error t value Pr(>|t|)

(Intercept) -3.63931 0.67803 -5.3675 0.00000

log(q)      0.71481 0.05455 13.1039 0.00000

pl -0.00031 0.00007 -4.2508 0.00004

sl 6.06389 1.64592 3.6842 0.00032

pf 0.01592 0.01499 1.0623 0.28985

log(q):pl 0.00003 0.00001 6.2902 0.00000

log(q):sl -0.67829 0.10229 -6.6308 0.00000

log(q):pf 0.00080 0.00113 0.7133 0.47680

pl:sl       0.00007 0.00018 0.4144 0.67916

pl:pf       0.00000 0.00000 0.1421 0.88722

sl:pf       0.01680 0.03092 0.5432 0.58780

This suggests omitting the terms pf, and all interactions except
log(q):pl and log(q):sl. We check that omission of these terms
makes little diﬀerence to the terms that remain:

elec2xx.lm <- lm(log(cost) ~ log(q)+pl+sl+pf+
                               log (q ): pl + log (q ): sl ,
                               data=Electricity)

round(coef(summary(elec2xx.lm)),5)

         Estimate Std. Error t value Pr(>|t|)

(Intercept) -4.12003 0.33312 -12.368            0

log(q)      0.74902 0.03852 19.445              0

pl       -0.00029 0.00004 -7.755                0

sl          7.29642 0.70758 10.312              0

pf          0.02611 0.00145 18.017              0

log(q):pl 0.00003 0.00000 7.657                 0

log(q):sl -0.68969 0.09435 -7.310               0

    Now check whether there is a strong case for adding in any fur-
ther individual terms:

add1(elec2xx.lm , scope=~(log(q)+pl+sl+pk+sk+pf+sf)^2, test="F")

Single term additions

Model:

log(cost) ∼ log(q) + pl + sl + pf + log(q):pl + log(q):sl

         Df Sum of Sq RSS AIC F value Pr(>F)

<none >                2.83 -622

pk 1 0.0041 2.82 -620 0.22 0.64

sk 1 0.0329 2.79 -621 1.76 0.19

sf 1 0.0294 2.80 -621 1.58 0.21

log(q):pf 1 0.0040 2.82 -620 0.21 0.64

pl:sl    1 0.0060 2.82 -620 0.32 0.57
pl:pf                                                                 regression with linear terms and factors 169
sl:pf
           1 0.0004 2.83 -620 0.02 0.88
           1 0.0016 2.83 -620 0.09 0.77

8.9 An introduction to logistic regression                              The dataset bronchit may alterna-
                                                                        tively be found in the SMIR package.
The data that will be used for illustration are from the data frame
bronchit in the DAAGviz package. The following loads packages
that will be needed:

library(DAAGviz, quietly=TRUE)
library(KernSmooth , quietly=TRUE)

    Figure 8.15 shows two plots – one of poll (pollution level)
against cig (number of cigarettes per day), and the other of poll
against log(poll). In each case, points are identiﬁed as with or
without bronchitis.

           70 Non−sufferer Sufferer           70                        Non−sufferer          Sufferer

Pollution  65                                 65 0.01                                   0.02
                                                                                      0.03
           60                                                 0.02

           55                                 60

                 0 5 10 15 20 25 30                               0.03

                        # cigarettes per day  55

                                                                                                               0.01

                                                         0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5

                                                             log(# cigarettes per day + 1)

## Panel A                                                              Figure 8.15: Panel A plots poll
colr <- adjustcolor(c("red","blue"), alpha=0.5)                         (pollution level) against cig (number
plot(poll ~ cig,                                                        of cigarettes per day). In panel B, the
                                                                        x-scale shows the logarithm of the
         xlab="# cigarettes per day", ylab="Pollution",                 number of cigarettes per day.
         col=colr[r+1], pch=(3:2)[r+1], data=bronchit ,
         ylim=ylim)
legend(x="topright",

            legend=c("Non-sufferer","Sufferer"),
            ncol=2, pch=c(3,2), col=c(2,4), cex=0.8)

## Panel B
plot(poll ~ log(cig+1), col=c(2,4)[r+1], pch=(3:2)[r+1],

         xlab="log(# cigarettes per day + 1)", ylab="", data=bronchit , ylim=ylim)
xy1 <- with(subset(bronchit , r==0), cbind(x=log(cig+1), y=poll))
xy2 <- with(subset(bronchit , r==1), cbind(x=log(cig+1), y=poll))
est1 <- bkde2D(xy1, bandwidth=c(0.7, 3))
est2 <- bkde2D(xy2, bandwidth=c(0.7, 3))
170 learning and exploring r

lev <- pretty(c(est1$fhat, est2$fhat),4)
contour(est1$x1, est1$x2, est1$fhat, levels=lev, add=TRUE, col=2)
contour(est2$x1, est2$x2, est2$fhat, levels=lev, add=TRUE, col=4, lty=2)
legend(x="topright", legend=c("Non-sufferer","Sufferer"), ncol=2, lty=1:2,

    The logarithmic transformation spreads the points out in the x-
direction, in a manner that is much more helpful for prediction than
the untransformed values in panel A. The contours for non-suﬀerer
and suﬀerer in panel B have a similar shape. The separation between
non-suﬀerer and suﬀerer is stronger in the x-direction than in the y-
direction. As one indication of this, the contours at a density of 0.02
overlap slightly in the x-direction, but strongly in the y-direction.

Logistic regression calculations

Figure 8.15 made it clear that the distribution of number of cigarettes
had a strong positive skew. Thus, we might ﬁt the model:

cig2.glm <- glm(r ~ log(cig+1) + poll, family=binomial , data=bronchit)
summary(cig2.glm)

Call:
glm(formula = r ∼ log(cig + 1) + poll, family = binomial , data = bronchit)

Deviance Residuals:             Max
     Min 1Q Median 3Q        2.653

-1.611 -0.586 -0.362 -0.239

Coefficients:

               Estimate Std. Error z value Pr(>|z|)

(Intercept) -10.7877   2.9885 -3.61 0.00031

log(cig + 1) 1.2882    0.2208 5.83 5.4e-09

poll           0.1306  0.0494 2.64 0.00817

(Dispersion parameter for binomial family taken to be 1)

       Null deviance: 221.78 on 211 degrees of freedom
Residual deviance: 168.76 on 209 degrees of freedom
AIC: 174.8

Number of Fisher Scoring iterations: 5

    Termplots (Figure 8.16) provide a useful summary of the contri-
butions of the covariates. For binary (0/1) data such as here, includ-
ing the data values provides no visually useful information. Code
is:

termplot(cig2.glm)

 8.10 Exercises

1. Exercise 3 in Section 2.6.2 involved reading data into a data frame
    molclock1. Plot AvRate against Myr. Fit a regression line (with
                                                                        regression with linear terms and factors 171

 3                                                                       3                        Figure 8.16: The panels show the
                                                                                                  contributions that the respective terms
 2                                                                       2                        make to the ﬁtted values (logit of
                                                                                                  probability of bronchitis), when the
 1                                                                       1                        other term is held constant.

 0                                                                       0

−1                                                                      −1
      0 5 10 15 20 25 30                                                              55 60 65

                    cig                                                                     poll
Partial for log(cig + 1)
                                                      Partial for poll

    intercept, or without intercept?), and add the regression line to the
    plot. What interpretation can be placed upon the regression slope?

2. Attach the DAAG package. Type help(elasticband) to see
    the help page for the data frame elasticband. Plot distance
    against stretch. Regress distance against stretch and ex-
    plain how to interpret the coeﬃcient.

3. Repeat the calculations in Section 8.6, now examining the regres-
    sion of time on dist and climb. Does this regression adequately
    model the data. Comment on the results.

4.(a) Investigate the pairwise relationships between variables in the
       data frame oddbooks (DAAG).

 (b) Fit the models

        volume <- apply(oddbooks[, 1:3], 1, prod)
        area <- apply(oddbooks[, 2:3], 1, prod)
        lob1.lm <- lm(log(weight) ~ log(volume), data=oddbooks)
        lob2.lm <- lm(log(weight) ~ log(thick)+log(area), data=oddbooks)
        lob3.lm <- lm(log(weight) ~ log(thick)+log(breadth)+log(height),

                                  data=oddbooks)

       Comment on what you ﬁnd, i.e., comment both on the estimates
       and on the standard errors.

 (c) Can weight be completely explained as a function of volume?
       Is there another relevant variable?

5. Repeat the calculations in Section 3.4, now with the dataset
    hills2000 (DAAG). Do any of the points stand out as outliers?
    Use predict(), with newdata = hills200, to obtain predic-
    tions from the hills2000 model for the nihills data. Compare
    with the predictions from the nihills model.
172 learning and exploring r
9
∗A Miscellany of Models & Methods
174 learning and exploring r

    This chapter is a tour through models and methods that are
straightforward to ﬁt using R. Some of these lend themselves to
relatively automated use. There is some limited attention to the traps
that can catch users who are unwary, or who have ventured too easily
into areas that call for some greater level of statistical sophistication
than their training and experience has given them.

    In each case, comments with be introductory and brief. Firstly,
there are brief comments on the ﬁtting of smooth curves. The second
and third topics highlight speciﬁc types of departure from the iid
(independently and identically distributed) assumption.

9.1 Regression with Fitted Smooth Curves

Load the DAAG package:

library(DAAG)

Commentary on Smoothing Methods                                            Smoothness is controlled by the
                                                                           width of the smoothing window. The
Two types of methods will be described – those where the user con-         default is f=2/3 for lowess(), or
trols the choice of smoothing parameter, and statistical learning type     span=0.75 for loess(). For other
methods where the amount of smoothing is chosen automatically:             functions that rely on this methodol-
                                                                           ogy, check the relevant help page.
• The ﬁrst class of methods rely on the user to make a suitable
   choice of a parameter that controls the smoothness. The default         1 Strong assumptions are required,
   choice is often a good ﬁrst approximation. Note here:                   notably that observations are inde-
                                                                           pendent. Normality assumptions are,
  – Smoothing using a “locally weighted regression smoother”.              often, less critical.
      Functions that use this approach include lowess(), loess(),
      loess.smooth(), and scatter.smooth().

  – Use of a regression spline basis in a linear model. Here the
      smoothness is usually controlled by the choice of number of
      spline basis terms.

• A second class of methods use a “statistical learning” approach
   in which the amount of smoothing is chosen automatically. The
   approach of the mgcv package extends and adapts the regression
   spline approach.1 The methodology generalizes to handle more
   general types of outcome variables, including proportions and
   counts. These extensions will not be further discussed here.

9.1.1 Locally weighted scatterplot smoothers

Locally weighted scatterplot smoothers pass a window across the
data, centering the window in turn at each of a number points that
are equally spaced through the data. The smooth at an x-value where
the window has been centred is the predicted value from a line (or
sometimes a quadratic or other curve) that is ﬁtted to values that
lie within the window. A weighted ﬁt is used, so that neighbouring
                                                                                          a miscellany of models & methods 175

points get greater weight than points out towards the edge of the                                       10000     q
                                                                                                         8000
window.                                                                                                  6000        q
                                                                                                         4000               q
Figure 9.1 shows a smooth that has been ﬁtted using the lowess                                           2000
                                                                                                               qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq q
(locally weighted scatterplot smoothing) methodology. The default

choice of with of smoothing window (a fraction                               f  =  2  of the total  ohms                                                                                                                           q
                                                                                   3
range of x) gives a result that, for these data, looks about right. The                                        q     q         q qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq
                                                                                                                       q
curve does however trend slightly upwards at the upper end of its

range. A monotonic response might seem more appropriate.

The code used to plot the graph is:                                                                                                                                                                                                   q

                                                                                                                                                                                                                                q

## Plot points                                                                                                    10 20 30 40 50 60
plot(ohms ~ juice, data=fruitohms , fg="gray")
## Add smooth curve, using default                                                                                             juice
## smoothing window
with(fruitohms ,                                                                                    Figure 9.1: Resistance in ohms is

         lines(lowess(ohms ~ juice), col="gray", lwd=2))                                            plotted against apparent juice content.

                                                                                                    A smooth curve (in gray) has been

    A more sophisticated approach uses the gam() function in the                                    added, using the lowess smoother.
mgcv package. This allows automatic determination of the amount
of smoothing, providing the assumption of independent residu-                                       The width of the smoothing window
als from the curve is reasonable. We now demonstrate the use of a
GAM model for a two-dimensional smooth.                                                             was the default fraction                                                                                                       f  =  2  of the
                                                                                                                                                                                                                                         3

                                                                                                    range of values of the x-variable.

9.1.2 Contours from 2-dimensional Smooths

Data are the amplitudes of responses to a visual stimulus, for each
of 20 individuals, at diﬀerent regions of the left eye. We use the
function gam() to create smooth surfaces, for males and females
separately. Figure 9.2 then uses the function vis.gam() to plot
heatmaps that show the contours:

           A: Response amplitudes, Males                                                B: Response amplitudes, Females

         4                                                                            4
                                                                                      2
                                                                   12.5

         2
         y                                                               12
                                 14 14.5
                                                     13 13.5

                                                                                y

                                                                                                                                                            13 13.5
                                                                                                                                                                                            12 12.5
                                                                                                                                                                                                             11.5
                                                                                                                                                                                                                            11
         00

         −2 −2

         −4                                                                           −4

             −4 −2  0                2                                   4                          −4 −2         0            2                                                                                                         4

                    x                                                                                             x

    The GAM ﬁt will as far as possible use the smooth surface to                                    Figure 9.2: Estimated contours of
account for the pattern of variation across the eye, with residuals                                 left eye responses to visual stimulae,
from the surface treated as random normal noise.                                                    projected onto the plane.
176 learning and exploring r

## Code
library(DAAGviz)
library(mgcv)
eyeAmpM.gam <- gam(amp ~ s(x,y), data=subset(eyeAmp , Sex=="m"))
eyeAmpF.gam <- gam(amp ~ s(x,y), data=subset(eyeAmp , Sex=="f"))
lims <- range(c(predict(eyeAmpF.gam), predict(eyeAmpM.gam)))
vis.gam(eyeAmpM.gam , plot.type='contour', color="cm", zlim=lims, main="")
mtext(side=3, line=0.5, adj=0, "A: Response amplitudes , Males")
vis.gam(eyeAmpF.gam , plot.type='contour', color="cm", zlim=lims, main="")
mtext(side=3, line=0.5, adj=0, "B: Response amplitudes , Females")

                                                                           ORAN                       q qqq
                                                                           WEAN
9.2 Hierarchical Multi-level Models                                        DBAN                qq     qq
                                                                           OVAN
                                                                                               q qqq
                                                                            LFAN
Models with Non-iid Errors – Multi-level models:                            TEAN          q    q qq
 Error Term Errors do not have to be (and often are not) iid               WLAN
                                                                           NSAN        q       qq

                                                                                       qq q q

Multi-level  Multi-level models are a (relatively) simple type of                 q q qq
models       non-iid model, implemented using lme() (nlme) or
             lmer() (lme4 package).                                               qqq  q
             Such models allow diﬀerent errors of prediction,
             depending on the intended prediction.                                234567

    Figure 9.3 shows corn yield data from the Caribbean island of                     Harvest weight of corn
Antigua, as in the second column (“Yields”) of Table 9.1. Each value
is for one package of land. The code for the ﬁgure is:                     Figure 9.3: Yields from 4 packages
                                                                           of land on each of eight sites on the
# ant111b is in DAAG                                                       Caribbean island of Antigua. Data are
Site <- with(ant111b , reorder(site, harvwt ,                              a summarized version of a subset of
                                                                           data given in Andrews and Herzberg
                                                      FUN=mean))           1985, pp.3˜39-353.
stripplot(Site ~ harvwt, data=ant111b , fg="gray",

                  scales=list(tck=0.5),
                  xlab="Harvest weight of corn")

Location     Yields               Location            Residuals from       Table 9.1: The leftmost column has
                                  eﬀect                location mean       harvest weights (harvwt), for the
DBAN      5.16, 4.8, 5.07, 4.51                  0.28, −0.08, 0.18, −0.38  packages of land in each location, for
 LFAN     2.93, 4.77, 4.33, 4.8          +0.59    −1.28, 0.56, 0.12, 0.59  the Antiguan corn data. Each of these
NSAN      1.73, 3.17, 1.49, 1.97          −0.08  −0.36, 1.08, −0.6, −0.12  harvest weights can be expressed as
ORAN      6.79, 7.37, 6.44, 7.07          −2.2   −0.13, 0.45, −0.48, 0.15  the sum of the overall mean (= 4.29),
                                  (4.29) +2.62                             location eﬀect (third column), and
OVAN      3.25, 4.28, 5.56, 6.24         +0.54   −1.58, −0.56, 0.73, 1.4   residual from the location eﬀect (ﬁnal
 TEAN     2.65, 3.19, 2.79, 3.51          −1.26  −0.39, 0.15, −0.25, 0.48  column).
WEAN      5.04, 4.6, 6.34, 6.12          +1.23   −0.49, −0.93, 0.81, 0.6
WLAN      2.02, 2.66, 3.16, 3.52          −1.45  −0.82, −0.18, 0.32, 0.68

    Depending on the use that will be made of the results, it may be

essential to correctly model the structure of the random part of the
model. In comparing yields from diﬀerent packages of land, there
are two sorts of comparison. Packages on the same location should
be relatively similar, while packages on diﬀerent locations should
be relatively more diﬀerent, as Figure 9.3 suggests. A prediction for
                                                                      a miscellany of models & methods 177

a new package at one of the existing locations is likely to be more     Because of the balance the corn yield
accurate than a prediction for a totally new location.                  data, an analysis of variance that
                                                                        speciﬁes a formal Error term is an
    Multi-level models are able to account for such diﬀerences in       alternative to the ﬁtting of a multi-
predictive accuracy. For the Antiguan corn yield data, it is necessary  level model.
to account both for variation within sites and for variation between
sites. The R packages nlme and lme4 are both able to handle such
data.

9.3 Regular Time Series in R

Models with Non-iid Errors – Time Series:

Time       Points that are close together in time commonly show

sequential a (usually, +ve) correlation. R’s acf() and arima()

           functions are powerful tools for use with time series.

    Any process that evolves in time is likely to have a sequential
correlation structure. The value at the current time is likely to be
correlated with the value at the previous time, and perhaps with
values several time points back. The discussion that follows will
explore implications for data analysis.

9.3.1 Example – the Lake Erie data

Level (m)  174.5                                                        Figure 9.4: Lake Erie levels (m).
           174.0
           173.5                                                        Erie <- greatLakes[,"Erie"]
                                                                        plot(Erie, xlab="", fg="gray",
                        1920
                                                                                 ylab="Level (m)")

                              1940  1960   1980  2000

    The data series Erie, giving levels of Lake Erie from 1918 to       2 Data are from http://www.lre.
                                                                        usace.army.mil/greatlakes/
2009, will be used as an example from which to start the discus-        hh/greatlakeswaterlevels/
sion.2 The series is available in the DAAG package, as the column       historicdata/
                                                                        greatlakeshydrographs/
Erie in the multivariate time series object greatLakes.

    Figure 9.4 shows a plot of the series.
178 learning and exploring r

          173.5              174.0        174.5                                     175.0                                                                                    173.5              174.0                    174.5         175.0  Figure 9.5: Panel A plots Lake Erie
                                                                                                                                                                                                                                              levels vs levels at lags 1, 2 and 3 re-
                                                                             q                                                      q                                                                           q                             spectively. Panel B shows a consistent
                                                                                                                                                                                                                                              pattern of decreasing autocorrelation
                                       q qq q                                       q                                        q                              qq                                      q           q              q              at successive lags.
                                                                                                                                                          q                                     q                qq         q qq
                                                                                                                                 q                                                                                    q                       ## Panel A
                                                                                                                                                                 qq                                                    q                      lag.plot(Erie, lags=3,
                                                                          q                                                         q                                                                                qq
                                          q                                                                                              q                                                                                                                    do.lines =FALSE ,
174.5                               q       qqq q                               qq                                        q         qq q                             q                                                                 q                      layout=c(1,3), fg="gray",
174.0
173.5                               qqqqqqqqqqqqqqqqqqqqqqqqqqqqq  qqqqq        q                                         q      qqqqqqqqqqqqqqqqqqqqqqq   qqqq       175.0                q             q         qq   qq  qq     q          ## Panel B
                                         q                                                                                q                               q                                               q            q    qqq               acf(Erie, main="", fg="gray")
                                                                                                       q                                                  q      qq                     q    q       q                            q
                    q                qq q                                                                q                                                                           q       q             q          q      q   q
                                 q                                                                                     q                                   q                                                    q qqq
                          q  q                                                                                                                                                          q                    q                      q
                     qq      q qq                                                                       q q qq                                                                        q               qq         qq
     Erie           q q qqq   qq                                                                          q qq                                                                    q             q    qq q       qq
                             q                                                                                                                                                    q               q
                           ACF                                                                                 q qq          q q qq                                                               q         q
                                                                                                       q q qq
                                                      Erieqqqq                                    q                          qq  q                                                   qq                q               q
                                                                                                        Erieqqq              q                                                       q qq qq                q
                 q                                                                                                                     q
                                                                                                                                                                                                       q qq
                       q                                                                          q qq                                                                              q q qq
       q         q qq    qq                                                                q                                 qq                                              qqq
                                                                                               q
                    qq q                                                                                q qq                                                                                                       q
                                                                                                                                                                                                qq

                       q                                                                                               q                                                                    q
                                                                                                                      q                                                                     q
              q                                                                                   q                                                                                        q
          q

                             lag 1                                                         173.5                          lag 2           174.5                                                 lag 3
                                                                                                                          174.0

                                           1.0                                                         5 10                                                                  15
                                           0.8
                                           0.6                                                                       Lag
                                           0.4
                                           0.2
                                           0.0
                                          −0.2

                                                     0

    The plots in Figure 9.5 are a good starting point for investigation                                                                                                                                                                       An autoregressive model is a special
of the correlation structure. Panel A shows lag plots, up to a lag of                                                                                                                                                                         case of an Autoregressive Moving
3. Panel B shows estimates of the successive correlations, in this                                                                                                                                                                            Average (ARMA) model.
context are called autocorrelations.
                                                                                                                                                                                                                                              Smoothing terms can be ﬁtted to the
    There is a strong correlation at lag 1, a strong but weaker correla-                                                                                                                                                                      pattern apparent in serially correlated
tion at lag 2, and a noticeable correlation at lag 3. Such a correlation                                                                                                                                                                      data, leaving errors that are pretty
pattern is typical of an autoregressive process where most of the                                                                                                                                                                             much uncorrelated. Such a pattern is
sequential dependence can be explained as a ﬂow-on eﬀect from a                                                                                                                                                                               in general, however, unrepeatable. It
dependence at lag 1.                                                                                                                                                                                                                          gives little clue of what may happen
                                                                                                                                                                                                                                              the future. A re-run of the process
    If possible, the analyst will want to ﬁnd covariates that largely or                                                                                                                                                                      (a new realization) will produce a
partly explain that dependence. At best, such covariates will com-                                                                                                                                                                            diﬀerent series, albeit one that shows
monly explain part only of the dependence, and there will remain                                                                                                                                                                              the same general tendency to move up
dependence that requires to be modeled.                                                                                                                                                                                                       and down.

    In an autoregressive time series, an independent error component,
or “innovation” is associated with each time point. For an order p
autoregressive time series, the error for any time point is obtained
by taking the innovation for that time point, and adding a linear
combination of the innovations at the p previous time points. (For
the present time series, initial indications are that p = 1 might
capture most of the correlation structure.)

9.3.2 Patterns that are repeatable

What sorts of patterns may then be repeatable? Indications that a
pattern may be repeatable include:

• A straight line trend is a good starting point for some limited
   extrapolation. But think: Is it plausible that the trend will continue
   more than a short distance into the future?
                                                                                        a miscellany of models & methods 179

• There may be a clear pattern of seasonal change, e.g., with seasons
   of the year or (as happens with airborne pollution) with days of
   the week. If yearly seasonal changes persist over diﬀerent years,
   or weekly day-of-the-week changes persist over diﬀerent weeks,
   these eﬀects can perhaps be extrapolated with some reasonable
   conﬁdence.

• There is a regression relationship that seems likely to explain
   future as well as current data.

    An ideal would be to ﬁnd a covariate or covariates than can
largely explain the year to year changes. For this series, this does
not seem a possibility. In the absence of identiﬁable direct cause for
the year to year changes, a reasonable recourse is to look for a cor-
relation structure that largely accounts for the pattern of the year to
year change.

Smooth, with automatic choice of smoothing parameter

                                                                               q                          Figure 9.6: GAM smoothing term,
                                                                                                          ﬁtted to the Lake Erie Data. Most of
Height of lake  174.5                                q            qq          q         q                 the autocorrelation structure has been
                174.0                                               qq          q  qq                     removed, leaving residuals that are
                173.5                                                                                     very nearly independent.
                                                                 q      q qq
                                                                                                          ## Code
                                   qq       qqqqqqqqqqqqq qq        q    qqqq     qqqqqqqq             q  library(mgcv)
                       q                                           qqq  q                      qqqqqq     df <- data.frame(
                                                                  q
                       qq                                        q                          q                height=as.vector(Erie),
                                                                                                             year=time(Erie))
                       qq q                       q     qq q                                qqq           obj <- gam(height ~ s(year),

                             qq        qqqqq                                                                                  data=df)
                           q     qqq                                                                      plot(obj, fg="gray",
                             qq             q qq
                                                                                                                   shift=mean(df$height),
                                                              q                                                    residuals=TRUE, pch=1,
                                                                                                                   xlab="",
                                         q                                                                         ylab="Height of lake")
                                        q
                                       q

                       1920                 1940        1960            1980                2000

    While smoothing methods that asssume independent errors can
be used, as in Figure 9.6, to ﬁt a curve to such data, the curve will
not be repeatable. Figure 9.6 does not separate systematic eﬀects
from eﬀects due to processes that evolve in time. Figure 9.6 uses
the abilities of the mgcv package, assuming independently and iden-
tically distributed data (hence, no serial correlation!) to make an
automatic choice of the smoothing parameter. As the curve is condi-
tional on a particular realization of the process that generated it, its
usefulness is limited.

    The pointwise conﬁdence limits are similarly conditioned, rel-
evant perhaps for interpolalation given this particular realization.
All that is repeatable, given another realization, is the process that
generated the curve, not the curve itself.
180 learning and exploring r

9.3.3 Fitting and use of an autoregressive model

There are several diﬀerent types of time series models that may be
used to model the correlatios structure, allowing realistic estimates
of the lake level a short time ahead, with realistic conﬁdence bounds
around those estimates. For the Lake Erie data, an autoregressive
correlation structure does a good job of accounting for the pattern of
change around a mean that stays constant.

    Figure 9.5 suggested that a correlation between each year and
the previous year accounted for the main part of the autocorrela-
tion structure in Figure 9.4. An AR1 model (autoregressive with a
correlation at lag 1 only), which we now ﬁt, formalizes this.

ar(Erie, order.max=1)

Call:
ar(x = Erie, order.max = 1)

Coefficients:
       1

0.851

Order selected 1 sigma∧2 estimated as 0.0291

The one coeﬃcient that is now given is the lag 1 correlation,
equalling 0.851.

Sim 1   4                       Sim 2   4                       Sim 3   4                       Figure 9.7: The plots are from re-
        2                               2                               2                       peated simulations of an AR1 process
Sim 4   0       50 100 150 200  Sim 5   0       50 100 150 200  Sim 6   0       50 100 150 200  with a lag 1 correlation of 0.85.
       −2                              −2                              −2                       Smooth curves, assuming independent
       −4                x             −4                x             −4                x      errors, have been ﬁtted.
                                                                       −6
             0  50 100 150 200               0  50 100 150 200                  50 100 150 200  for (i in 1:6){
                                                                             0                  ysim <-
        8                x              4                x                               x
        6                               2                               6                          arima.sim(list(ar=0.85),
        4                               0                               4                                            n=200)
        2                              −2                               2
        0                              −4                               0                       df <- data.frame(x=1:200,
       −2                                                              −2                                                      y=ysim)
       −4                                    0
                                                                             0                  df.gam <- gam(y ~ s(x),
             0                                                                                                           data=df)

    Figure 9.7 then investigates how repeated simulations of this                               plot(df.gam, fg="gray",
process, with a lag 1 correlation of 0.0.85, compare with Figure 9.4.                                    ylab=paste("Sim", i),
This illustrates the point that a GAM smooth will extract, from an                                       residuals=TRUE)
autoregressive process with mean 0, a pattern that is not repeatable
when the process is re-run.                                                                     }

    The curves are diﬀerent on each occasion. For generalization
beyond the particular realization that generated them, they serve no
useful purpose.

    Once an autoregressive model has been ﬁtted, the function
forecast() in the forecast package can be used to predict future
levels, albeit with very wide conﬁdence bounds. For this, it is neces-
sary to reﬁt the model using the function arima(). An arima model
                                                                                                                                                                                                                                     a miscellany of models & methods 181

with order (1,0,0) is an autoregressive model with order 1.

Lake level (m)  174.5                                                                                                                                                                                                                    Figure 9.8: Predictions, 15 years
                                                                                                                                                                                                                                         into the future, of lake levels (m).
                174.0                                                                                                                                                                                                                    The shaded areas give 80% and 95%
                                                                                                                                                                                                                                         conﬁdence bounds.
                173.5                    1940                                                                     1960  1980     2000     2020
                             1920                                                                                                                                                                                                        erie.ar <- arima(Erie,
                                                                                                                                                                                                                                                               order=c(1,0,0))

                                                                                                                                                                                                                                         library(forecast)
                                                                                                                                                                                                                                         fc <- forecast(erie.ar ,

                                                                                                                                                                                                                                                                    h=15)
                                                                                                                                                                                                                                         plot(fc, main="", fg="gray",

                                                                                                                                                                                                                                                  ylab="Lake level (m)")
                                                                                                                                                                                                                                            # 15 time points ahead

    This brief excursion into a simple form of time series model is
intended only to indicate the limitations of automatic smooths. and
to give a sense of the broad style of time series modeling. The list of
references at the end of the chapter has details of several books on
time series.

9.3.4 Regression with time series errors

Figure 9.9 ﬁts annual rainfall, in the Murray-Darling basin of Aus-
tralia, as a sum of smooth functions of Year and SOI. Figure 3.9
shows the estimated contributions of the two model terms.

## Code
mdbRain.gam <- gam(mdbRain ~ s(Year) + s(SOI),

                                  data=bomregions)
plot(mdbRain.gam , residuals=TRUE, se=2, fg="gray",

         pch=1, select=1, cex=1.35, ylab="Partial , Year")
mtext(side=3, line=0.75, "A: Effect of Year", adj=0)
plot(mdbRain.gam , residuals=TRUE, se=2, fg="gray",

         pch=1, select=2, cex=1.35, ylab="Partial , SOI")
mtext(side=3, line=0.75, "B: Effect of SOI", adj=0)

                A: Effect of Year                                                                                       B: Effect of SOI                                                                                                 Figure 9.9: Estimated contributions of
                                                                                                                                                                                                                                         model terms to mdbRain, in a GAM
300                                                                                                                                                                   qq                                                                 model that adds smooth terms in Year
                                                                                                                        300                                                                                                              and Rain. The dashed curves show
                                                                                                                                                                                                                                         pointwise 2-SE limits, for the ﬁtted
                                   qq                                                                                                                      q                                                                             curve.
                                                                                                                                 qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq
200 q qq q                                                                                                               200     q                                                                                                    q
Partial, Year                                                                                                            100                                                                                                         20
                                                   Partial, SOI
 100            qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq             0q
     0                                                                                                                  −100
                                                                                                                        −200
−100

−200 q                 qq q              q        q
                              q

                1900   1940                 1980                                                                        −20 −10        0  10

                                   Year                                                                                          SOI
182 learning and exploring r

    The left panel indicates a consistent pattern of increase of rainfall
with succeeding years, given an adjustment for the eﬀect of SOI. Er-
rors from the ﬁtted model are consistent with the independent errors
assumption. The model has then identiﬁed a pattern of increase of
rainfall with time, given SOI, that does seem real. It is necessary to
warn against reliance on extrapolation more than a few time points
into the future. While the result is consistent with expected eﬀects
from global warming, those eﬀects are known to play out very diﬀer-
ently in diﬀerent parts of the globe.

Investigation of the residual error structure

Sequential correlation structures are often eﬀective, with data col-
lected over time, for use in modeling departure from iid errors.
Where there is such structure structure in the data, the methodol-
ogy will if possible use a smooth curve to account for it.

    The residuals can be checked to determine whether the ﬁtted
curve has removed most of the correlation structure in the data.
Figure 9.10 shows the autocorrelation function of the residuals, fol-
lowed by autocorrelation functions for several series of independent
random normal numbers. Apart from the weakly attested correlation
at a lag of 12 years, which is a commonplace of weather data, the
pattern of sequential correlation is not much diﬀerent from what can
be expected in a sequence of independent random normal numbers.

MDB series   1.0                             Sim 1   1.0                             Sim 2   1.0
             0.8                                     0.8                                     0.8
             0.6        Series rnorm(n)  20          0.6        Series rnorm(n)  20          0.6        Series rnorm(n)  20
             0.4                                     0.4                                     0.4
             0.2           5 10 15                   0.2           5 10 15                   0.2           5 10 15
             0.0                                     0.0                                     0.0
            −0.2                  Lag               −0.2                  Lag               −0.2                  Lag

Sim 3                0                       Sim 4           0                       Sim 5           0

             1.0        5 10 15 20                   1.0        5 10 15 20                   1.0        5 10 15 20
             0.8                                     0.8                                     0.8
             0.6                                     0.6                                     0.6
             0.4                                     0.4                                     0.4
             0.2                                     0.2                                     0.2
             0.0                                     0.0                                     0.0
            −0.2                                    −0.2                                    −0.2

                     0                                       0                                       0

    Code is:                                                                                Figure 9.10: The top left panel shows
                                                                                            the autocorrelations of the residu-
mdbRain.gam <- gam(mdbRain ~ s(Year) + s(SOI),                                              als from the model mdbRain.gam.
                                  data=bomregions)                                          The ﬁve remaining panels are the
                                                                                            equivalent plots for sequences of
n <- dim(bomregions)[1]                                                                     independent random normal numbers.
acf(resid(mdbRain.gam), ylab="MDB series")
for(i in 1:5)acf(rnorm(n), ylab=paste("Sim",i),

                              fg="gray", col="gray40")
                                                       a miscellany of models & methods 183

9.3.5 ∗Box-Jenkins ARIMA Time Series Modeling                                         Models that are closely analagous to
                                                                                      ARIMA models had been used earlier
From the perspective of the Box-Jenkins ARIMA (Autoregressive                         in control theory. ARIMA models are
Integrated Moving Average) approach to time series models, au-                        feedback systems!
toregressive models are a special case. Many standard types of time
series can be modeled very satisfactorily as ARIMA processes.

Exercise

The simulations in Figure 9.7 show a pattern of variation that seems
not too diﬀerent from that in the actual series. Modeling of the pro-
cess as an ARMA or ARIMA process (i.e., allow for a moving av-
erage term) may do even better. Use the auto.arima() function in
the forecast package to ﬁt an ARIMA process:

9.3.6 Count Data with Poisson ErrorsEstimated rate per week                           Data are a time series. Serious acci-
                                                                                      dents are however suﬃcently uncom-
Data is for aircraft accidents, from the website http://www.                          mon that occasions where events occur
planecrashinfo.com/. The 1920 ﬁle has accidents starting from                         together, or where one event changes
1908. The full data are in the dataset gamclass::airAccs. Such                        the probability of the next event, seem
issues as there are with sequential correlation can be ameliorated by                 likely to be uncommon.
working with weekly, rather than daily, counts.

          2.0

          1.5

          1.0

          0.5

                         2006  2007  2008  2009  2010  2011                           2012  2013  2014
                                                                                      Figure 9.11: Estimated number of

    Figure 9.11 shows a ﬁtted smooth curve, with pointwise conﬁ-                      events (aircraft crashes) per week,
dence bounds, from a GAM smoothing model that was ﬁtted to the
weekly counts.                                                                        versus time. The yearly tick marks are

    The function gamclass::eventCounts() was used to create                           for January 1 of the stated year.
weekly counts of accidents from January 1, 2006:                                      See Section 4.3.9 for further details on

                                                                                      the function eventCounts().

## Code
airAccs <- gamclass::airAccs
fromDate <- as.Date("2006-01-01")
dfWeek06 <- gamclass::eventCounts(airAccs , dateCol="Date",

                                                             from=fromDate ,
                                                          by="1 week", prefix="num")
dfWeek06$day <- julian(dfWeek06$Date, origin=fromDate)

Code for Figure 9.11 is then.

## Code
library(mgcv)
year <- seq(from=fromDate , to=max(dfWeek06$Date), by="1 year")
at6 <- julian(seq(from=fromDate , to=max(dfWeek06$Date), by="6 months"), origin=fromDate)
184 learning and exploring r

atyear <- julian(year, origin=fromDate)
dfWeek06.gam <- gam(num~s(day, k=200), data=dfWeek06 , family=quasipoisson)
avWk <- mean(predict(dfWeek06.gam))
plot(dfWeek06.gam , xaxt="n", shift=avWk, trans=exp, rug=FALSE,

         xlab="", ylab="Estimated rate per week", fg="gray")
axis(1, at=atyear , labels=format(year, "%Y"), lwd=0, lwd.ticks=1)
abline(h=0.5+(1:4)*0.5, v=at6, col="gray", lty=3, lwd=0.5)

    The argument ‘k’ to the function s() that sets up the smooth
controls the temporal resolution. A large k allows, if the data seem
to justify it, for ﬁne resolution. A penalty is applied that discrimi-
nates against curves that are overly “wiggly”.

    Not all count data is suitable for modeling assuming a Pois-
son type rare event distribution. For example, the dataset http:
//maths-people.anu.edu.au/~johnm/stats-issues/data/
hurric2014.csv has details, for the years 1950-2012, of US deaths
from Atlantic hurricanes. For any given hurricane, deaths are not at
all independent rare events.

9.4 Classiﬁcation                                                         For the special case g = 2, logistic
                                                                          regression models are an alternative.
Classiﬁcation models have the character of regression models where
the outcome is categorical, one of g classes. The fgl (forensic glass)    3 Limited further details and refer-
dataset that will be used as an example has measurements of each on       ences are provided in Maindonald and
nine physical properties, for 214 samples of glass that are classiﬁed     Braun: Data Analysis and Graphics
into g = 6 diﬀerent glass types.                                          Using R, Cambridge University Press,
                                                                          3rd edn 2010.
    This section will describe a very limited range of available ap-
proaches. For details on how and why these methods work, it will be
necessary to look elsewhere.3

    Linear discriminant analysis (LDA), and quadratic discriminant
analysis (QDA) which slightly generalizes LDA, both use linear
functions of the explanatory variables in the modeling of the proba-
bilities of group membership. These methods will be contrasted with
the strongly non-parameteric approaches of tree-based classiﬁcation
and of random forests.

Linear and quadratic discriminant analysis                                4 Quadratic discriminant analysis is
                                                                          an adaptation of linear discriminant
The functions that will be used are lda() and qda(), from the             analysis to handle data where the
MASS package. The function lda() implements linear discriminant           variance-covariance matrices of
analysis, while qda() implements quadratic discriminant analysis.4        the diﬀerent classes are markedly
                                                                          diﬀerent.
library(MASS, quietly=TRUE)

    Results from use of lda() lead very naturally to useful and
informative plots. Where lda() gives results that are a sub-optimal
ﬁt to the data, the plots may hint at what type of alternative method
may be preferable. They may identify subgroups of the orginal g
groups, and/or identify points that seem misclassiﬁed.

    An attractive feature of lda() is that the discriminant rule that is
obtained has a natural representation r-dimensional space. Providing
a miscellany of models & methods 185

that there is suﬃcient independent covariate data, r = g − 1. The       5 This is based on a spectral decompo-
analysis leads5 to r sets of scores, where each set of scores explains  sition of the model matrix.

a successively smaller (or at least, not larger) proportion of the sum  With three groups, two dimensions
of squares of diﬀerences of group means from the overall mean.          will account for all the variation. A
The r sets of scores can be examined using a pairs plot. With larger    scatterplot is then a geometrically
                                                                        complete representation of what the
numbers of groups, it will often happen that two or at most three       analysis has achieved.

dimensions will account for most of the variation.

Use of lda() to analyse the forensic glass data

As noted above, the data frame fgl has 10 measured physical char-
acteristics for each of 214 glass fragments that are classiﬁed into
6 diﬀerent types. First, ﬁt a linear discriminant analysis, and use
leave-one-out cross-validation to check the accuracy, thus:

fglCV.lda <- lda(type ~ ., data=fgl, CV=TRUE)
tab <- table(fgl$type, fglCV.lda$class)
## Confusion matrix
print(round(apply(tab, 1, function(x)x/sum(x)),

                      digits=3))

                WinF WinNF Veh Con Tabl Head
   WinF 0.729 0.237 0.647 0.000 0.111 0.034
   WinNF 0.229 0.684 0.353 0.462 0.222 0.069
   Veh 0.043 0.000 0.000 0.000 0.000 0.000
   Con 0.000 0.039 0.000 0.462 0.000 0.034
   Tabl 0.000 0.026 0.000 0.000 0.556 0.000
   Head 0.000 0.013 0.000 0.077 0.111 0.862

    The function confusion() (DAAG) makes it easy to get all the
above output. Enter:

library(DAAG)
confusion(fgl$type, fglCV.lda$class)

Two-dimensional representation                                          Observe that most of the discrimina-
                                                                        tory power is in the ﬁrst two dimen-
Now ﬁt the model with CV=FALSE, which is the default:                   sions.

fgl.lda <- lda(type ~ ., data=fgl)

The ﬁnal three lines of the output, obtained by entering fgl.lda at
the command line, are:

Proportion of trace:
   LD1 LD2 LD3 LD4 LD5

0.815 0.117 0.041 0.016 0.011

The numbers show the successive proportions of a measure of the
variation that are accounted for by projections onto spaces with
successively larger numbers of dimensions.

    Figure 9.12 shows the two-dimensional representation.
186 learning and exploring r

                4                                                          Figure 9.12: Visual representation
                                                                           of scores from a linear discriminant
                2                                                          analysis, for the forensic glass data. A
                                                                           six-dimensional pattern of separation
Discriminant 2  0                                 WinF                     between the categories has been
                                                  WinNF                    collapsed to two dimensions. Some
                −2                                Veh                      categories may therefore be better
                                                  Con                      distinguished than is evident from this
                                                  Tabl                     ﬁgure.
                                                  Head
                −4

                −6

                −8       −2 0 2 4              6
                     −4
                               Discriminant 1

 library(lattice)                                                          See Figure 9.15 in Subsection 9.5.1,
 scores <- predict(fgl.lda)$x                                              for an example of the type of low-
 xyplot(scores[,2] ~ scores[,1], groups=fgl$type,                          dimensional representation that is
                                                                           possible for results from a randdom
             xlab="Discriminant 1",                                        forest classiﬁcation.
             ylab="Discriminant 2",
             aspect=1, scales=list(tck=0.4),                               More technical points, as they apply
             auto.key=list(space="right"),                                 to the use of R’s function glm() for
                                                                           logistic regression, are:
    Additionally, it may be useful to examine the plot of the third
versus the second discriminant. Better still, use the abilites of the rgl  - The ﬁtting procedure minimizes
package to examine a 3-dimensional dynamic representation. With               the deviance. This equals 2 (
most other methods, a low-dimensional representation does not arise           loglikelihood for ﬁtted model,
so directly from the analysis.                                                minus the loglikelihood for the
                                                                              ‘saturated’ model). The ‘saturated
Two groups – comparison with logistic regression                              model has predicted values equal to
                                                                              observed values.
The approach is to model the probability of class membership given
the covariates, using the same logistic ﬁxed part of the model as          - Standard errors and Wald statistics
for linear and quadratic discriminant analysis. With π equal to the           (roughly comparable to t-statistics)
probability of membership in the second class, the model assumes              are given for parameter estimates.
that                                                                          These depend on approximations
                                                                              that may fail if predicted propor-
                            log(π/(1 − π) = β x                               tions are close to 0 or 1 and/or the
                                                                              sample size is small.
where β is a vector of coeﬃcients that are to be estimated, and x is a
vector of covariate values.

    A logistic regression model is a special case of a Generalized
Linear Model (GLM), as implemented by R’s function glm(). There
is no provision to adjust predictions to take account of prior proba-
bilities, though this can be done as an add-on to the analysis. Other
points of diﬀerence from linear discriminant analysis are:

• Inference is conditional on the observed covariate values. A model
   for the probability of covariate values x given the class c, as for
   linear discriminant analysis, is not required. (Linear discriminant
                                                                                        a miscellany of models & methods 187

   analysis assumes a multivariate normal distribution assumptions
   for x, given the class c. In practice, results seem relatively robust
   against failure of this assumption.)

• The logit model uses the link function f (π) = log(π/(1 − π).
   Other choices of link function are available. Where there are suf-
   ﬁcient data to check whether one of these other links may be more
   appropriate, this should be checked. Or there may be previous
   experience with comparable data that suggests use of a link other
   than the logit.

• Observations can be given prior weights.

9.5 Tree-based methods and random forests                              The dataset bronchit may alterna-
                                                                       tively be found in the SMIR package.
On a scale in which highly parametric methods lie at one end and       Here r=1 denotes bronchitis, while
highly non-parametric methods at the other, linear discriminant        r=0 indicates that bronchitis is absent.
methods lie at the parametric end, and tree-based methods and ran-
dom forests at the non-parametric extreme. An attraction of tree-      With a factor (rfac) as outcome,
based methods and random forests is that model choice can be pretty    method="class" is the default.
much automated.                                                        Setting method="class", to make
                                                                       it quite clear that we are using a
    We begin by loading the rpart package:                             splitting rule that is appropriate to a
                                                                       categorical (rather than continuous)
library(rpart)                                                         outcome, is good practice.

    For the calculations that follow, data are columns in the data
frame bronchit, in the DAAGviz package.

head(bronchit , 3)

   r cig poll
1 0 5.15 67.1
2 0 6.75 64.4
3 0 0.00 65.9

In place of the variable r with values 0 and 1, we use a factor with
levels abs and pres. Labels that appear in the output are then more
meaningful.

## Now make the outcome variable a factor
bronchit <-

   within(bronchit ,
                rfac <- factor(r, labels=c("abs","pres")))

    The following ﬁts a tree-based model:

set.seed(47) # Reproduce tree shown
b.rpart <- rpart(rfac ~ cig+poll, data=bronchit ,

                               method="class")

    The “complexity” paremeter cp, by default set to 0.01, controls
how far splitting continues. In practice, it is usual to set cp small
enough that splitting continues further than is optimal, then pruning
the tree back. Cross-validation based accuracies are calculated at
each split, and can be used to determine the optimal depth of tree.
188 learning and exploring r                                                                                 cig< 4.375
                                                                                                                    |
Details will not be given at this point, as the interest is in trees as a
lead-in to random forests. For random forests, the depth of the splits                                                       cig< 6.3
in individual trees is not of great consequence — it is not important                               abs
for individual trees to be optimal.
                                                                                                                                         poll< 58.35
    Figure 9.13 is a visual summary of results from the tree-based                                               abs poll>=55.65
classiﬁcation, designed to predict the probability that a miner will
have bronchitis. Where the condition at a node is satisﬁed, the left                                                                                   pres
branch is taken. Thus, at the initial node, cig<4.385 takes the                                                              abs pres
branch to the left. In general (no random number seed), the tree may
be diﬀerent for each diﬀerent run of the calculations.                                          Figure 9.13: Decision tree for predict-
                                                                                                ing whether a miner has bronchitis.
    Tree-based classiﬁcation proceeds by constructing a sequence of                             Code for Figure 9.13 is:
decision steps. At each node, the split is used that best separates the
data into two groups. Here (Figure 9.13) tree-based regression does                             plot(b.rpart)
unusually well (CV accuracy = 97.2%), perhaps because it is well                                text(b.rpart, xpd=TRUE)
designed to reproduce a simple form of sequential decision rule that
has been used by the clinicians.                                                                Figure 9.14: Each tree is for a diﬀerent
                                                                                                bootstrap sample of observations. The
    How is ‘best’ deﬁned? Splits are chosen so that the Gini index of                           ﬁnal classiﬁcation is determined by
“impurity” is minimized. Other criteria are possible, but this is how                           a random vote over all trees. Where
randomForest() constructs its trees.                                                            there are > 2 explanatory variables
                                                                                                (but not here) a diﬀerent random
9.5.1 Random forests                                                                            sample of variables is typically used
                                                                                                for each diﬀerent split. The ﬁnal
library(randomForest , quietly=TRUE)                                                            classiﬁcation is determined by a
                                                                                                random vote over all trees.
    Figure 9.14 shows trees that have been ﬁtted to diﬀerent boot-
strap samples of the bronchitis data. Typically 500 or more trees are
ﬁtted, without a stopping rule. Individual trees are likely to overﬁt.
As each tree is for a diﬀerent random sample of the data, there is no
overﬁtting overall.

     cig< 3.3                cig< 6.3                cig< 6.3                cig< 6.4

             |                       |                       |                       |

           poll< 53.95             poll< 57.65             poll< 53.95              poll< 58.5
abs                     abs                     abs                     abs

          abs pres                abs pres                abs pres                abs pres
                                cig< 6.3              cig< 6.725             cig< 3.3
     cig< 6.4
                                        |                       |                    |
             |
                        abs pres                abs pres                           poll< 54.55
           poll< 58.35      cig< 3.45               cig< 3.45           abs
abs
                                     |                       |                    abs pres
          abs pres                                                            cig< 6.725
                                    cig< 7.325             poll< 61.45
    cig< 4.625          abs                     abs                                     |

             |                    abs pres                abs pres      abs pres

           poll< 54.55
abs

          abs pres

    For each bootstrap sample, predictions are made for the obser-
vations that were not included – i.e., for the out-of-bag data. Com-
parison with the actual group assignments then provides an unbiased
estimate of accuracy.

    For the bronchit data, here is the randomForest() result.
                                                                     a miscellany of models & methods 189

(bronchit.rf <- randomForest(rfac ~ cig+poll,
                                                    data=bronchit))

Call:
 randomForest(formula = rfac ∼ cig + poll, data = bronchit)
                           Type of random forest: classification
                                      Number of trees: 500

No. of variables tried at each split: 1

OOB estimate of error rate: 23.58%                                                                   abs q                         pres

Confusion matrix:

abs pres class.error                                                                                 qqqqqqqqqqqqqqqqqqq

abs 145 21         0.1265                                                        0.2                                          q    qqqqqqqqqqqqqqqqqqqqqqqqqq
                                                                                 0.0
                                                                                −0.2                                      qq
                                                                                −0.4
pres 29 17         0.6304

                                                                        Axis 2                                                     q   q                       qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq
                                                                                                                                    q  q

The accuracy is much better than the rpart() accuracy. The ran-                       qqqqqqqqqqqqq
dom forest methodology will often improve, sometimes quite dra-
matically, on tree-based classiﬁcation.                                               qqqqq                               qqqqqqq
                                                                                      qqq q
    Figure 9.15 is a visual summary of the random forest classiﬁ-                                    q
cation result. The proportion of trees in which any pair of points
appear together at the same node may be used as a measure of the                                     qq qqqqqqqqqqqq
“proximity” between that pair of points. Then, subtracting proxim-
ity from one to obtain a measure of distance, an ordination method                    −0.4 −0.2 0.0 0.2                                                        0.4
is used to ﬁnd an approximates representation of those points in a
low-dimensional space.                                                                             Axis 1

    There is a tuning parameter mtry which controls the number          Figure 9.15: The plot is designed
of randomly chosen variables considered for each tree. This is not      to represent, in two dimensions, the
too much of an issue for the present data, where there are only two     random forest result. It aims to reﬂect
explanatory variables.                                                  probabilities of group membership
                                                                        given by the analysis. It is not derived
    Code for Figure 9.15 is:                                            by a ’scaling’ of the feature space.

parset <- simpleTheme(pch=1:2)
bronchit.rf <- randomForest(rfac ~ cig+poll,

                                                   proximity =TRUE ,
                                                   data=bronchit)
points <- cmdscale(1-bronchit.rf$proximity)
xyplot(points[,2] ~ points[,1],
            groups = bronchit $rfac ,
            xlab="Axis 1", ylab="Axis 2",
            par.settings=parset , aspect=1,
            auto.key=list(columns=2))

A random forest ﬁt to the forensic glass data                           6 The default is to set mtry to the
                                                                        square root of the total number of
The algorithm can be used in a highly automatic manner. Here then       variables, rounded up to an integral
is the random forest analysis for the forensic glass data, leaving the  value.
tuning parameter (mtry) at its default6:

(fgl.rf <- randomForest(type ~ ., data=fgl))

Call:
  randomForest(formula = type ∼ ., data = fgl)
190 learning and exploring r

                           Type of random forest: classification
                                      Number of trees: 500

No. of variables tried at each split: 3

OOB estimate of error rate: 20.56%

Confusion matrix:

WinF WinNF Veh Con Tabl Head class.error

WinF 63  610 0 0              0.1000

WinNF 10 59 1 3 2 1           0.2237

Veh 8 3 6 0 0 0 0.6471

Con 0 3 0 9 0 1 0.3077

Tabl 0 2 0 0 7 0              0.2222

Head 1 2 0 0 0 26             0.1034

This improves substantially on the linear discriminant result. This
may happen because the explanatory variables have eﬀects that are
non-linear on a logit scale. The more likely reason is that there are
interaction eﬀects, perhaps of a relatively complicated kind, for
which the lda() analysis has not accounted.

    The predictive accuracy might be further improved by varying
the tuning parameter mtry from its default. See help(tuneRF)
for details of the function tuneRF() that is designed to assist in
ﬁndind=g the optimum choice of mtry.

9.6 ∗Ordination                                                          An ordination might alternatively be
                                                                         based on road travel times, or on air
From Australian road travel distances between cities and larger          travel times.
towns, can we derive a plausible “map”, or “ordination”, showing
the relative locations? The resulting “map” would give a better indi-    The ordination methods described here
cation than a geographical map of the road travel eﬀort involved in      are all versions of multi-dimensional
getting from one place to another.                                       scaling (MDS). If distances are not
                                                                         already given, a ﬁrst tasl is to calculate
    Genomic data provides another example. Various methods are           ‘distances’ between points. Or if
available for calculating genomic “distances ” between, e.g., diﬀer-     similarities are given, they must be
ent insect species. The distance measures are based on evolutionary      ﬁrst be transformed into ‘distances’.
models that aim to give distances between pairs of species that are a
monotone function of the time since the two species separated.           7 Principal components analysis cir-
                                                                         cumvents the calculation of distances,
    Ordination is a generic name for methods for providing a low-        for the commonly used Euclidean
dimensional view of points in multi-dimensional space, such that         distance measure. See below.
“similar” objects are near each other and dissimilar objects are sep-
arated. The plot(s) from an ordination in 2 or 3 dimensions may
provide useful visual clues on clusters in the data and/or on outliers.

    One standard type of problem starts from a matrix X of n obser-
vations by p variables, then seeking a low-dimensional represen-
tation. A ﬁrst step is then to calculate distances between observa-
tions.7 The hope is that a major part of the information content in
the p variables, as it relates to the separation between observations,
can be pretty much summarized in a small number of constructed
variables.

    There is typically no good model, equivalent to the evolutionary
models used by molecular biologists, that can be used to motivate
                                                                                       a miscellany of models & methods 191

distance calculations. There is then a large element of arbritariness
in the distance measure used. Results may depend strongly on the
distance measure used. Unless measurements are comparable (e.g.,
relative growth, as measured perhaps on a logarithmic scale, for
diﬀerent body measurements), it is usually desirable to calculate dis-
tances from standardized variable values. This is done by subtracting
the mean and dividing by the standard deviation.

    If data can be separated into known classes that should be re-
ﬂected in any ordination, then the scores from classiﬁcation using
lda() may be a good basis for an ordination. Plots in 2 or perhaps 3
dimensions may then reveal additional classes and/or identify points
that may be misclassiﬁed and/or are in some sense outliers. They
give an indication of the eﬀectiveness of the discrimination method
in choosing the boundaries between classes.

    Figure 9.15 demonstrated the use of “proximities” that are avail-
able from randomForest() as measures of the closeness of any pair
of points. These were then turned into rough distance measures that
then formed the basis for an ordination. With Support Vector Ma-
chines, distance measures can be derived from the ’decision values’
and used for ordination.

9.6.1 Distance measures                                                8 This says that a straight line is the
                                                                       shortest distance between two points!
Euclidean distances
                                                                       9 More generally, they can be arbitrar-
Treating the rows of X (n by p) as points in a p-dimensional space,    ily transformed before calculating the
the squared Euclidean distance di2j between points i and j is          di j.

                                                  p

                           di2j = (xik − x jk)2

                                              k=1

The distances satisfy the triangle inequality8

                               di j ≤ dik + dk j

    The columns may be weighted diﬀerently.9 Use of an un-
weighted measure with all columns scaled to a standard deviation
of one is equivalent to working with the unscaled columns and cal-
culating di2j as

                                               p

                         di2j = wi j(xik − x jk)2

                                           k=1

where wi j = (sis j)−1 is the inverse of the product of the standard
deviations for columns i and j.

    Where all elements of a column are positive, use of the logarith-
mic transformation is common. A logarithmic scale makes sense for
biological morphometric data, and for other data with similar char-
acteristics. For morphometric data, the eﬀect is to focus attention
on relative changes in the various body proportions, rather than on
absolute magnitudes.
192 learning and exploring r                                               For the Manhattan distance:

Non-Euclidean distance measures                                                                     p

Euclidean distance is one of many possible choices of distance mea-                  di j = | xik − x jk |
sures, still satisfying the triangle inequality. As an example of a
non-Euclidean measure, consider the Manhattan distance. The Man-                                 k=1
hattan distance is the shortest distance for a journey that always pro-
ceeds along one of the co-ordinate axes. In Manhattan in New York,         10 The function daisy() in the clus-
streets are laid out in a rectangular grid. This is then (with k = 2) the  ter package oﬀers a wider choice,
walking distance along one or other street. For other choices, see the     including distance measures for factor
help page for the function dist().10                                       or ordinal data. Its argument stand
                                                                           causes prior standardization of data.
From distances to a representation in Euclidean space
                                                                           11 This is true whether ot not the
Irrespective of the method of calculation of the distance measure,         triangle inequality is satisﬁed.
ordination methods yield a representation in Euclidean space. It
is always possible to ﬁnd a conﬁguration X in Euclidean space in
which the “distances” are approximated, perhaps rather poorly.11
It will become apparent in the course of seeking the conﬁguration
whether an exact embedding (matrix X) is possible, and how ac-
curate this embedding is. The representation is not unique. The
matrices X and XP, where P is an orthonormal matrix, give exactly
the same distances.

The connection with principal components                                   We assume that none of the columns
                                                                           can be written as a linear combination
Let X be an n by p matrix that is used for the calculation of Eu-          of other columns.
clidean distances, after any transformations and/or weighting. Then
metric p-dimensional ordination, applied to Euclidean distances be-
tween the rows of X, yields a representation in p-dimensional space
that is formally equivalent to that derived from the use of principal
components. The function cmdscale() yields, by a diﬀerent set of
matrix manipulations, what is essentially a principal components
decomposition. Principal components circumvents the calculation of
distances.

Semi-metric and non-metric scaling                                         The assumption of a Euclidean dis-
                                                                           tance scale is a convenient starting
Semi-metric and non-metric methods all start from “distances”,             point for calculations. An ordina-
but allow greater ﬂexibility in their use to create an ordination. The     tion that preserves relative rather
aim is to represent the “distances” in some speciﬁed number of             than absolute distances can often be
dimensions, typically two dimensions. As described here, a ﬁrst step       more appropriate. Additionally, small
is to treat the distances as Euclidean, and determine a conﬁguration       distances may be measured more
in Euclidean space. These Euclidean distances are then used as a           accurately than large distances.
starting point for a representation in which the requirement that
these are Euclidean distances, all determined with equal accuracy,
is relaxed. The methods that will be noted here are Sammon scaling
and Kruskal’s non-metric multidimensional scaling.
                                                                          a miscellany of models & methods 193

Example – Australian road distances                                                  q

The distance matrix that will be used is in the matrix audists, from              Perth
the DAAG package. Figure 9.16 is from the use of classical multi-
dimensional scaling, as implemented in the function cmdscale():                                                                         Melbourne
An alternative way to add names of cities or other labels is to use
identify() to add labels interactively, thus:                                                                                           q q q Canberra
                                                                                                                                                       q
    Code is:                                                                                                                            Adelaide
                                                                                                                                                  Sydney
aupts <- cmdscale(audists)
plot(aupts, axes=FALSE, ann=FALSE, fg="gray",                                  q                                                    q         q

         frame.plot=TRUE)                                                 Broome                                                 Alice  Brisbane
city <- rownames(aupts)
pos <- rep(1,length(city))                                                             q
pos[city=="Melbourne"]<- 3
pos[city=="Canberra"] <- 4                                                        Darwin
par(xpd=TRUE)
text(aupts, labels=city, pos=pos)                                                                                                           q
par(xpd=FALSE)
                                                                                                                                        Cairns
    Classical multi-dimensional scaling, as implemented by
cmdscale(), gives long distances the same weight as short dis-            Figure 9.16: Relative locations of
tances. It is just as prepared to shift Canberra around relative to Mel-  Australian cities, derived from road
bourne and Sydney, as to move Perth. It makes more sense to give          map distances, using metric scaling.
reduced weight to long distances, as is done by sammon() (MASS).

A: Using Classical MDS                                  q                 B: Using Sammon Scaling                                        q

                                     q                                 q                                       q                                        q
                   q                                                                         q
                                                                   q                                                                                q
                                           q                   q                                                     q                          q
                                                       q                                                                                q
      q                                                                         q
                                                    q                                                                         q

    Figure 9.17 shows side by side the overlays of the “maps” that re-    Figure 9.17: In Panel A, Figure 9.16
sult from the diﬀerent ordinations, onto a physical map of Australia.     has been linearly transformed, to give
Panel A shows the result for classical multi-dimensional scaling.         a best ﬁt to a map of Australia. Each
Panel B does the same, now for the result from Sammon scaling.            city moves as shown by the line that
Notice how Brisbane, Sydney, Canberra and Melbourne now main-             radiates out from it. Panel B is the
tain their relative positions better.                                     equivalent plot for Sammon scaling.

    To see the code for Figure 9.17, source the ﬁle that has the code
for the ﬁgures of this chapter, and type:

fig12.15A
fig12.15B
194 learning and exploring r

    The exercise can be repeated for multidimensional scaling
(MDS). MDS preserves only, as far as possible, the relative dis-
tances. A starting conﬁguration of points is required. This might
come from the conﬁguration given by cmdscale(). For the sup-
plementary ﬁgure supp12.1() that shows the MDS conﬁguration,
however, we use the physical latitudes and longitudes.

    To show this ﬁgure, source the ﬁle, if this has not been done
previously, that has the code for the ﬁgures of this chapter. Then
type:

supp12.1()

References

  Cowpertwait P. S. P. and Metcalfe A. V. 2009. Introductory Time
  Series with R. Springer.
  Hyndman, R. J.; Koehler, A. B.; Od, J. K.; and Snyder, R. D.
  2008. Forecasting with Exponential Smoothing: The State Space
  Approach, 2nd edn, Springer.
  Taleb, Naseem. 2004. Fooled By Randomness: The Hidden Role
  Of Chance In Life And In The Markets. Random House, 2ed.
  [Has insightful comments about the over-interpretation of phe-
  nomena in which randomness is likely to have a large role.]
10
Map Overlays and Spatial Modeling
196 learning and exploring r                                            For an overview of what is available
                                                                        under the R umbrella, see the CRAN
    In the past several years, there have been spectacular advances in  Task View: http://cran.csiro.
R’s mapping and spatial analysis abilities. These have used R as a      au/web/views/Spatial.html.
unﬁed framework both for abilities that were developed within R and
for abilities that were designed to run independently of R. Use of R    1 Alternatively, install from the GUI
in this way can have huge beneﬁts.                                      menu.

    From the R command line, the relevant R packages can be in-
stalled thus: 1

install.packages(c("rgdal","gstat","sp"),
                               dependencies=TRUE)

    The rgdal binaries for Windows and for MacOS X include
GDAL, PROJ.4 and Expat. This avoids any need to install this soft-
ware outside of R. Ensure also that you have rJava.

10.1 Static Overlay onto Maps

library(oz)                                                                                       Bulburin q
library(DAAG)                                                                                     Conondale q

10.1.1 Overlay onto country and regional outlines                                                             Byrangery

Figure 10.1 uses the function oz() in the oz package to plot an                                                                    q
outline of the Australian coast and state boundaries.                                                                               q

    Labeling information has been added, using the functions                                                Whian Whian
points() and text(), that identiﬁes seven sites where studies of                               Allyn River q
possums were conducted. Names of sites, and latitude and longitude
information, were taken from the possumsites data set.                       Cambarville q q Bellbird

    Code used for plot is:                                              Figure 10.1: Sites at which possums
                                                                        were collected.
oz(sections=c(3:5, 11:16), col="gray")
chh <- par()$cxy[2]
with(possumsites , {

   points(Longitude ,
                Latitude+c(0,0,0,.2,-.2, 0,0)*chh,
                col="blue")

   text(Latitude ~ Longitude ,
            labels=rownames(possumsites),
            col="red", pos=c(2,4,2,1,3,2,2), xpd=TRUE)

   # pos = 1:below, 2:left, 3:above, 4:right
   # xpd=TRUE allows plotting outside figure region
})

10.1.2 The dismo package’s Interface to Google maps                     Loading the package dismo, with the
                                                                        default dependencies=TRUE, will at
The function gmap() (dismo package) is designed to access and           the same time load the sp and raster
download Google map data.                                               packages.

library(dismo, quietly=TRUE)

   ## The raster and sp packages are dependencies
map overlays and spatial modeling 197

Basic syntax, accepting defaults: The following is a simple exam-       The argument type to gmap()
ple of what is possible:                                                can be set to ’roadmap’,
                                                                        ’satellite’, ’hybrid’or
cbr <- gmap("Canberra , ACT")                                           ’terrain’. Use scale=2 to
plot(cbr)                                                               double the number of pixels (default is
acton <- gmap("Acton, ACT", type="satellite")                           1.
plot(acton)
                                                                        The argument zoom takes values
Road addresses can be speciﬁed. Try, e.g.                               between 0 and 21.

TBhouse <- gmap('11 Bowen St, Wellington , NZ',
                             type='satellite', scale=2, zoom=20)

plot(TBhouse)

Specify map longitude/latitude extent; overlay onto map: The data       Extents are speciﬁed in a longi-
frame possumsites (DAAG) holds latitudes and longitudes of pos-         tude/latitude coordinate system. The
sum study sites. In the following, a map is created that takes in all   function gmap() will, unless called
the sites. Site names are then overlaid on to the map:                  with lonlat=TRUE, return a raster
                                                                        object that uses a Mercator projection.
## Extend longitude & latitude ranges slightly
lonlat <- with(possumsites ,

                           c( range ( Longitude )+ c(-3 ,3) ,
                               range ( Latitude )+ c(-2 ,2))

)
## Obtain map, as a ` ` RasterLayer ' ' object
googmap <- gmap(extent(lonlat))
plot(googmap, inter=TRUE)
## From latitude/longitude to Mercator projection
xy <- Mercator(with(possumsites ,

                                    cbind(Longitude , Latitude)))
## Points show location of sites on the map
points(xy)
## Add labels that give the names
text(xy, labels=row.names(possumsites))

Interactive selection of a map extent from a screen display: Type:      2 An initial click on the map may be
                                                                        required to initiate the process.
newlims <- drawExtent()
                                                                        The new area is likely to be somwhat
Now click at opposite corners2 of the rectangular region that is to be  larger than was marked out by the
selected. Red ’+’ symbols will appear at the locations clicked, and a   bounding box.
bounding box will be marked out in red. Then enter:

googmap2 <- gmap(newlims)
plot(googmap2)

10.1.3 The plotKML package                                              The range of dates is from 2009-
                                                                        08-02 to 2014-01-20, for quakes of
require(plotKML)                                                        magnitude 4.5 or greater. Subsection
                                                                        |refss:markup has the code that was
    The plotKML() function overlays any of points, lines, contours      used to retrieve the data from the NZ
and images onto a Google earth display. Just as with a standard         GeoNet website.
Google Earth display, this can be manipulated with a mouse or track-
pad. The following brings the data into R:
198 learning and exploring r                                           If the image does not appear,
                                                                       look in the working directory for
library(DAAGviz)                                                       quakes__Energy__.kml, and click on
fullpath <- system.file('datasets/nzquakes.CSV',                       it.

                                           package='DAAGviz')          Among the many raster formats are
quakes <- read.csv(fullpath)                                           several that are widely used for image
quakes$Date <- as.Date(quakes$Date)                                    ﬁles more generally: BMP, various
quakes$Energy <- 10^quakes$magnitude/1000000                           JPEG formats, GIF, PNG, XPM, etc.
                                                                       Georeferencing, allowing inclusion of
    Now prepare the data for plotting:                                 spatial reference data, is available for
                                                                       BMP, JPEG 2000 formats, and TIFF.
## Prepare data for plotting
coordinates(quakes) <- ~ longitude+latitude
proj4string(quakes) <-

   CRS("+proj=longlat +datum=WGS84")

    Now create the display:

plotKML(quakes['Energy'], points_names="")
   # Makes circle area proportional to Energy

10.1.4 Specifying projections

Note that we had to specify a coordinate system. With longitude/lat-
itude coordinates, as above, we can specify "WGS84". Projec-
tions become important when spatial data, e.g., on metal con-
centrations, is overlaid on map data, e.g., from Google maps. See
help(proj4string) and help(CRS) for further details.

10.2 Working with Raster (Image) Files

The function readGDAL() in the rgdal package is intended for read-
ing GDAL grid maps. The following, loosely based on the example
code in the help pages for readGDAL, requires the packages rgdal,
sp, and grid. We begin by using the function readGDAL() to input,
as a grid, the R logo ﬁle that is supplied with the R package rgdal:

library(rgdal)

logofile <- system.file("pictures/Rlogo.jpg",
                                           package = "rgdal")[1]

rlogo <- readGDAL(logofile , silent=TRUE)

Typing these commands from the command line, but with
silent=FALSE, will result in the warning message “GeoTrans-
form values not available”. This is not surprising. The pixels in the
image do not have associated geographical spatial coordinates.

    Now examine the input object:

class(rlogo)

[1] "SpatialGridDataFrame"
attr ( ," package ")
[1] "sp"

names(rlogo)

[1] "band1" "band2" "band3"
                                                                   map overlays and spatial modeling 199

Observe that the ﬁle has been input as a SpatialGridDataFrame.
The function image has a method for objects of this class.

    The command image(), specifying the red, green and blue chan-
nels, can be used to show the ﬁgure, using the folowing code:

image(rlogo, red="band1",
           green="band2",
           blue="band3")

The function spplot.grid() is called to do the plotting. In turn, it
calls function levelplot() from the lattice package.

    Another possibility is to use the function spplot() to examine
the red green and blue layers separately, as in Figure 10.2:

3−layer (RGB) raster image − example                                  Figure 10.2: Red, green and blue
                                                                      layers from the R logo image.
red  green  blue                      250
                                      200
                                      150
                                      100
                                      50
                                      0

## Code                                                               The following can be used to get
col3 <- c("red","green","blue")                                       information about the ﬁle, before
spplot(rlogo, zcol=1:3, names.attr=col3,                              inputting it:

            col.regions=grey(0:100/100), as.table=TRUE,               GDALinfo(sp27)
            layout=c(3,1), main=paste("3-layer (RGB)",
            "raster image - example"))

    Note also the functions spplot.polygons() and
spplot.points(). These are all documented on the same page
as the generic function spplot().

∗A genuine spatial image

The following locates the ﬁle that will be input from the package
installation directory:

sp27 <- system.file("pictures/SP27GTIF.TIF",
                                    package = "rgdal")[1]

    Now use readGDAL() to create a GDAL grid map image:

SP27GTIF <- readGDAL(sp27, output.dim=c(100,100),
                                      silent=TRUE)

class(SP27GTIF)

[1] "SpatialGridDataFrame"
attr ( ," package ")
[1] "sp"

Then to plot the image, enter:

spplot(SP27GTIF)
                                                                                             Zinc(ppm)

200 learning and exploring r                                                         333000  qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq q qqqqqq qqq qqq qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq   q 100
                                                                                     332000                                                                                                                                                                 q 200
10.2.1 Overlaying onto a bubble plot                                                 331000                                                                                                                                                                 q 400
                                                                                     330000
Figure 4.2 in Section 4.4.1 showed how to use a bubble plot to dis-                                                                                                                                                                                        qq 800
play the meuse data from the sp package. Figure 10.3 adds river                                                                                                                                                                                                    1600
boundaries, using data from the dataset meuse.riv. (This is a ma-
trix, with Eastings in column 1 and Northings in column 2.)                          178500 179500 180500 181500

    The function bubble() uses the abilities of the lattice package.                 Figure 10.3: Bubble plot for zinc,
As a consequence, the layering abilities of the latticeExtra package                 with area of bubbles proportional to
(see Subsection 7.2.8) can be used to add to the plot. Code is:                      concentration. River Meuse bound-
                                                                                     aries are in gray.

library(sp)
data(meuse); data(meuse.riv)
coordinates(meuse) <- ~ x + y
gph <- bubble(meuse, "zinc", pch=1, key.entries =
100 * 2^(0:4),

                         main = "Zinc(ppm)", scales=list(axes=TRUE, tck=0.4))
add <- latticeExtra::layer(panel.lines(meuse.riv[,1], meuse.riv[,2],

                                        col="gray"))
gph+add

10.3 ∗Reading and Processing Shapeﬁles

Shapeﬁles (ESRI Shapeﬁles) are a popular geospatial vector data format. For
detailed comments, see http://en.wikipedia.org/wiki/Shapefile. They
describe geometries – points, lines and polygons.

     The subdirectory vectors, stored as part of the rgdal package, has a number
of shapeﬁle collections. The following extracts and stores the path (dsn = “dataset
name”) to this directory:

dsn <- system.file("vectors", package = "rgdal")[1]
dir(dsn, pattern="shp$")

[1] "cities.shp"    "kiritimati_primary_roads.shp"                                   The following can be used to get
[3] "scot_BNG.shp"  "trin_inca_pl03.shp"                                             information on the "cities" layer,
                                                                                     prior to input:
There are thus three shapeﬁle collections, or “layers”.
     The ﬁles in the cities shapeﬁle collection are:                                 ogrInfo ( dsn =dsn ,
                                                                                                   layer="cities")
## Get names of files in shapefile collection
dir(dsn, pattern="cities")                                                           Note also .prj ﬁles, which hold coor-
                                                                                     dinate system and projection informa-
[1] "cities.dbf" "cities.htm" "cities.prj" "cities.sbn" "cities.sbx"                 tion.
[6] "cities.shp" "cities.shx"

The mandatory ﬁles are the .shp (shape format), the .shx (shape index format) and
.dbf (attribute format) ﬁles. For detailed information, see http://en.wikipedia.
org/wiki/Shapefile.

     Now input the shapeﬁle collection cities:

cities <- readOGR(dsn=dsn, layer="cities", verbose=FALSE)

The readOGR() function combines information from the separate shapeﬁles into a
SpatialPointsDataFrame

     The following gives summary information:

summary(cities)

Object of class SpatialPointsDataFrame
Coordinates:

                         min max
coords.x1 -165.27 177.1
                                                                        map overlays and spatial modeling 201

coords.x2 -53.15 78.2

Is projected: FALSE

proj4string :

[+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0]

Number of points: 606

Data attributes:

NAME                 COUNTRY  POPULATION CAPITAL

Hyderabad: 2 US        : 49 -99 : 30 N:442

San Jose : 2 Russia : 37 1270000: 5 Y:164

Tripoli : 2 China : 36 1550000: 4

Valencia : 2 Canada : 22 1140000: 3

Abidjan : 1 India : 20 1190000: 3

Abu Zaby : 1 Brazil : 19 1225000: 3

(Other) :596 (Other):423 (Other):558

The four “data attributes” are columns of the data slot. Use for example          For example, omne might add, using
cities$COUNTRY or cities[,"COUNTRY"] to extract the column COUNTRY.               data on the World Bank website, a
Further columns can be added as required, or existing columns removed or modi-    column giving the percentage of the
ﬁed.                                                                              population under 20 years of age.

     To get information obout the countries represented, type:

slotNames(cities)

[1] "data"        "coords.nrs" "coords"  "bbox"
"proj4string"

names(cities)     "COUNTRY"   "POPULATION" "CAPITAL"
[1] "NAME"

   ## Returns the names in the data slot
length(levels(cities$COUNTRY))

[1] 165

There are 165 countries.
     The following extracts and plots the shapeﬁle details for Canada:

canada <- subset(cities , COUNTRY=="Canada")
trellis.par.set(sp.theme())
spplot(canada, zcol="POPULATION")

ASGC Digital Boundaries                                                           If the ﬁle is not in the working direc-
                                                                                  tory, precede the ﬁle name with the
The following downloads, to the working directory, a zipﬁle for a directory that  path to the ﬁle.
holds 2011 statistical region boundaries in ESRI shapeﬁle format:

url <- paste0("http://www.abs.gov.au/ausstats/subscriber.nsf/",
   "log? openagent & 1259030001 _sr11aaust_shape.zip & 1259 .0.30.001 ",
   "&Data%20Cubes&B8003880BC09FA5BCA2578CC00124E25&0",
   "& July %202011 & 14 .07.2011 & Latest ")

downloadTo <- "../downloads/1259030001_sr11aaust_shape.zip"
download.file(url, destfile=downloadTo)

The ﬁle is 25.6MB and, depending on the speed of the connection, will take a
modest time to download.

     Alternatively, go to the web page http://www.abs.gov.au/AUSSTATS/
abs@.nsf/DetailsPage/1259.0.30.001July%202011?OpenDocument, locate
the zip ﬁle identiﬁed as containing “Statistical Region ASGC Ed 2011 Digital
Boundaries in ESRI Shapeﬁle Format”, and download it. Click on SUMMARY
to get information that describes the codes that are used to identify states and
territories, the ﬁeld headers, ans the nature of the included data.

     The following then unzips the ﬁles into the subdirectory au-srs:
202 learning and exploring r

unzip("../downloads/1259030001_sr11aaust_shape.zip", exdir="au-srs")
dir("../downloads/au-srs")

[1] "SR11aAust.cpg" "SR11aAust.dbf" "SR11aAust.prj" "SR11aAust.shp"
[5] "SR11aAust.shx"

     Now input the information from the shapeﬁles, and combine it to create a
SpatialPolygonsDataFrame, named auSRS, that has statistical region bound-
aries:

auSRS <- readOGR("../downloads/au-srs", layer="SR11aAust")

OGR data source with driver: ESRI Shapefile
Source: "/Users/johnm1/_notes/learnR/downloads/au-srs", layer: "SR11aAust"
with 66 features
It has 3 fields

States or territories are 1:New South Wales, 2:Victoria, 3:Queensland, 4:South
Australia, 5:Western Australia, 6:Tasmania, 7:Northern Territory, 8:Aus-
tralian Capital Territory, 9:Other Territories. The following extracts the
SpatialPolygonsDataFrame for Victoria.

vicSRS <- subset(auSRS, STATE_CODE==2)
unique(vicSRS@data[,"SR_NAME11"])

[1] Outer Western Melbourne North Western Melbourne

[3] Inner Melbourne           North Eastern Melbourne

[5] Inner Eastern Melbourne Southern Melbourne

[7] Outer Eastern Melbourne South Eastern Melbourne

[9] Mornington Peninsula      Barwon-Western District

[11] Central Highlands -Wimmera Loddon-Mallee

[13] Goulburn -Ovens-Murray   All Gippsland

66 Levels: All Gippsland ... Wide Bay-Burnett

Notice that all 66 factor levels from auSRS have been retained, even though only 14
of these levels are present in this dataset.

     Functions are available for combining ﬁles of this type, or for removing bound-
aries such as between the SR_NAME11 regions.

Further information

The R geo website, at http://www.r-project.org/Rgeo/ has extensive in-
formation. The Wiki page http://spatial-analyst.net/wiki/index.php?
title=Software has extensive information about installation of relevant geostatis-
tical software.

     Table 3.1 in Hengl(2011) compares the spatio-temporal abilities of some popu-
lar statistics and GIS packages. There are columns for R+gstat and R+geoR.

     The web page http://www.nceas.ucsb.edu/scicomp/usecases/
ReadWriteESRIShapeFiles has several examples that demonstrate the read-
ing and plotting of shapeﬁles, comparing abilities in the rgdal package with those in
maptools and PBSmapping. Note also the package shapeﬁles.

     The website http://info.geonet.org.nz/display/appdata/
Earthquake+Web+Feature+Service has information on how New Zealand
earthquake data may be retrieved in a variety of formats. The site http:
//www.christchurchquakemap.co.nz/ has impressive dynamic visualizations
of Christchurch (NZ) and other quake data.

     A carefully documented example of the use of shapeﬁles of New Zealand data
can be found at

http://www.r-bloggers.com/simplifying-polygon-shapefiles-in-r/.
                                                                                       map overlays and spatial modeling 203

10.4 Other software – QGIS

Note in particular QGIS, which has an interface via manageR to R;
go to http://www.ftools.ca/plugins.html.

    To obtain Windows and Linux installers for QGIS, go to http:
//www.qgis.org/wiki/Download. The standalone installer for
Windows includes GRASS. For MacOSX, go to http://www.
kyngchaos.com/software/qgis. For Leopard and Snow Leopard
installations, the QGIS 1.7 developer builds seem relatively stable.
GRASS must be installed separately.

10.5 References

  Bivand R, Pebesma E J, Gomez-Rubio, V. 2008. Applied Spatial
  Data Analysis with R. Springer.

  Diggle, Peter J. & Ribeiro Jr, Paulo J 2007. Model-Based Geo-
  statistics. Springer.

  Hengl, T. 2011, A Practical Guide to Geostatistical Mapping. 2nd
  edn.
  [To download (free) or purchase ($US15.19), go to:
  http://www.lulu.com/ and search for ’Hengl’]

  Hijmans, R J. 2011. Introduction to the ’raster’ package.
  [With the R package raster attached, type vignette("Raster").

  Hijmans, R J and Elith J. 2011. Species distribution modeling with
  R.
  [With the R package dismo attached, type vignette("sdm").
  The vignette appears to be an outline for a book. Later chapters
  are very incomplete.]

  Lamigueiro, O P 2012. Maps with R (I) http://procomun.
  wordpress.com/2012/02/18/maps_with_r_1/

  Maindonald, J H 2011. Generalized Additive Models in Spatial
  Statistics – Linear Models with a Twist (slides). maths.anu.edu.
  au//~johnm/r/spatial/
  [This oﬀers a perspective on spatial interpolation.]

  Quantum GIS Development Team 2010. Quantum GIS User
  Guide( Version 1.6.0 ‘Copiapó’). Obtain from http://www.
  qgis.org/en/documentation/manuals.html

See also the vignettes that accompany the package sp, describing
classes and methods for spatial data, and overlay and aggregation.
204 learning and exploring r
11
Brief Notes on Text Mining
206 learning and exploring r

    A ﬁrst step is to load the tm package. This is designed for work-
ing with a corpus — corpus is the name for a collection of docu-
ments.

library(tm)

11.1 Creation of a Volatile Corpus                                      A pdf to text converter has taken the
                                                                        pdf for this document, and extracted
The data used is from three text ﬁles, stored in the DAAGviz direc-     the three chapter ranges into the
tory tree. They hold text from the respective chapter ranges 1 - 5, 6   respective ﬁles ch1-5prelims.txt,
- 7, and 8 - 9 of an older version of this present document. We show    ch6-7data.txt, and ch8-9graphics.txt.
two ways to use it to form a corpus. The ﬁrst breaks the process
down into detailed steps, while the second uses a much terser and
summary approach. The resultant corpus is volatile, so described
because stored in the workspace. Unless saved separately or as part
of the workspace, it will disappear at the end of the session.

Detailed steps

First create paths to the ﬁles, and check that they seem correct:

## Create paths to the text files, stored in the
## subdirectory "texts" of the DAAGviz package.
txdir <- system.file("texts", package="DAAGviz")
dir(txdir, pattern=".txt$")

[1] "data6 -7.txt"  "graphics8 -9.txt" "prelims1 -5.txt"

txfiles <- dir(txdir, pattern=".txt$", full.names=TRUE)

    The following brings the ﬁrst of these ﬁles into the workspace,
with one text string per line. The separate text strings are then col-
lapsed into a single character vector, with spaces at the end of each
line:

## Input first file, with one text string per line
tx1 <- readLines(txfiles[1], encoding="UTF-8", warn=FALSE)
## Join the separate text strings end to end
tx1 <- paste(tx1, collapse=" ")

    Repeat this process for ﬁles 2 and 3:

tx2 <- readLines(txfiles[2], encoding="UTF-8", warn=FALSE)
tx2 <- paste(tx2, collapse=" ")
tx3 <- readLines(txfiles[3], encoding="UTF-8", warn=FALSE)
tx3 <- paste(tx3, collapse=" ")

    Now bring the three text strings together into a corpus:

txcorp <- Corpus(VectorSource(c(tx1, tx2, tx3)))
Creation of a corpus using DirSource()                                 brief notes on text mining 207

The following creates a directory source:                              The call to tm_map() is a mech-
                                                                       anism for marking the document
dirSource <- DirSource(directory=txdir,                                as UTF-8. The pdf to text con-
                                          pattern=".txt$")             verter creates UTF-8 documents.
                                                                       The tokenizer scan_takenizer
    Now create the corpus. The text will be input from the ﬁles that   then calls scan(), but without
were identiﬁed, within the speciﬁed directory doc:                     marking the document that results
                                                                       as UTF-8, as required for use of
toUTF8 <- function(x) iconv(x, to="UTF-8",                             termDocumentMatrix() or
                                                   sub = "byte")       termFreq().

txcorp <- Corpus(dirSource)
txcorp <- tm_map(txcorp,

       content_transformer(toUTF8))

Next steps

A common starting point for further work is a term by document
matrix. For this, use TermDocumentMatrix(). Or if a document by
term matrix is required, use DocumentTermMatrix()

    Pre-processing steps prior to creating such a matrix may include
stripping away stopwords, elimination of white space, and conver-
sion to lower case. These can be performed in the process of creating
a term document matrix, thus:

ctl <- list(removePunctuation = list(preserve_intra_word_dashes = FALSE),
                     removeNumbers = TRUE,
                     stopwords=c(stopwords("SMART"), "[1]"),
                     wordLengths=c(3,Inf))

tx.tdm <- TermDocumentMatrix(txcorp , control=ctl)

Notice the identiﬁcation of [1], which appears quite frequently        1 See help(termFreq) for an
in the R output, as a stopword. This omits it from the list of terms.  example of a user-supplied tokenizer.
Closer investigation would reveal other issues, most because the
default tokenizer1 is not designed to handle R code and output.

    Stopwords are words that are likely to be uniformative for pur-
poses of comparing text content. The function tm::stopwords()
accepts the arguments kind="en", which gives a relatively re-
stricted list of English stopwords, or kind="SMART" which gives a
much more extensive list. See ?tm::stopwords for details of non-
English stopword lists that are immediately available. The following
will give an idea of the sorts of words that are in the two lists:

## First few stopwords in the "en" set
sort ( stopwords ())[1:5]

[1] "a"     "about" "above" "after" "again"

## First few stopwords in the "SMART" set
stopwords('SMART')[1:5]

[1] "a"     "a's" "able" "about" "above"
208 learning and exploring r

## Stopwords in "SMART" but not in "en"; first 10
stopwords (" SMART ")[! stopwords (" SMART ")% in% stopwords ()][1:10]

[1] "a's"                          "able"                                                                                                                                                   "according"
                                                                                                                                                                                            "ain 't"
"accordingly" "across"

[6] "actually" "afterwards"

"allow"             "allows"

   Now list terms that occur 100 or more times:

findFreqTerms(tx.tdm, 100)

[1] "code"                "data"                                                                                                                                                            "figure" "file"                                                                                               "frame"
                                                                                                                                                                                                                                                                                                          "package"
[6] "function" "functions" "graphics" "objects"

[11] "plot"

Wordclouds                                                                                                                                                                                                                                                                                                       Figure 11.1: Wordcloud plots are A:
                                                                                                                                                                                                                                                                                                                 for the words in Chapters 1 - 5; B: 6 -
First load the wordcloud package:                                                                                                                                                                                                                                                                                7; and C: 8 - 9.

library(wordcloud)                                                                                                                                                                                                                                                                                        C: Chapters 8 − 9

    Figure 11.1 shows wordcloud plots for the ﬁrst (chapters 1-5),
second (6-7) and third (8-9) documents in the corpus.

A: Chapters 1 − 5                                                                                                                                                                           B: Chapters 6 − 7

                    manipulation                                                                                                                                                                                                   quickplot
                                                                                                                                                                                                                            simulated
                    charararsayeccdtitaoetnerucdabierargdemnutimsgsriaeopnnhstics element                                                                                                                                          analysis                                                                                        commander installation
                                                                                                                                                                                                             weight                                                                                                                menu scatterplotscales
                                                                                                                                                                                                                     shape  gph    argument                                                                                   packagenames
                                                                                                                                                                                                                     note                                                                                                              commandrange
                                            files                                                                                                                                                                           point                                    display plotting                                         frame    files rstudioinformation
                                                default                                                                                                                                         possum set size                                                      axis add                                                 figure
         refoxotwrramctmcoalturimx n columns              country                                                                                                                                                                  data                                                                        shows                   directoryobject
                                                          daag                                                                                                                                      create                                                           plots                                document            install                              travelbooks
   functionsmango levels file                                                                                                                                                                                                             true                                                                                                             note
           year                                            rows                                                                                                                               latticeprint text                                         panels        points                                 result
                                                       information                                                                                                                                                                                                                                                   enter
 objects frameformat falsepage                                                                                                                                                              visualisation                                                       sport                                                       function                       typewidth
      web                                              values                                                                                                                                                                                                                                                               plots
    returns                                                                                                                                                                                  figuretypecode
                                                            read                                                                                                                                                                                                                                                            plot
      sapply                                               set                                                                                                                                functions base                                                                                              datapanel

   length time                                                     include                                                                                                                                                                                                                                analysis
travelbooksvectors                                                                         apply                                                                                            graphs                                                                                                                                 workspace               volume
                                                         input                                                                                                                                height xyplot
 datasum                                                   nas logical                                                                                                                                     graphicslabpealrs                                                                       false  weightclick                                         save         left road
                                                                                                                                                                                                             sex                                                                                          columns                                                   libraryimage
                                                                                                                                                                                                                                                                                                dierent   default           list
                                                                                                                                                                                                                                                                                                show
                                                                                                                                                                                                                                                                                layer
                                                                                                                                                                                                             plot panelglinreas pchlick                                                                   codeinput                                            distance
                                                                                                                                                                                                                                                                           geom                              set                                         year summary
                                                                                                                                                                                                                                                                            page                          fileuser rdata
futnabcletiontruepackagwefoasrcktfoitcnaotagaclfrcsmcrluutlaoalmeausmtmrissoseanersysannuvamelybcsetiosr rmoliasbnttsjrueiplcmicesaentelsctaerckiocmmandgeoeeetsentetoxtsatrdbmeleertshods                                                                                                                           objects                columlinnetilmogepdsavatatahalurgets
                                                                                                                                                                                                                                                                                                                                            graphics icon
                                                                                                                                                                                                              object                densitycolor distribution                                             packagessearch
                                                                                                                                                                                                                                                                     call     colors                                 include  working
                                                                                                                                                                                                             functionkeyline                                               log motion                                  guide

                                                                                                                                                                                                             region normal                                                 daag                                             cran   session    model html
                                                                                                                                                                                                                                                                                                                            base   functions
                                                                                                                                                                                                                ggplotcolumns                                                                                                text               visualisation
                                                                                                                                                                                                             yenuamr essruicpeptpliteiadnscgykmsabodglseefccaoroouulwnchtlrtayprttarleeltlties
                    visualisation                                                                                                                                                                                                                                                                                                  markdown window

                                                                                                                                                                                                                            bodywt                                                                                                 windows change

Code for the plots is:

pal <- brewer.pal(6, "Dark2")
fnam1 <- as.matrix(tx.tdm)[,1]
wordcloud(names(fnam1), fnam1, max.words=80, colors=pal[-1],

                  random.order=FALSE , scale=c(8.5,.5))
mtext(side=3, line=3.5, "A: Chapters 1 - 5", adj=0, cex=1.8)
fnam2 <- as.matrix(tx.tdm)[,2]
wordcloud(names(fnam2), fnam2, max.words=80, colors=pal[-1],

                  random.order=FALSE , scale=c(4.5,.5))
mtext(side=3, line=3.5, "B: Chapters 6 - 7", adj=0, cex=1.8)
fnam3 <- as.matrix(tx.tdm)[,3]
wordcloud(names(fnam3), fnam3, max.words=80, colors=pal[-1],

                  random.order=FALSE , scale=c(6.0,.5))
mtext(side=3, line=3.5, "C: Chapters 8 - 9", adj=0, cex=1.8)
                                                                         brief notes on text mining 209

Less frequent words will be lost oﬀ the edge of the plot if the size     All three panels used a 5in by 5in
of the graphics page is too small relative to the pointsize. Note the    graphics page, with a pdf pointsize of
diﬀerent scaling ranges used in the three cases, with the large scaling  12.
range for Panel B (scale=c(10,.5)) used to accommmodate a
frequency distribution in which one item (‘data’) is a marked outlier.

11.2 Creation of a Corpus from PDF Files

The tm package has functions that can be used to create readers for
several diﬀerent types of ﬁles. Type getReaders() to get a list.
Note in particular readPDF() that can be used with pdf ﬁles. See
?tm::readPDF for details of PDF extraction engines that may be
used. The default is to use the Poppler PDF rendering library as
provided in the pdftools package.

    The following sets the path to the directory pdf in the package
DAAGviz that holds the pdf ﬁles for (possibly, an older version) of
the four ranges of chapters of the present text:

uri <- system.file("pdf", package="DAAGviz")
## Check names of files in directory
dir(uri)

[1] "ch1 -3.pdf" "ch4 -6.pdf" "ch7.pdf" "ch8 -9.pdf"

    The corpus that has all three documents is, starting with the pdf
ﬁles, most easily created thus:

fromPDF <- Corpus(DirSource(directory=uri, pattern=".pdf$"),
                               readerControl =list(reader=readPDF ,
                               PdftotextOptions = "-layout"))

makeChar <- function(x)gsub("[^[:alnum:][:blank:]]","" , x, ignore.case = TRUE)
fromPDF <- tm_map(fromPDF , content_transformer(makeChar))

    Create the term-document matrix thus:

txx.tdm <- TermDocumentMatrix(fromPDF , control=ctl)

11.3 Document Collections Supplied With tm

Several document collections are supplied with the package, as text
ﬁles or as XML ﬁles. To get the path to the directories where these
document collections are stored, type

(pathto <- system.file("texts", package="tm"))

[1] "/Library/Frameworks/R.framework/Versions/3.5/Resources/library/tm/texts"

dir(pathto)           "crude"          "custom.xml"
                      "rcv1_2330.xml"  "reuters -21578.xml"
[1] "acq"
[4] "loremipsum.txt"
[7] "txt"
210 learning and exploring r

The subdirectory acq has 50 Reuters documents in XML format,
crude has the ﬁrst 23 of these, and txt has a small collection of 5
text documents from the Roman poet Ovid. These can be accessed
and used for experimenation with the abilities provided in tm, as
required.

    The following are the names of the ﬁve Ovid documents:

dir(paste(pathto, "txt",sep="/"))

[1] "ovid_1.txt" "ovid_2.txt" "ovid_3.txt" "ovid_4.txt" "ovid_5.txt"

    The following brings these documents into a volatile corpus, i.e.,
a corpus that is stored in memory:

(ovid <-
     Corpus(DirSource(paste(pathto , "txt", sep="/")),
                  readerControl=list(language="lat")))

<<SimpleCorpus >>
Metadata: corpus specific: 1, document level (indexed): 0
Content: documents: 5
12
∗Leveraging R Language Abilities
212 learning and exploring r                                          The data frame mtcars has 11
                                                                      columns from which the two axes
12.1 Manipulation of Language Constructs                              for a scatterplot might be chosen:

Language structures can be manipulated, just like any other object.   names(mtcars)
Below, we will show how formulae, expressions, and argument lists
for functions, can be pasted together.                                 [1] "mpg" "cyl"
                                                                       [3] "disp" "hp"
12.1.1 Manipulation of Formulae                                        [5] "drat" "wt"
                                                                       [7] "qsec" "vs"
Formulae are a key idea in R, though their implementation is incom-    [9] "am" "gear"
plete. They are widely available for specifying graphs, models and    [11] "carb"
tables. Details will be given below.

Model, graphics and table formulae

We demonstrate the construction of model or graphics formulae
from text strings. The following plots the column mpg, from the data
frame mtcars (MASS), against disp:

plot(mpg ~ disp, data=mtcars)

The following gives the same result:

yvar <- "mpg"
xvar <- "disp"
form <- as.formula(paste(yvar, "~", xvar))
plot(form, data=mtcars)

With this second approach, yvar and xvar can be arguments to a
function, and xvar and yvar can be any pair of columns. A suitable
functionis:

plot.mtcars <- function(xvar="disp", yvar="mpg"){
       form <- as.formula(paste(yvar, "~", xvar))
       plot(form, data=mtcars)

}

    The following calls the function with xvar="hp" and
yvar="mpg":

plot.mtcars(xvar="hp", yvar="mpg", data=mtcars)

12.1.2 Extraction of names from a formula

Use the function all.vars() to extract the variable names from a
formula, thus:

all.vars(mpg ~ disp)

[1] "mpg" "disp"

    As well as using a formula to specify the graph, the following
gives more informative x- and y-labels:

plot.mtcars <- function(form = mpg ~ disp){
     yvar <- all.vars(form)[1]
     xvar <- all.vars(form)[2]
                                                     ∗leveraging r language abilities 213

   ## Include information that allows a meaningful label

   mtcars.info <-

   c(mpg= "Miles/(US) gallon",       cyl= "Number of cylinders",

   disp= "Displacement (cu.in.)", hp= "Gross horsepower",

   drat= "Rear axle ratio",          wt= "Weight (lb/1000)",

   qsec= "1/4 mile time",            vs= "V/S",

   gear= "Number of forward gears",

   carb= "Number of carburettors",

   am= "Transmission (0 = automatic , 1 = manual)")

   xlab <- mtcars.info[xvar]

   ylab <- mtcars.info[yvar]

   plot(form, xlab=xlab, ylab=ylab)

}

12.2 Function Arguments and Environments

12.2.1 Extraction of arguments to functions

A simple use of substitute() is to extract a text string representa-
tion of a function argument:

plot.mtcars <-
   function(x = disp, y = mpg){
       xvar <- deparse(substitute(x))
       yvar <- deparse(substitute(y))
       form <- formula(paste(yvar, "~", xvar))
       plot(form, xlab=xvar, ylab=yvar, data=mtcars)
   }

12.2.2 Use of a list to pass parameter values

The following are equivalent:
    Use of do.call() allows the parameter list to be set up in ad-

vance of the call. The following shows the use of do.call() to
achieve the same eﬀect as mean(possum$totlngth):

do.call("mean", list(x=possum$totlngth))

This makes more sense in a function, thus:

 average <-
   function(x=possum$chest, FUN=function(x)mean(x)){
       fun <- deparse(substitute(FUN))
       do.call(fun, list(x=x))
   }

    This allows, e.g., the following:

average()
average(FUN=median)

    Note also call(), which sets up an unevaluated expression. The
expression can be evaluated at some later time, using eval(). Here
is an example:

mean.call <- call("mean", x=rnorm(5))
eval(mean.call)
214 learning and exploring r

[1] 0.06572

eval(mean.call)

[1] 0.06572

Notice that the argument x was evaluated when call() was
evoked. The result is therefore unchanged upon repeating the call
eval(mean.call). This can be veriﬁed by printing out the expres-
sion:

mean.call

mean(x = c(-0.654951646429221, -0.679896362331012, 0.979408998110931,
1.01194857431004, -0.327894174927872))

12.2.3 Function environments                                            1 Additionally, frames may be referred
                                                                        to by name. Use
Every call to a function creates a frame that contains the local vari-
ables created in the function. This combines with the environment          sys.nframe() to get the number
in which the function was deﬁned to create a new environment. The          of the current evaluation frame
global environment, .Globalenv, is the workspace. This is frame 0.         sys.frame(sys.nframe()) to
The frame number increases by 1 with each new function call.1              identify the frame by name
                                                                           sys.parent() to get the number
[1] "test"                                                                 of the parent frame.

    Here is code that determines, from within a function, the function  Now change the function name to
name:                                                                   newtest():

test <- function(){                                                     newtest <- test
  fname <- as(sys.call(sys.parent())[[1]],                              newtest()
                       "character")
   fname                                                                [1] "newtest"

}
test()

[1] "test"

    When a number of graphs are required, all for the one dociment,
a sequential naming system, e.g., fig1(), fig2(), . . . , may be
convenient, with matching names ﬁg1.pdf, ﬁg2.pdf, . . . for the re-
spective graphics ﬁles. The following function gf() generates the
ﬁle name automatically, for passing to the graphics device that is
opened.

gf <-
       function(width=2.25, height=2.25, pointsize=8){
              funtxt <- sys.call(1)
              fnam <- paste0(funtxt, ".pdf")
              print(paste0("Output is to the file '",
                                      fnam, "'"))
              pdf(file=fnam, width=width, height=height ,
                      pointsize=pointsize)
       }
                                                                  ∗leveraging r language abilities 215

   Now create a function that calls gf():

fig1 <- function(){

   gf()              # Call with default parameters

   curve(sin, -pi, 2*pi)

   dev.off()

}

fig1()

Output goes to the ﬁle ﬁg1.pdf. For a function fig2() that calls
gf(), output goes to the ﬁle ﬁg2.pdf, and so on.

Scoping of object names

Local objects are those that are created within the body of the func-
tion. Objects that are not local and not passed as parameters are ﬁrst
searched for in the frame of the function, then in the parent frame,
and so on. If they are not found in any of the frames, then they are
sought in the search list.

12.3 Creation of R Packages                                              The RStudio documentation includes
                                                                         a large amount of information on
Much of the functionality of R, for many important tasks, comes          package preparation, testing, and
from the packages that are built on top of base R. Users who make        submission to CRAN or other reposi-
extenive use of R may soon ﬁnd a need to document and organize           tories. Click on
both their own functions and associated data. Packages are the pre-
ferred vehicle for making functions and/or data available to others,       Help | RStudio Docs
or for use by posterity.                                                 and look under

    Organisation of data and functions into a package may have the         PACKAGE DEVELOPMENT.
following beneﬁts:

• Where the package relates to a project, it should be straightfor-
   ward to return to the project at some later time, and/or to pass the
   project across to someone else.

• Attaching the packages give immediate access to functions, data
   and associated documentation.

• Where a package is submitted to CRAN (Comprehensive R
   Archive Network) and used by others, this extends opportuni-
   ties for testing and/or getting contributions from other work-
   ers. Checks that are required by CRAN ensure that the package
   (code and documentation) meets certain formal standards. CRAN
   checks include checks for consistency between code and docu-
   mentation, e.g., in names of arguments. Code must conform to
   CRAN standards.

Namespaces

Packages can have their own namespaces, with private functions
and classes that are not ordinarily visible from the command line, or
216 learning and exploring r

from other packages. For example, the function intervals.lme()
that is part of the lme package must be called via the generic func-
tion intervals().

12.4 S4 Classes and Methods

There are two implementations of classes and methods – those of
version 3 of the S language (S3), and those of version 4 of the S
language (S4). The methods package supplies the infrastructure for
the S4 implementation. This extends the abilities available under S3,
builds in checks that are not available with S3, and are is conducive
to good software engineering practice. The Bioconductor bundle of
packages makes extensive use of S4 style classes and methods. See
help(Methods) (note the upper case M) for a brief overview of S4
classes and methods.

    Where available, extractor functions should be used to extract
slot contents. If this is not possible, use the function slotNames()
to obtain the names of the slots, and either the function slot() or
the operator @ to extract or replace a slot. For example:

library(DAAG)
library(lme4)

hp.lmList <- lmList(o2 ~ wattsPerKg | id,
                                    data=humanpower1)

slotNames(hp.lmList)

[1] ".Data"      "call"    "pool"  "groups"

[5] "origOrder"

    The following are alternative ways to display the contents of the
"call" slot:

hp.lmList@call

lmList(formula = o2 ∼ wattsPerKg | id, data = humanpower1)

slot(hp.lmList , "call")

lmList(formula = o2 ∼ wattsPerKg | id, data = humanpower1)

    Where available, use an extractor function to extract some rele-
vant part of the output, thus:

coef(hp.lmList)

   (Intercept) wattsPerKg

1 -1.155 15.35

2  1.916         13.65

3 -12.008        18.81

4  8.029         11.83

5 11.553 10.36
                                                                                         ∗leveraging r language abilities 217

    For moderately simple examples of the deﬁnition and use of S4
classes and methods, see help(setClass) and help(setMethod).

    How is it possible to identify, for a particular S4 class, the
function that implements a method. To identify the function
in the sp package that implements the spplot method for
SpatialGridDataFrame objects, type:

library(sp)
selectMethod("spplot",

                       signature="SpatialGridDataFrame")

Method Definition:

function (obj, ...)
spplot.grid(as(obj, "SpatialPixelsDataFrame"), ...)
<bytecode: 0x1166d7098 >
<environment: namespace:sp>

Signatures:
              obj

target "SpatialGridDataFrame"
defined "SpatialGridDataFrame"

This makes it clear that the spplot method for
SpatialGridDataFrame objects calls the function
spplot.grid(). To display the function spplot.grid(), type:

getFromNamespace("spplot.grid", ns="sp")

Alternatively, use the less targeted
getAnywhere("spplot.grid").

    Use showMethods() to show all the methods for one or more
classes of object. For example:

showMethods(classes='SpatialGridDataFrame')

12.5 Summary

  Language structures (formulae and expressions) can be manipu-
  lated, just like any other object.

  R uses formulae to specify models, graphs and (xtabs() only)
  tables.

  The expression syntax allows the plotting of juxtaposed text
  strings, which may include mathematical text.

  All evaluations have an environment that determines what objects
  will be visible. This can be especially important for the writing
  and testing of functions.

  Packages are the preferred vehicle for making substantial collec-
  tions of functions and/or data available to others, or for use by
  posterity. They facilitate re-use of code and enforce checks for
218 learning and exploring r

  common inconsistencies. They make it straighforward to enforce
  high standards of documentation.

  Many of R’s more recent packages use S4 classes and methods.
  Extractor functions are available that will extract the most com-
  monly required types of information.
A
∗R System Conﬁguration
220 learning and exploring r

A.1 Fine tuning the installation

The information in this section is relevant mainly to users of the
Windows or Mac GUI, rather than RStudio. With RStudio, work
is typically organized by projects, albeit usually with a diﬀerent
working directory for each diﬀerent project.

The working directory: This is best set to a directory that is con-      Figure A.1: This shows the sequence
venient for storing ﬁles connected with the project on which you         of clicks needed to display the page
are currently working. When starting a new project, it to start a new    from which the Start in: directory can
working directory.                                                       be set. This will then be the working
                                                                         directory in which R will start.
    Under Windows, each R icon has associated with it a working
directory. Right click the icon. Then click on Properties (at the bot-   Under MacOS X, dragging a ﬁle onto
tom of the list), thus displaying the Properties submenu. Make sure      the R icon will start R in the directory
that Shortcut is selected. Set the Start in: directory to the working    that contains the ﬁle. Alternatively, in
directory in which you want R to start. See Figure A.1.                  a terminal window, type for example:

Multiple (MDI) or Single (SDI) display interface for Windows:              open -a R ∼/r/course
One way to get R to start in SDI mode is to add sdi, with a pre-         This will start R with ∼/r/course as
ceding space, to the target that is shown in Figure A.1.                 working directory.

A.2 Setting the Default CRAN Mirror                                      Figure A.2: This shows the R Win-
                                                                         dows GUI menu option that can be
The default CRAN mirror can be set from the Windows or MacOS X           used to set the CRAN mirror. If not
R GUI.                                                                   set, the user is asked to nominate the
                                                                         mirror whenever one or more pack-
Windows: Click on Packages | Set CRAN mirror . . .                       ages are downloaded or updated from
                                                                         CRAN.

A.3 R system information

If access is needed to ﬁles that are in the R installation tree, obtain
the path, thus:
MacOS X: Click on R | Preferences                                       ∗r system configuration 221

                                                                      Figure A.3: In a factory fresh
                                                                      MacOS X installation, pack-
                                                                      ages are downloaded from
                                                                      http://cran.r-project.org. The
                                                                      preferences pages allow the setting
                                                                      of a wide variety of other preferences
                                                                      also.

Click on
Preferences. Then
click, if necessary,
on Startup to dis-
play the startup
options, shown in the
Window on the right.

R.home()

[1] "C:/PROGRA∼1/R/R-32∼1.2"

When using Microsoft Windows systems, a more intelligible result is   If the winslash="/" argument is
obtained by wrapping the function call in normalizePath(), thus:      omitted, double backslashes are used
                                                                      to separate names in the directory tree.
normalizePath(R.home(), winslash="/")
[1] "C:/Program Files/R/R-3.2.2"

    To see a list of all R system variables, type

names(Sys.getenv())

These can then be inspected individually.

Sys.getenv("R_HOME")

[1] "C:/PROGRA∼1/R/R-32∼1.2"

See help(Rprofile) for details on how to set system variables.
    The following can be used to get the path to ﬁles that come with

an installed package:

system.file("misc/ViewTemps.RData", package="DAAG")

[1] "C:/Users/JohnM/Documents/R/win-library/3.2/DAAG/misc/ViewTemps.RData"

A.4 Repositories additional to CRAN

Figure A.4 shows a list of available repositories, as given by the
Windows GUI, after clicking on: Packages|Set repositories.
222 learning and exploring r                                               Figure A.4: List of available reposito-
                                                                           ries, as given by the Windows GUI.
To select more than one repository, hold down the Windows key, or
under MacOS X the command key, while left-clicking.

    To use the command line to view a list of all repositories known
to the R installation, and possibly to select one or more, type:

setRepositories ()

Alternatively, use the argument ind, in a call to
setRepositories(), to specify repositories. For example:

setRepositories(ind=1:2)

A.5 Running R in Batch Mode                                                For Windows 64-bit R
                                                                           (2.12.0 or later), the directory
On the command line (for Windows, Unix, Linux, . . . ), enter              R_HOME\bin\x64 must be in the
                                                                           system path. For Windows 32-bit R,
R CMD BATCH infile outfile                                                 replace x64 by i386. For determining
                                                                           R_HOME, see above.
    Here inﬁle is a ﬁle that holds R commands. See help(BATCH)
for further information. The path to the R executable must be in-
cluded in the system path variable. The R FAQ for Windows has
information on setting environment variables.

A.6 The R Windows installation directory tree                              For running R from a DVD (or CD),
                                                                           be sure to change the Start In directory
The R system can be installed into any directory where the installer       to a directory that is writable.
has write permission. The hierarchy of directories and ﬁles that form
the R installation is termed the directory tree. Likely defaults for the
directory tree of an R-3.2.2 Windows installation are:

     C:\PROGRAM FILES\R\R-3.2.2\

or, for example,

     C:\Documents and Settings\Owner\My Documents\R\R-3.2.2\

    The directory tree is relocatable. It can be copied to a ﬂash drive
or CD or DVD, which can be then be used to run R. Thus, copy
the installation tree with root at C:\Program Files\R\R-3.2.2\
across to D: to become a tree with root D:\R-3.2.2\. The executable
(binary) D:\R-3.2.2\bin\x64\Rgui.exe can then be used to start
a 64-bit R session. To verify that this works, click on its icon. For
32-bit R, replace x64, where it appears in the path, by i386.

A.7 Library directories

Packages that the user installs can go anywhere on the system. It is
not necessary to install them into the library directory that is in the R
directory tree.

    An R session that is running from one installation, perhaps the
main installation on the hard drive, can in principle access any com-
patible R library directory that is available. Thus, the following gives
access, from an R session that is started (e.g.) from the hard drive, to
to a library tree that is stored under D:\R-3.2.2:
.libPaths("D:/R-3.0.2/library")                                               ∗r system configuration 223

This might for example be the library tree from an R installation on a      1 This function will then be saved
DVD that has been placed in the D: drive.                                   as part of the default workspace,
                                                                            and executed at the start of any new
    To avoid the need to type this each time a new session is started       session in that directory.
in that working directory, create the following function:1
                                                                            2 This follows a suggestion from Bill
.First <- function().libPaths("D:/R-3.0.2/library")                         Venables.

Alternatively, the function can be placed in a startup proﬁle ﬁle, as
described in the next section.

    In moving to a new major version of R (e.g., from R-3.1.2 to R-
3.2.0), the library directory in the R installation tree is replaced. A
relatively painless way to update the new installation library direc-
tory is to copy packages across from the former installation library
directory to the new library directory, being careful not to replace
any existing packages in that directory. (If of course packages are in
a separate user directory, no moving is required.) Then, from within
R, type:

update.packages(checkBuilt=TRUE, ask=FALSE)
## Check package status:
summary(packageStatus())

    Use of a .Renviron ﬁle in the home directory is a further possi-
bility. This can be conveniently done from within R:2

cat('LIB1="C:/Users/owner/R/win-library/2.15"\n',
       file = "~/.Renviron", append = TRUE)

cat('LIB2="C:/Users/owner/R/win-library/2.14"\n',
       file = "~/.Renviron", append = TRUE)

cat('LIB1="R_LIBS_USER=${LIB1};${LIB2}\n',
       file = "~/.Renviron", append = TRUE)

A.8 The Startup mechanism

Various system variables are set at startup, and a number of packages       3 If this is unset, R searches for a ﬁle
are attached. The details can be controlled at an installation level, at    R_HOME/etc/Rproﬁle.site. ’Factory-
a user level, and at a startup directory level. If started in the standard  fresh’ installations will not have such
manner, the ’R_PROFILE’ environment variable3 can be used to                a ﬁle. Code is sourced into the base
give the name of a site-wide proﬁle ﬁle. See help(Startup) for              package, before other packages are
details.                                                                    4loAadlteedrn. atively, the
                                                                            ’R_PROFILE_USER’ environment
    R next searches at startup for a ﬁle called .Rproﬁle in the current     variable can be used to set the name of
directory or in the user’s home directory (in that order).4 Such a          a user proﬁle ﬁle.
.Rproﬁle ﬁle can for example deﬁne a .First() and/or a .Last()
function.

    A user (or site-wide) proﬁle ﬁle might for example include the
following statements:

options(papersize="a4")    # Preferred editor
options(editor="notepad")
options(pager="internal")
options(tab.width = 4)
224 learning and exploring r

options(width = 120)              # Wider console line
options(graphics.record=TRUE)
options(show.signif.stars=FALSE)  # Banish the stars
options(prompt="? ")              # Use ' ? ' as prompt
options(continue=" ")             # Blank continuation
.libPaths("C:/my_R_library")      # Add library to path.
B
The R Commander Graphical User Interface
226 learning and exploring r                                            At startup, the R Commander checks
                                                                        whether all packages are available
    To start the R commander, start R and enter:                        that are needed for the full range
                                                                        of features. If some are missing,
 library(Rcmdr)                                                         the R commander oﬀers to install
                                                                        them. (This requires a live internet
This opens an R Commander script window, with the output window         connection.)
                                                                        The code can be run either from the
underneath. This window can be closed by clicking on the × in the       script window or from the R console
                                                                        window (if open).
top left corner. If thus closed, enter Commander() to reopen it again
later in the session.                                                   1 This uses scatterplot() (car
                                                                        package), which in turn uses functions
From GUI to writing code: The R commander displays the code             from base graphics.
that it generates. Users can take this code, modify it, and re-run it.
                                                                        2 This uses the R Commander function
The active data set: There is, at any one time, a single “active”       scatter3d() that is an interface to
data set. Start by clicking on the Data drop-down menu. To select or    functions in the rgl package.
create or change the active data set, do one of the following:

• Click on Active data set, and pick from among data sets, if any, in
   the workspace.

• Click on Import data, and follow instructions, to read in data from
   a ﬁle. The data set is read into the workspace, at the same time
   becoming the active data set.

• Click on New data set . . . , then entering data via a spreadsheet-
   like interface.

• Click on Data in packages, then Read Data from Package. Then
   select an attached package and choose a data set from among
   those included with the package.

• A further possibility is to load data from an R image (.RData)
   ﬁle; click on Load data set . . .

Creating graphs: To draw graphs, click on the Graphs drop-down
menu. Then, among other possibilities:

• Click on Scatterplot . . . to obtain a scatterplot.1

• Click on X Y conditioning plot . . . for lattice scatterplots and
   panels of scatterplots.

• Click on 3D graph to obtain a 3D scatterplot.2

Statistics (& ﬁtting models): Click on the Statistics drop down
menu to get submenus that give summary statistics and/or carry out
various statistical tests. This includes (under Contingency tables)
tables of counts and (under Means) One-way ANOVA. Also, click
here to get access to the Fit models submenu.

*Models: Click here to extract information from model objects
once they have been ﬁtted. (NB: To ﬁt a model, go to the Statistics
drop down menu, and click on Fit models).
the r commander graphical user interface 227

Other GUIs for R                                                       Note also the abilities in playwith
                                                                       and latticist for interaction with
The rattle GUI, aimed broadly at “data mining” (data manipulation,     graphs. These are both discussed in
regression, classiﬁcation and clustering) applications, is a powerful  Subsection 7.2.10. See also Figure
and sophisticated system. It has a number of features that make it     7.16
attractive for use in standard data mining applications. Note also
JGR (Java Graphics for R) and pmg (Poor Man’s GUI).
228 learning and exploring r
C
Color Versions of Selected Graphs
230 learning and exploring r

Annotated Motion Chart

                                                                                                              Figure C.1: Snapshot of a motion
                                                                                                              chart, with annotation that identiﬁes
                                                                                                              selected chart features that can be
                                                                                                              modiﬁed interactively.
                       color versions of selected graphs 231

A Playwith GUI Window

                       Figure C.2: This playwith GUI win-
                       dow was generated by wrapping
                       the call to xyplot() in the func-
                       tion playwith(), then clicking on
                       Identify. Click near to a point to see
                       its label. A second click adds the label
                       to the graph. This is a color version of
                       7.16.
232 learning and exploring r                                                                             The name “coxcomb” arose from a
                                                                                                         misreading of Florence Nightingale’s
Florence Nightingale’s Wedge Plot                                                                        Mortality of the British Army that was
                                                                                                         an annex to a larger oﬃcial report. See
Figure C.3 is a “wedge” plot that shows the mortality of British                                         http://www.york.ac.uk/depts/
troops according to cause in the Crimean War over 1853-1853. It has                                      maths/histstat/small.htm
often been called a “coxcomb” plot – a name that suits this imagina-
tive form of graphical presentation.

                          A: Causes of Mortality in the Army in the East : Before       B: Causes of Mortality in the Army in the East : After

                                           Jun 54  Jul 54  Disease                                       Jun 55  Jul 55  Disease

                     1000 Other                                                    1000 Other

                     750                                            Wounds         750                                            Wounds
                                                           Aug 54                                                        Aug 55
                                   May 54                                                        May 55

                     500                                                           500

                     250                                                           250

Deaths per thousand       Apr 54                           Sep 54                       Apr 55                           Sep 55

                     00

                          Mar 55                           Oct 54                       Mar 56                           Oct 55

                          Feb 55                                  Nov 54                Feb 56                                  Nov 55
                                         Jan 55    Dec 54                                              Jan 56    Dec 55

    Figure C.3 is used here to show abilities in ggplot2. The wedge                                      Figure C.3: Deaths (per 1000 per
plot is not ideal for giving an accurate sense of the data. It is not                                    annum), up to and after the Sanitary
however easy to suggest an alternative that is clearly better.                                           Commission’s visit in March 1855.
                                                                                                         Areas, measured from the centres of
Code for the wedge plot                                                                                  the common vertices, are proportional
                                                                                                         to mortalities..
The url http://maths.anu.edu.au/~johnm/r/functions/
wedgeORbubble.R.1 has code for the function wedgeplot() that                                             1 Data are from the data frame
was used for this plot. Note also the function gdot() that gives a not                                   Nightingale in the HistData pack-
entirely satisfactory alternative to the wedge plot.                                                     age. Subsection C.3 showed how to
                                                                                                         create a dataset Crimean that is in a
                                                                                                         convenient form for creating this plot.
                                                                  color versions of selected graphs 233

Selected base graphics parameter settings

A: Plot symbols and text; specify colors and/or character expansion; draw rectangle
 par(fig=c(0, 1, 0.415, 1))

 plot(0, 0, xlim=c(0, 13), ylim=c(0, 19), type="n")
 xpos <− rep((0:12)+0.5, 2); ypos <− rep(c(14.5,12.75), c(13,13))
 points(xpos, ypos, cex=2.5, col=1:26, pch=0:25)
 text(xpos, ypos, labels=paste(0:25), cex=0.75)

q0 1 2 3 4                q5 6 7 8 9 10 11                                           12
                          q q18 19 q20 21 22 23 24                                   25
q13 14  q15 16 17

## Plot characters, vary cex (expansion)

text((0:4)+0.5, rep(9*ht, 5), letters[1:5], cex=c(2.5,2,1,1.5,2))

ab c d e                                                          above (3)
                                                                         q
## Position label with respect to point
xmid <− 10.5; xoff <− c(0, −0.5, 0, 0.5)                          left (2) q  q right (4)
ymid <− 5.8; yoff <− c(−1,0,1,0)
col4 <− colors()[c(52, 116, 547, 610)]                                       q
                                                                  below (pos=1)

points(xmid+xoff, ymid+yoff, pch=16, cex=1.5, col=col4)

posText <− c("below (pos=1)", "left (2)", "above (3)", "right (4)")

text(xmid+xoff, ymid+yoff, posText, pos=1:4)

rect(xmid−2.3, ymid−2.3, xmid+2.3, ymid+2.3, border="red")

B: Triangles or polygons, circles, and mathematical text
 par(fig=c(0, 1, 0.01, 0.40), new=TRUE)

 plot(0, 0, xlim=c(0, 13), ylim=c(0, 12), type="n")
 polygon(x=c(10.7,12.8,12), y=c(7.5,8,11), col="gray", border="red")

## Draw a circle, overlay 2−headed arrow (code=3)

xcenter <− 11.7; ycenter <− 4; r=1.1

symbols(x=xcenter, y=ycenter, circles=r,

bg="gray", add=TRUE, inches=FALSE)

arrows(x0=xcenter−r, y0=ycenter, x1=xcenter, y1=ycenter,                      Area = πr2
            length=.05, code=3)

                                                                              r

## Use expression() to add labeling information

charht <− strheight("R")

text(x=xcenter−r/2, y=ycenter−charht, expression(italic(r)))

text(xcenter, ycenter+3.5*charht, expression("Area" == pi*italic(r)^2))

.                                                                 Figure C.4: This ﬁgure, intended to
                                                                  accompany Section 7.1.2, demon-
Note that the function paste(), used in line 5 of Panel A, turns  strates the use of parameter settings to
the vector of numerical values 0:12 into a vector of character    control various graphical features.
strings with elements "0", "1", ..., "12". An alternative to
paste(0:12) is as.character(0:12).
